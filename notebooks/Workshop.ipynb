{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df488b2-c156-431d-80d6-95409cec7b1c",
   "metadata": {},
   "source": [
    "## Layout-Aware Entity Detection with Amazon Textract and Amazon SageMaker\n",
    "\n",
    "# End-to-End Workshop\n",
    "\n",
    "> *This notebook works well with the `Data Science 3.0 (Python 3)` kernel on SageMaker Studio*\n",
    "\n",
    "This alternative notebook accompanies a **guided workshop** on the Amazon Textract Transformer Pipeline solution. The steps have been somewhat streamlined, and the inline commentary reduced, compared to the main numbered notebook series. If you're trying out the solution on your own, you may prefer to start with [Notebook 1: Data Preparation](1.%20Data%20Preparation.ipynb) instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaf75a5-f133-4d85-b780-c42a256ef620",
   "metadata": {},
   "source": [
    "---\n",
    "## Environment setup \n",
    "\n",
    "### SageMaker notebook permissions\n",
    "\n",
    "▶️ In the [AWS IAM Console](https://console.aws.amazon.com/iamv2/home#/roles), check that you've attached the deployed OCR pipeline stack's **data science policy** to your SageMaker Execution Role, before continuing. You can find your deployed OCRPipeline stack in the [AWS CloudFormation Console](https://console.aws.amazon.com/cloudformation/home), and the Data Science Policy name is one of the Stack outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e799284-0075-4343-8e99-94a9cdc357a4",
   "metadata": {},
   "source": [
    "### Notebook libraries and configurations\n",
    "\n",
    "This notebook will require some additional libraries that aren't available by default in the SageMaker Studio Data Science kernel. Run the cell below to install the extra dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9cdc9fb-377f-44dc-bb8c-51401c4a07d0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: amazon-textract-response-parser in /opt/conda/lib/python3.10/site-packages (0.1.44)\n",
      "Requirement already satisfied: sagemaker-studio-image-build in /opt/conda/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: sagemaker<3,>=2.87 in /opt/conda/lib/python3.10/site-packages (2.145.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from amazon-textract-response-parser) (1.26.111)\n",
      "Requirement already satisfied: marshmallow<4,>=3.14 in /opt/conda/lib/python3.10/site-packages (from amazon-textract-response-parser) (3.19.0)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (0.7.5)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (1.24.2)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (5.4.1)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (2.5.2)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (4.11.3)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (3.2.0)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (3.20.3)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (0.3.0)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (21.4.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (1.4.4)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (0.2.0)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (0.1.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (21.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker<3,>=2.87) (1.0.1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->amazon-textract-response-parser) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->amazon-textract-response-parser) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.111 in /opt/conda/lib/python3.10/site-packages (from boto3->amazon-textract-response-parser) (1.29.111)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker<3,>=2.87) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->sagemaker<3,>=2.87) (3.0.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker<3,>=2.87) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker<3,>=2.87) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker<3,>=2.87) (67.6.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker<3,>=2.87) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker<3,>=2.87) (2022.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker<3,>=2.87) (1.7.6.6)\n",
      "Requirement already satisfied: dill>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker<3,>=2.87) (0.3.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker<3,>=2.87) (0.70.14)\n",
      "Requirement already satisfied: pox>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker<3,>=2.87) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker<3,>=2.87) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.111->boto3->amazon-textract-response-parser) (1.26.15)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "--2023-05-27 16:05:31--  https://nodejs.org/dist/v16.18.0/node-v16.18.0-linux-x64.tar.xz\n",
      "Resolving nodejs.org (nodejs.org)... 104.20.23.46, 104.20.22.46, 2606:4700:10::6814:172e, ...\n",
      "Connecting to nodejs.org (nodejs.org)|104.20.23.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22496468 (21M) [application/x-xz]\n",
      "Saving to: ‘STDOUT’\n",
      "\n",
      "-                   100%[===================>]  21.45M  9.72MB/s    in 2.2s    \n",
      "\n",
      "2023-05-27 16:05:34 (9.72 MB/s) - written to stdout [22496468/22496468]\n",
      "\n",
      "NodeJS v16.18.0 installed!\n"
     ]
    }
   ],
   "source": [
    "# Install Python libraries:\n",
    "!pip install amazon-textract-response-parser \\\n",
    "    sagemaker-studio-image-build \\\n",
    "    \"sagemaker>=2.87,<3\"\n",
    "\n",
    "# Install NodeJS:\n",
    "NODE_VER = \"v16.18.0\"\n",
    "NODE_DISTRO = \"linux-x64\"\n",
    "!mkdir -p /usr/local/lib/nodejs\n",
    "!wget -c https://nodejs.org/dist/{NODE_VER}/node-{NODE_VER}-{NODE_DISTRO}.tar.xz -O - | tar -xJ -C /usr/local/lib/nodejs\n",
    "NODE_BIN_DIR = f\"/usr/local/lib/nodejs/node-{NODE_VER}-{NODE_DISTRO}/bin\"\n",
    "ONPATH_BIN_DIR = \"/usr/local/bin\"\n",
    "!ln -fs {NODE_BIN_DIR}/node {ONPATH_BIN_DIR}/node && \\\n",
    "    ln -fs {NODE_BIN_DIR}/npm {ONPATH_BIN_DIR}/npm && \\\n",
    "    ln -fs {NODE_BIN_DIR}/npx {ONPATH_BIN_DIR}/npx && \\\n",
    "    echo \"NodeJS {NODE_VER} installed!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e0741-21ec-438e-b782-e1728b301106",
   "metadata": {},
   "source": [
    "With the extra libraries installed, you're ready to load them into the kernel and initialise clients for the various AWS services we'll be calling from the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d433651b-ff28-4540-8c8d-ba355000f120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-27 16:05:36,764 project [INFO] No PROJECT_ID variable found in environment: You'll need to call init('myprojectid')\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "from datetime import datetime\n",
    "import json\n",
    "from logging import getLogger\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3  # AWS SDK for Python\n",
    "from IPython import display  # To display rich content in notebook\n",
    "import pandas as pd  # For tabular data analysis\n",
    "import sagemaker  # High-level SDK for SageMaker\n",
    "from tqdm.notebook import tqdm  # Progress bars\n",
    "\n",
    "# Local Dependencies:\n",
    "import util\n",
    "\n",
    "# AWS service clients:\n",
    "s3 = boto3.resource(\"s3\")\n",
    "smclient = boto3.client(\"sagemaker\")\n",
    "ssm = boto3.client(\"ssm\")\n",
    "\n",
    "logger = getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772da7c5-e69d-4e2c-bf81-97bd47e6dc71",
   "metadata": {},
   "source": [
    "This notebook will work with data sandboxes in Amazon S3, and connect to a deployed document processing pipeline solution. Below, we configure S3 data folders and read deployed pipeline parameter configuration from [AWS Systems Manager Parameter Store (AWS SSM)](https://docs.aws.amazon.com/systems-manager/latest/userguide/systems-manager-parameter-store.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cad19ece-bf6a-41e0-8941-d4ed0aa75e59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bucket Name: sagemaker-us-east-1-015943506230\n",
      "Bucket Prefix: DynamicTableParser/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use our own bucket loaded with training images 2023-05-23\n",
    "#bucket_name = 'bt-digital-bt-labs-internal-200'\n",
    "#bucket_prefix = \"DynamicTableParser/4_TrainingData/\"\n",
    "\n",
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "bucket_prefix = \"DynamicTableParser/\"\n",
    "\n",
    "print()\n",
    "print (\"Bucket Name: \" + bucket_name)\n",
    "print (\"Bucket Prefix: \" + bucket_prefix)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d2a9655-b6a7-4a75-ab2f-99f2833ce4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working in bucket s3://sagemaker-us-east-1-015943506230/DynamicTableParser/\n",
      "\n",
      "2023-05-27 16:05:38,067 project [INFO] Working in project 'ocr-transformers-demo'\n",
      "<util.project.ProjectSession(\n",
      "  project_id=ocr-transformers-demo,\n",
      "  a2i_review_flow_arn_param=/ocr-transformers-demo/config/HumanReviewFlowArn,\n",
      "  entity_config_param=/ocr-transformers-demo/config/EntityConfiguration,\n",
      "  sagemaker_endpoint_name_param=/ocr-transformers-demo/config/SageMakerEndpointName,\n",
      "  thumbnail_endpoint_name_param=/ocr-transformers-demo/config/ThumbnailEndpointName,\n",
      "  a2i_execution_role_arn=arn:aws:iam::015943506230:role/OCRPipelineDemo-ProcessingPipelineReviewStepProces-M6UD1K31HQ0Q,\n",
      "  pipeline_input_bucket_name=ocrpipelinedemo-pipelineinputbucket350ea1ae-1ffox60d5xk2z,\n",
      "  model_callback_topic_arn=arn:aws:sns:us-east-1:015943506230:OCRPipelineDemo-ProcessingPipelineEnrichmentStepNLPEnrichmentModelSageMakerAsyncNLPEnrichmentModelE62625A1-WxGfSPiKRll3,\n",
      "  model_results_bucket=ocrpipelinedemo-processingpipelineenrichedresults-bt6ehtmayta3,\n",
      "  pipeline_sfn_arn=arn:aws:states:us-east-1:015943506230:stateMachine:ProcessingPipelinePipelineStateMachineC698BCB6-OfF7h2R7eWfO,\n",
      "  plain_textract_sfn_arn=arn:aws:states:us-east-1:015943506230:stateMachine:ProcessingPipelineOCRStepTextractStepTextractStateMachineFA5B3847-JnTeNju1dIbg,\n",
      "  preproc_image_uri=015943506230.dkr.ecr.us-east-1.amazonaws.com/sm-ocr-preprocs:pytorch-1.10-inf-cpu,\n",
      "  pipeline_reviews_bucket_name=ocrpipelinedemo-processingpipelinehumanreviewsbuc-v3nqj65r0rt9,\n",
      "  sm_image_build_role=OCRPipelineDemo-AnnotationInfraSMImageBuildRole8DB-93NPCEWTHQPR,\n",
      "  thumbnails_callback_topic_arn=arn:aws:sns:us-east-1:015943506230:OCRPipelineDemo-ProcessingPipelineThumbnailStepSageMakerAsyncThumbnailStepD663EB88-T83wFi71Nvmf\n",
      ") at 0x7f15ee14b370>\n"
     ]
    }
   ],
   "source": [
    "# S3 data locations:\n",
    "# 2023-05-24\n",
    "#bucket_name = sagemaker.Session().default_bucket()\n",
    "#bucket_prefix = \"textract-transformers-wshp/\"\n",
    "\n",
    "raw_s3uri = f\"s3://{bucket_name}/{bucket_prefix}data/raw\"\n",
    "imgs_s3uri = f\"s3://{bucket_name}/{bucket_prefix}data/imgs-clean\"\n",
    "textract_s3uri = f\"s3://{bucket_name}/{bucket_prefix}data/textracted\"\n",
    "thumbs_s3uri = f\"s3://{bucket_name}/{bucket_prefix}data/thumbnails\"\n",
    "annotations_base_s3uri = f\"s3://{bucket_name}/{bucket_prefix}data/annotations\"\n",
    "print(f\"Working in bucket s3://{bucket_name}/{bucket_prefix}\\n\")\n",
    "\n",
    "try:\n",
    "    config = util.project.init(\"ocr-transformers-demo\")\n",
    "    print(config)\n",
    "except Exception as e:\n",
    "    try:\n",
    "        print(f\"Your SageMaker execution role is: {sagemaker.get_execution_role()}\")\n",
    "    except Exception:\n",
    "        print(\"Couldn't look up your SageMaker execution role\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a9cb45-40ea-4f65-89d2-9cb52fc0a763",
   "metadata": {},
   "source": [
    "### SageMaker Ground Truth work team\n",
    "\n",
    "For this demo, you'll also need to manually set up a private work \"team\" in SageMaker Ground Truth, and enrol yourself to be able to use the data annotation UI.\n",
    "\n",
    "▶️ **Open** the [Amazon SageMaker Ground Truth console, *Labeling Workforces* page](https://console.aws.amazon.com/sagemaker/groundtruth?#/labeling-workforces)\n",
    "\n",
    "> ⚠️ **Check** SM Ground Truth opens in the same **AWS Region** where this notebook and your CloudFormation stack are deployed: You may find it defaults to `N. Virginia`. Use the drop-down in the top right of the screen to switch regions.\n",
    "\n",
    "▶️ **Select** the *Private* tab and click **Create private team**\n",
    "\n",
    "- Choose an appropriate **name** for your team e.g. `just-me`\n",
    "- (If you get the option) select to **Invite new workers via email** and enter your email address (you'll need access to this address to log in and annotate the data)\n",
    "- And leave the other (Cognito, SNS, etc) parameters as default.\n",
    "\n",
    "▶️ **If you didn't get the option** to add workers during team creation (typically because your account is already set up for SageMaker Ground Truth), then after the team is created you can:\n",
    "\n",
    "- Click **Invite new workers** to add your email address to the workforce, and then\n",
    "- Click on your **team name** to open the team details, then navigate to the *Workers tab* to add yourself to the team\n",
    "\n",
    "▶️ **Copy** the *name* of your workteam and paste it into the cell below, to store it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da49ffc7-f976-478a-90ea-151885e10ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2023-05-24 skipping since we already have labled our training data\n",
    "\n",
    "#workteam_name = \"just-me\"  # TODO: Update this to match yours, if different\n",
    "\n",
    "#workteam_arn = util.smgt.workteam_arn_from_name(workteam_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3633c52e-566b-4472-94fe-5fd9aef295ac",
   "metadata": {},
   "source": [
    "Finally:\n",
    "\n",
    "▶️ **Check your email** for an invitation and log in to the labelling portal. You'll be asked to configure a password on first login.\n",
    "\n",
    "\n",
    "Your completed setup should look something like this in the AWS Console:\n",
    "\n",
    "![](img/smgt-private-workforce.png \"Screenshot of SageMaker Ground Truth private workforces configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d01f0c2-fde1-48fc-907c-439d8d288c0d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fetch the raw document corpus\n",
    "\n",
    "In this example, we'll explore entity detection on specimen **credit card agreements** published by the United States' [Consumer Finance Protection Bureau](https://www.consumerfinance.gov/credit-cards/agreements/). This dataset includes providers across the US, and is interesting for our purposes because the documents are:\n",
    "\n",
    "- **Diverse** in formatting, as various providers present the required information in different ways\n",
    "- **Representative of commercial** documents - rather than, for example, academic papers which might have quite different tone and structure\n",
    "- **Complex** in structure, with common data points in theory (e.g. interest rates, fees, etc) - but a lot of nuances and differences between documents in practice.\n",
    "\n",
    "The sample dataset (approx. 900MB uncompressed) is published as an archive file (approx. 750MB) which we'll need to extract for the raw PDFs. Since it's a reasonable size, we can perform the extraction here in SageMaker Studio to also have local copies of the raw files to inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a35cac5-4883-4483-9d08-8dc7b96fa6f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/raw'}\n"
     ]
    }
   ],
   "source": [
    "print ({raw_s3uri})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bad343-ea5b-402b-b94a-ea72e811d16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading raw PDFs from s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/raw...\n",
      "Done\n",
      "CPU times: user 26 ms, sys: 4.52 ms, total: 30.5 ms\n",
      "Wall time: 1.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "os.makedirs(\"data/raw\", exist_ok=True)\n",
    "\n",
    "# 2023-05-24  skipping since we want to use our own data\n",
    "# Fetch the example data:\n",
    "#!wget -O data/CC_Agreements.zip https://files.consumerfinance.gov/a/assets/Credit_Card_Agreements_2020_Q4.zip\n",
    "\n",
    "#  WE will upload our image files from S3 to data/raw rather than download them.  \n",
    "\n",
    "# The s3 sync command can upload folders from SageMaker to S3 (or download, swapping the args).\n",
    "# For the example data, we extracted locally so will upload:\n",
    "print(f\"Downloading raw PDFs from {raw_s3uri}...\")\n",
    "!aws s3 sync --quiet {raw_s3uri} data/raw\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "965cf6bb-cef5-4620-bf62-ae361754db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# Extract the file:\n",
    "\n",
    "# 2023-05-23  not needed; our images are already unzipped\n",
    "\n",
    "#print(\"Extracting...\")\n",
    "#shutil.rmtree(\"data/raw\")\n",
    "#with ZipFile(\"data/CC_Agreements.zip\", \"r\") as fzip:\n",
    "#    fzip.extractall(\"data/raw\")\n",
    "\n",
    "# Clean up unneeded files and remap if the folder became nested:\n",
    "# (This is written specific to our sample data zip, but is unlikely to break most custom data)\n",
    "#original_root_items = os.listdir(\"data/raw\")\n",
    "#if \"__MACOSX\" in original_root_items:\n",
    "#    shutil.rmtree(\"data/raw/__MACOSX\")\n",
    "#if len(original_root_items) < 4:\n",
    "#    try:\n",
    "#        folder = next(f for f in original_root_items if f.startswith(\"Credit_Card_Agreements\"))\n",
    "#        print(f\"De-nesting folder '{folder}'...\")\n",
    "#        for sub in os.listdir(f\"data/raw/{folder}\"):\n",
    "#            shutil.move(f\"data/raw/{folder}/{sub}\", f\"data/raw/{sub}\")\n",
    "#            time.sleep(0.1)  # (Saw a FileNotFound error during renames one time in SMStudio)\n",
    "#        os.rmdir(f\"data/raw/{folder}\")\n",
    "#    except StopIteration:\n",
    "#        pass\n",
    "\n",
    "#print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac05fc9-49ab-4999-b11f-df6f56579e19",
   "metadata": {},
   "source": [
    "To build an initial manifest/index of the data, we'd like to filter out any unsupported system files or other non-document content in the folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6454c9e9-2484-4582-8e37-e8368a401aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/raw/\n",
      "\n",
      "Found 100 valid files for OCR\n"
     ]
    }
   ],
   "source": [
    "raw_bucket_name, raw_prefix = util.s3.s3uri_to_bucket_and_key(raw_s3uri)\n",
    "\n",
    "valid_file_types = {\"jpeg\", \"jpg\", \"pdf\", \"png\", \"tif\", \"tiff\"}\n",
    "\n",
    "n_files = 0\n",
    "with open(\"data/raw-all.manifest.jsonl\", \"w\") as f:\n",
    "    # sorted() guarantees output order for reproducible sampling later:\n",
    "    for obj in sorted(\n",
    "        s3.Bucket(raw_bucket_name).objects.filter(Prefix=raw_prefix + \"/\"),\n",
    "        key=lambda obj: obj.key,\n",
    "    ):\n",
    "        # Filter out any files you know shouldn't be counted:\n",
    "        file_ext = obj.key.rpartition(\".\")[2].lower()\n",
    "        if \"/.\" in obj.key or file_ext not in valid_file_types:\n",
    "            print(f\"Skipping s3://{obj.bucket_name}/{obj.key}\")\n",
    "            continue\n",
    "\n",
    "        # Save\n",
    "        item = {\"raw-ref\": f\"s3://{obj.bucket_name}/{obj.key}\"}\n",
    "        f.write(json.dumps(item)+\"\\n\")\n",
    "        n_files += 1\n",
    "\n",
    "print(f\"\\nFound {n_files} valid files for OCR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad41d0-a5b0-4541-ab8d-b6e9b393d60f",
   "metadata": {},
   "source": [
    "With the documents downloaded and catalogued, we can explore some examples to get an initial idea of the kind of content in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dca3a214-4149-4c93-9c01-cc278ce5c53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying: data/raw/019112540_-_Juul_Labs_-_Francis_Howell_School_District-3.jpeg\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"data/raw/019112540_-_Juul_Labs_-_Francis_Howell_School_District-3.jpeg\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f904e0337f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read from docs manifest:\n",
    "with open(\"data/raw-all.manifest.jsonl\") as f:\n",
    "    raw_doc_s3uris = [json.loads(l)[\"raw-ref\"] for l in f]\n",
    "\n",
    "# Choose a document by index number:\n",
    "disp_record = raw_doc_s3uris[0]\n",
    "filepath = disp_record.replace(raw_s3uri+\"/\", \"data/raw/\")\n",
    "\n",
    "print(f\"Displaying: {filepath}\")\n",
    "display.IFrame(\n",
    "    filepath,\n",
    "    height=\"600\",\n",
    "    width=\"100%\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9835769b-c255-4226-978b-8258891eb1e8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Define the challenge\n",
    "\n",
    "So we have our sample documents - what information would we like to extract from them?\n",
    "\n",
    "As an example, we'll consider a market data aggregation use case: Collecting information like interest rates, fees, provider and product names, and some other more challenging examples like minimum payment descriptions and locally-applicable terms. The cell below defines the list of entities for the use-case, with some tips on how to annotate them that you'll also be able to see in the data labelling UI later:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f0a54e6-3a0a-4301-9208-75f76a12ac36",
   "metadata": {},
   "source": [
    "from util.postproc.config import FieldConfiguration\n",
    "\n",
    "# For config API details, you can see the docs in the source file or run:\n",
    "# help(FieldConfiguration)\n",
    "\n",
    "fields = [\n",
    "    # (To prevent human error, enter class_id=0 each time and update programmatically below)\n",
    "    FieldConfiguration(0, \"Agreement Effective Date\", optional=True, select=\"first\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Avoid labeling extraneous dates which are not necessarily the effective date of \"\n",
    "            \"the document: E.g. copyright dates/years, or other dates mentioned in text.</p> \"\n",
    "            \"<p>Do not include unnecessary qualifiers e.g. 'from 2020/01/01'.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"APR - Introductory\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Use this class (instead of the others) for <em>ANY</em> case where the rate is \"\n",
    "            \"offered for a fixed introductory period - regardless of interest rate subtype e.g. \"\n",
    "            \"balance transfers, purchases, etc.</p> \"\n",
    "            \"<p>Include the term of the introductory period in cases where it's directly listed \"\n",
    "            \"(e.g. '20.00% for the first 6 months'). Try to minimize/exclude extraneous \"\n",
    "            \"information about the offer (e.g. '20.00% for the first 6 months after account \"\n",
    "            \"opening').</p> \"\n",
    "            \"<p>'Prime rate + X%' mentions are acceptable and should be labeled.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"APR - Balance Transfers\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Use for interest rates which are specific to balance transfers.</p> \"\n",
    "            \"<p>Avoid including extraneous information about the terms of balance transfers, or \"\n",
    "            \"using for fixed-term introductory rates.</p> \"\n",
    "            \"<p>'Prime rate + X%' mentions are acceptable and should be labeled.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"APR - Cash Advances\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Use for interest rates which are specific to cash advances.</p> \"\n",
    "            \"<p>Avoid including extraneous information about the terms of cash advances, or using \"\n",
    "            \"for fixed-term introductory rates.</p> \"\n",
    "            \"<p>'Prime rate + X%' mentions are acceptable and should be labeled.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"APR - Purchases\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Use for interest rates which are specific to purchases.</p> \"\n",
    "            \"<p>'Prime rate + X%' mentions are acceptable and should be labeled.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"APR - Penalty\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Use for penalty interest rates applied under certain conditions.</p> \"\n",
    "            \"<p><em>Exclude</em> include information about the conditions under which the penalty \"\n",
    "            \"rate comes into effect: Only include the interest rate which will be applied.</p> \"\n",
    "            \"<p>'Prime rate + X%' mentions are acceptable and should be labeled.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"APR - General\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Use for interest rates which are general and not specifically tied to a \"\n",
    "            \"particular transaction type e.g. purchases / balance transfers.</p> \"\n",
    "            \"<p>Avoid using for fixed-term introductory rates.</p> \"\n",
    "            \"<p>'Prime rate + X%' mentions are acceptable and should be labeled.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"APR - Other\", optional=True, select=\"confidence\",\n",
    "        # TODO: Remove this class\n",
    "        annotation_guidance=(\n",
    "            \"<p>Use only for interest rates which don't fall in to any other category (including \"\n",
    "            \"general or introductory rates). You may not see any examples in the data.</p> \"\n",
    "            \"<p>Avoid using for fixed-term introductory rates.</p> \"\n",
    "            \"<p>'Prime rate + X%' mentions are acceptable and should be labeled.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Fee - Annual\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Include cases where the document explicitly indicates no fee e.g. 'None'</p> \"\n",
    "            \"<p>Avoid any introductory terms e.g. '$0 for the first 6 months' or extraneous \"\n",
    "            \"words: Label only the standard fee.</p> \"\n",
    "            \"<p>Label only the annual amount of the fee, in cases where other breakdowns are \"\n",
    "            \"specified: E.g. '$120', not '$10 per month ($120 per year)'.</p> \"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Fee - Balance Transfer\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            # TODO: Review\n",
    "            \"<p>Try to be concise and exclude extra terms where not necessary</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Fee - Late Payment\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Label only the fee, not the circumstances in which it is payable.</p> \"\n",
    "            \"<p>Limits e.g. 'Up to $25' are acceptable (don't just label '$25').</p> \"\n",
    "            \"<p>Do <em>NOT</em> include non-specific mentions of pass-throgh costs (e.g. 'legal \"\n",
    "            \"costs', 'reasonable expenses', etc.) incurred in the general collections process.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Fee - Returned Payment\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Label only the fee, not the circumstances in which it is payable.</p> \"\n",
    "            \"<p>Limits e.g. 'Up to $25' are acceptable (don't just label '$25').</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Fee - Foreign Transaction\", optional=True, select=\"shortest\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Do <em>NOT</em> include explanations of how exchange rates are calculated or \"\n",
    "            \"non-specific indications of margins between rates. <em>DO</em> include specific \"\n",
    "            \"charges/margins with <em>brief</em> clarifying info where listed e.g. '3% of the US \"\n",
    "            \"dollar amount'.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Fee - Other\", ignore=True,\n",
    "        annotation_guidance=(\n",
    "            \"<p>Common examples include: Minimum interest charge, cash advance fees, and \"\n",
    "            \"overlimit fees.</p> \"\n",
    "            \"<p>Do <em>NOT</em> include fixed-term introductory rates for fees (e.g. '$0 during \"\n",
    "            \"the first year. After the first year...') - only the standard fees</p> \"\n",
    "            \"<p><em>DO</em> include qualifying information on the amount and limits of the fee, \"\n",
    "            \"e.g. '$5 or 5% of the amount of each transaction, whichever is the greater'.</p> \"\n",
    "            \"<p>Do <em>NOT</em> include general information on the nature of the fee and \"\n",
    "            \"circumstances under which it is applied: E.g. 'Cash advance fee' or 'If the amount \"\n",
    "            \"of interest payable is...'</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Card Name\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Label instances of the brand name of specific card(s) offered by the provider \"\n",
    "            \"under the agreement, e.g. 'Rewards Platinum Card'</p> \"\n",
    "            \"<p>Include the ' Card' suffix where available, but also annotate instances without \"\n",
    "            \"such as 'Rewards Platinum'</p> \"\n",
    "            \"<p><em>Avoid</em> including the Provider Name (use the separate class for this) e.g. \"\n",
    "            \"'AnyCompany Rewards Card' unless it's been substantially modified/abbreviated for \"\n",
    "            \"the card name (e.g. 'AnyCo Rewards Card') or the company name is different from the \"\n",
    "            \"Credit card provider (e.g. AnyBank offering a store credit card for AnyCompany)</p> \"\n",
    "            \"<p>Do <em>NOT</em> include fixed-term introductory rates for fees (e.g. '$0 during \"\n",
    "            \"the first year. After the first year...') - only the standard fees</p> \"\n",
    "            \"<p><em>Avoid</em> labeling generic payment provider names e.g. 'VISA card' or \"\n",
    "            \"'Mastercard', except in contexts where the provider clearly uses them as the brand \"\n",
    "            \"name for the offered card (e.g. 'VISA Card' from 'AnyCompany VISA Card'.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Provider Address\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Include department or 'attn:' lines where present (but not Provider Name where \"\n",
    "            \"used at the start of an address e.g. 'AnyCompany; 100 Main Street...').</p> \"\n",
    "            \"<p>Include zip/postcode where present.</p> \"\n",
    "            \"<p><em>Avoid</em> labeling addresses for non-provider entities, such as watchdogs, \"\n",
    "            \"market regulators, or independent agencies.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Provider Name\", select=\"longest\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>Label the name of the card provider: Including abbreviated mentions.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Min Payment Calculation\", ignore=True,\n",
    "        annotation_guidance=(\n",
    "            \"<p>Label clauses describing how the minimum payment is calculated.</p> \"\n",
    "            \"<p>Exclude lead-in e.g. 'The minimum payment is calculated as...' and label directly \"\n",
    "            \"from e.g. 'the minimum of...'.</p> \"\n",
    "            \"<p>Do <em>NOT</em> include clauses from related subjects e.g. how account balance is \"\n",
    "            \"calculated</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Local Terms\", ignore=True,\n",
    "        annotation_guidance=(\n",
    "            \"<p>Label full terms specific to residents of certain states/countries, or applying \"\n",
    "            \"only in particular jurisdictions.</p> \"\n",
    "            \"<p><em>Include</em> the scope of where the terms apply e.g. 'Residents of GA and \"\n",
    "            \"VA...'</p> \"\n",
    "            \"<p><em>Include</em> locally-applicable interest rates, instead of annotating these \"\n",
    "            \"with the 'APR - ' classes</p>\"\n",
    "        ),\n",
    "    )\n",
    "]\n",
    "for ix, cfg in enumerate(fields):\n",
    "    cfg.class_id = ix\n",
    "\n",
    "# Print out to a simple list:\n",
    "entity_classes = [f.name for f in fields]\n",
    "print(\"\\n\".join(entity_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51fe7d-d415-4535-b05c-891826a3b997",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "Person\n",
      "Description\n",
      "Hours\n",
      "Rate\n",
      "Total\n"
     ]
    }
   ],
   "source": [
    "from util.postproc.config import FieldConfiguration\n",
    "\n",
    "# For config API details, you can see the docs in the source file or run:\n",
    "# help(FieldConfiguration)\n",
    "\n",
    "fields = [\n",
    "    # (To prevent human error, enter class_id=0 each time and update programmatically below)\n",
    "    FieldConfiguration(0, \"Date\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>This is the date that the task was performed by a person.  This should be a date field in mm/dd/yyyy, mm/dd, or yyyy-mm-dd, or dd-mm-yyyy</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Person\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>This is the person doing the work. It can have a column label such as Employee, Name, Timekeeper, Initals, etc.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Description\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>It is a phrase or sentence that describes the task that was peformed by the person.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Hours\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>This is a numeric or decimal value that represents the number of hours and minutes a person worked on the task.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Rate\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>This is a numeric or decimal value that represents the amount the person charges per hour.</p>\"\n",
    "        ),\n",
    "    ),\n",
    "    FieldConfiguration(0, \"Total\", optional=True, select=\"confidence\",\n",
    "        annotation_guidance=(\n",
    "            \"<p>This is a numeric or deciaml amount that describes the total cost of Rate * Hours for a task.  It is optional.  This is not to be confused with a grand total. </p>\"\n",
    "        ),\n",
    "    ),\n",
    "    \n",
    "]\n",
    "for ix, cfg in enumerate(fields):\n",
    "    cfg.class_id = ix\n",
    "\n",
    "# Save the configuration to file:\n",
    "with open(\"data/field-config.json\", \"w\") as f:\n",
    "    f.write(json.dumps(\n",
    "        [cfg.to_dict() for cfg in fields],\n",
    "        indent=2,\n",
    "    ))\n",
    "\n",
    "# And print out a simple list:\n",
    "entity_classes = [f.name for f in fields]\n",
    "print(\"\\n\".join(entity_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f19c38-3c31-4a52-b9a8-497265f5cb30",
   "metadata": {},
   "source": [
    "---\n",
    "## Filter a sample corpus\n",
    "\n",
    "For a quick example model, there's no need for us to process or annotate all ~2,500 documents in the original corpus. Here, we'll select a random subset - but ensuring those present in the pre-prepared annotation data are kept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "468130b2-5d40-4125-9654-eaf42586a12d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'textract-ref'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Crawl source annotated Textract URIs from the job manifests:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m annotated_textract_s3uris \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mocr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_preannotated_textract_uris\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mann_jobs_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/annotations/BT_annotations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_job_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLICENSE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m (annotated_textract_s3uris)\n",
      "File \u001b[0;32m~/amazon-textract-transformer-pipeline/notebooks/util/ocr.py:63\u001b[0m, in \u001b[0;36mlist_preannotated_textract_uris\u001b[0;34m(ann_jobs_folder, exclude_job_names)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(manifest_file) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 63\u001b[0m         uris\u001b[38;5;241m.\u001b[39mupdate([json\u001b[38;5;241m.\u001b[39mloads(line)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtextract-ref\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n\u001b[1;32m     65\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m file is not valid JSON-Lines: Skipping\u001b[39m\u001b[38;5;124m\"\u001b[39m, manifest_file)\n",
      "File \u001b[0;32m~/amazon-textract-transformer-pipeline/notebooks/util/ocr.py:63\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(manifest_file) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 63\u001b[0m         uris\u001b[38;5;241m.\u001b[39mupdate([\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtextract-ref\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n\u001b[1;32m     65\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m file is not valid JSON-Lines: Skipping\u001b[39m\u001b[38;5;124m\"\u001b[39m, manifest_file)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'textract-ref'"
     ]
    }
   ],
   "source": [
    "# Crawl source annotated Textract URIs from the job manifests:\n",
    "annotated_textract_s3uris = util.ocr.list_preannotated_textract_uris(\n",
    "    ann_jobs_folder=\"data/annotations/BT_annotations\",\n",
    "    exclude_job_names=[\"LICENSE\"],\n",
    ")\n",
    "print (annotated_textract_s3uris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0675a4ec-324a-4030-927d-2e18ec5c16c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Couldn't find matching document in dataset for annotated Textract URI: s3://DOC-EXAMPLE-BUCKET/EXAMPLE-PREFIX/data/textracted/American Airlines Federal Credit Union/Visa Credit Card Agreement and Disclosure.pdf/consolidated.json",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m n_matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(matching_doc_s3uris)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_matches \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find matching document in dataset for annotated Textract URI: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;241m%\u001b[39m (uri,)\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_matches \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     31\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextract URI matched \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m document URIs: Matching criterion may be too loose.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m         n_matches,\n\u001b[1;32m     34\u001b[0m         uri,\n\u001b[1;32m     35\u001b[0m         matching_doc_s3uris,\n\u001b[1;32m     36\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Couldn't find matching document in dataset for annotated Textract URI: s3://DOC-EXAMPLE-BUCKET/EXAMPLE-PREFIX/data/textracted/American Airlines Federal Credit Union/Visa Credit Card Agreement and Disclosure.pdf/consolidated.json"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define how to check for matches:\n",
    "def textract_uri_matches_doc_uri(tex_uri, doc_uri) -> bool:\n",
    "    \"\"\"Customize this function if needed for your use case's data layout\"\"\"\n",
    "    # With our sample, Textract URIs will look like:\n",
    "    # some/prefix/data/textracted/subfolders/file.pdf/consolidated.json\n",
    "    tex_s3key = tex_uri[len(\"s3://\"):].partition(\"/\")[2]\n",
    "    # With our sample, Raw URIs will look like:\n",
    "    # some/prefix/data/raw/subfolders/file.pdf\n",
    "    doc_s3key = doc_uri[len(\"s3://\"):].partition(\"/\")[2]\n",
    "\n",
    "    # Given the expectations above:\n",
    "    tex_rel_filepath = tex_s3key.partition(\"data/textracted/\")[2].rpartition(\"/\")[0]\n",
    "    doc_rel_filepath = doc_s3key.partition(\"data/raw/\")[2]\n",
    "    return doc_rel_filepath == tex_rel_filepath\n",
    "\n",
    "# Build the list of docs for which some annotations exist (prioritising debug over speed here):\n",
    "annotated_doc_s3uris = set()\n",
    "for uri in annotated_textract_s3uris:\n",
    "    matching_doc_s3uris = [\n",
    "        doc_s3uri\n",
    "        for doc_s3uri in raw_doc_s3uris\n",
    "        if textract_uri_matches_doc_uri(uri, doc_s3uri)\n",
    "    ]\n",
    "    n_matches = len(matching_doc_s3uris)\n",
    "    if n_matches == 0:\n",
    "        raise ValueError(\n",
    "            \"Couldn't find matching document in dataset for annotated Textract URI: %s\"\n",
    "            % (uri,)\n",
    "        )\n",
    "    if n_matches > 1:\n",
    "        logger.warning(\n",
    "            \"Textract URI matched %s document URIs: Matching criterion may be too loose.\\n%s\\n%s\",\n",
    "            n_matches,\n",
    "            uri,\n",
    "            matching_doc_s3uris,\n",
    "        )\n",
    "    annotated_doc_s3uris.update(matching_doc_s3uris)\n",
    "\n",
    "# This sorted list of required document S3 URIs is the main result you need to get to here:\n",
    "annotated_doc_s3uris = sorted(annotated_doc_s3uris)\n",
    "print(f\"Found {len(annotated_doc_s3uris)} docs with pre-existing annotations\")\n",
    "print(\"For example:\")\n",
    "print(\"\\n\".join(annotated_doc_s3uris[:5] + [\"...\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f984f6-beab-420e-a9a1-503ae4e0894f",
   "metadata": {},
   "source": [
    "Both Amazon Textract and the multi-lingual entity recognition model we'll use later should be capable of processing Spanish, but you may want to exclude the small number of Spanish-language docs in the corpus if you're not able to confidently read and annotate them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "65d8d03f-7834-4378-a63c-7e9202db4eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted random sample of 100 docs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'raw-ref': 's3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/raw/019112540_-_Juul_Labs_-_Francis_Howell_School_District-3.jpeg'},\n",
       " {'raw-ref': 's3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/raw/019121420_-_Juul_Labs_-_Bronstein-4.jpeg'},\n",
       " {'raw-ref': 's3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/raw/020031085_2020-03-06_-_Juul_Labs-Breathe_DC-3.jpeg'},\n",
       " {'raw-ref': 's3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/raw/1150230-3.jpeg'},\n",
       " {'raw-ref': 's3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/raw/1150230-4.jpeg'},\n",
       " '...']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_DOCS_KEPT = 120\n",
    "SKIP_SPANISH_DOCS = True\n",
    "\n",
    "\n",
    "def include_filename(name: str) -> bool:\n",
    "    \"\"\"Filter out likely Spanish/non-English docs (if SKIP_SPANISH_DOCS enabled)\"\"\"\n",
    "    if not name:\n",
    "        return False\n",
    "    if not SKIP_SPANISH_DOCS:\n",
    "        return True\n",
    "    name_l = name.lower()\n",
    "    if (\n",
    "        \"spanish\" in name_l\n",
    "        or \"tarjeta\" in name_l\n",
    "        or re.search(r\"espa[nñ]ol\", name_l)\n",
    "        or re.search(r\"[\\[\\(]esp?[\\]\\)]\", name_l)\n",
    "        or re.search(r\"cr[eé]dito\", name_l)\n",
    "    ):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "if N_DOCS_KEPT < len(annotated_doc_s3uris):\n",
    "    raise ValueError(\n",
    "        \"Existing annotations cannot be used for model training unless the target documents are \"\n",
    "        \"Textracted. To proceed with fewer docs than have already been annotated, you'll need to \"\n",
    "        \"`exclude_job_names` per the 'data/annotations' folder (e.g. ['augmentation-1']) AND \"\n",
    "        \"remember to not include them in notebook 2 (model training). Alternatively, increase \"\n",
    "        f\"your N_DOCS_KEPT. (Got {N_DOCS_KEPT} vs {len(annotated_doc_s3uris)} prev annotations).\"\n",
    "    )\n",
    "\n",
    "with open(\"data/raw-all.manifest.jsonl\") as f:\n",
    "    # First apply filtering rules:\n",
    "    sampled_docs = [\n",
    "        doc for doc in (json.loads(line) for line in f)\n",
    "        if include_filename(doc[\"raw-ref\"])\n",
    "    ]\n",
    "\n",
    "# Forcibly including the pre-annotated docs *after* the shuffling ensures that the order of\n",
    "# sampling new docs is independent of what/how many have been pre-annotated:\n",
    "required_docs = [d for d in sampled_docs if d[\"raw-ref\"] in annotated_doc_s3uris]\n",
    "random.Random(1337).shuffle(sampled_docs)\n",
    "new_docs = [d for d in sampled_docs if d[\"raw-ref\"] not in annotated_doc_s3uris]\n",
    "sampled_docs = sorted(\n",
    "    required_docs + new_docs[:N_DOCS_KEPT - len(required_docs)],\n",
    "    key=lambda doc: doc[\"raw-ref\"],\n",
    ")\n",
    "\n",
    "# Write the selected set to file:\n",
    "with open(\"data/raw-sample.manifest.jsonl\", \"w\") as f:\n",
    "    for d in sampled_docs:\n",
    "        f.write(json.dumps(d) + \"\\n\")\n",
    "\n",
    "print(f\"Extracted random sample of {len(sampled_docs)} docs\")\n",
    "sampled_docs[:5] + [\"...\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7285f0-0f3f-4697-ad70-e512a65310aa",
   "metadata": {},
   "source": [
    "> ▶️ In [data/raw-sample.manifest.jsonl](data/raw-sample.manifest.jsonl) you should now have an alphabetized list of the `N_DOCS_KEPT` randomly selected documents, which should include any documents referenced in existing annotations under `data/annotations`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a43ae7-0a41-471b-88bb-d6255c4e123f",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## OCR the input documents\n",
    "\n",
    "> ⚠️ **Note:** Refer to the [Amazon Textract Pricing Page](https://aws.amazon.com/textract/pricing/) for up-to-date guidance before running large extraction jobs.\n",
    ">\n",
    "> At the time of writing, the projected cost (in `us-east-1`, ignoring free tier allowances) of analyzing 100 documents with 10 pages on average was approximately \\\\$67 with `TABLES` and `FORMS` enabled, or \\\\$2 without. Across the full corpus, we measured the average number of pages per document at approximately 6.7.\n",
    "\n",
    "With (a subset of) the raw documents selected, the next ingredient is to link them with Amazon Textract-compatible OCR results in a new manifest - with entries something like:\n",
    "\n",
    "```json\n",
    "{\"raw-ref\": \"s3://doc-example-bucket/folder/mydoc.pdf\", \"textract-ref\": \"s3://doc-example-bucket/folder/mydoc-textracted.json\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53aec4c-882b-4a89-aafe-46fe1165489c",
   "metadata": {},
   "source": [
    "We need to be mindful of the service [quotas](https://docs.aws.amazon.com/general/latest/gr/textract.html#limits_textract) when processing large batches of documents with Amazon Textract, to avoid excessive rate limiting and retries. Since an OCR pipeline solution stack is already set up for this sample, you can use just the *Amazon Textract portion of the pipeline* to process the documents in bulk.\n",
    "\n",
    "> ⏰ This process took about 6 minutes to run against the 120-document sample set in our tests.\n",
    "\n",
    "> ⚠️ **If you see errors in the output:**\n",
    ">\n",
    "> - Try re-running the cell - Rate limiting can sometimes cause intermittent failures, and the function will skip successfully processed files in repeat runs.\n",
    "> - Persistent errors (on custom datasets) could be due to malformed files (remove them from the manifest) or very large files (see the [/CUSTOMIZATION_GUIDE.md](../CUSTOMIZATION_GUIDE.md) for tips on re-configuring your pipeline to handle very large documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8456c95-7e74-477b-b0e3-36271f788a2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3761e7d9e241bf980e7e5c4b2cda04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textracting PDFs...:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934950fd5b8841969aada0729c1ffe8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Starting jobs...:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.76 s, sys: 109 ms, total: 1.87 s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "textract_results = util.ocr.call_textract(\n",
    "    textract_sfn_arn=config.plain_textract_sfn_arn,\n",
    "    # Can instead use raw-all.manifest.jsonl to process whole dataset (see cost note above):\n",
    "    input_manifest=\"data/raw-sample.manifest.jsonl\",\n",
    "    manifest_raw_field=\"raw-ref\",\n",
    "    manifest_out_field=\"textract-ref\",\n",
    "    # Map subpaths of {input_base} to subpaths of {output_base}:\n",
    "    output_base_s3uri=textract_s3uri,\n",
    "    input_base_s3uri=raw_s3uri,\n",
    "    # Note that turning on additional features can have significant impact on API costs:\n",
    "    features=[\"FORMS\", \"TABLES\"],\n",
    "    skip_existing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43f46c79-02e3-49ee-bbeb-083f730f3a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://bt-digital-bt-labs-internal-200/DynamicTableParser/4_TrainingData/data/textracted\n"
     ]
    }
   ],
   "source": [
    "# this is annoying.\n",
    "# I am not sure where to look to \"Doc failed to process - see results for details\"\n",
    "# this is just doing OCR with Textracks and writting to here\n",
    "# maybe we can simulate this for now and use our own Textrack responses .json files \n",
    "# TO DO:  Use your own CODE TO OCR document to .JSON until we can figure out how to modify this code and view the log\n",
    "print (textract_s3uri)\n",
    "#  we are going to proceed with our .JSON files to bypass this step.\n",
    "\n",
    "# fix:  use the default bucket.   I don't thing the the cloud formation template setup an ROLE with \n",
    "# to ready S3, just the default bucket.   \n",
    "# What access role was created and if so can't we just update the rights to allow to read from S3?\n",
    "\n",
    "# Workaround :   Use the Default S3 bucket - sagemaker-us-east-1-015943506230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab3e0b6f-2fc0-49c5-9477-99e2eae9291a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print (textract_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a184c07-dd58-4912-8c6c-a2d14fcc88a7",
   "metadata": {},
   "source": [
    "Once the extraction is done, write (only successful items) to a manifest file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38867c33-0e99-4980-b94d-a185598ffd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 of 100 docs processed successfully\n"
     ]
    }
   ],
   "source": [
    "n_success = 0\n",
    "n_fail = 0\n",
    "with open(\"data/textracted-all.manifest.jsonl\", \"w\") as fout:\n",
    "    for ix, item in enumerate(textract_results):\n",
    "        if isinstance(item[\"textract-ref\"], str):\n",
    "            fout.write(json.dumps(item) + \"\\n\")\n",
    "            n_success += 1\n",
    "        else:\n",
    "            if n_fail == 0:\n",
    "                print ()\n",
    "                print (item)\n",
    "                print ()\n",
    "                logger.error(\"First failure at index %s:\\n%s\", ix, item[\"textract-ref\"])\n",
    "                print ()\n",
    "            n_fail += 1\n",
    "\n",
    "print(f\"{n_success} of {n_success + n_fail} docs processed successfully\")\n",
    "if n_fail > 0:\n",
    "    raise ValueError(\n",
    "        \"Are you sure you want to continue? Consider re-trying to process the failed docs\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686fc8c-353b-487c-b664-1ebf4a87fa6f",
   "metadata": {},
   "source": [
    "> ▶️ You should now have a [data/textracted-all.manifest.jsonl](data/textracted-all.manifest.jsonl) JSON-Lines manifest file mapping source documents `raw-ref` to Amazon Textract result JSONs `textract-ref`: Both as `s3://...` URIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdae5616-5de2-4e62-954f-e9aca3f51335",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Extract clean input images (batch)\n",
    "\n",
    "To annotate our documents with SageMaker Ground Truth image task UIs, we need **individual page images**, stripped of EXIF rotation metadata (because, at the time of writing, SMGT ignores this rotation for annotation consistency) and converted to compatible formats (since some formats like TIFF are not supported by most browsers).\n",
    "\n",
    "For large corpora, this process of splitting PDFs and rotating and converting images may require significant resources - but is easy to parallelize.\n",
    "\n",
    "Therefore instead of pre-processing the raw documents here in the notebook, this is a good use case for a scalable [SageMaker Processing Job](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html).\n",
    "\n",
    "The job uses a **custom container image**, since the PDF reading tools we use aren't installed by default in pre-built SageMaker containers and aren't `pip install`able. However, the image has already been built and deployed to [Amazon Elastic Container Registry (ECR)](https://aws.amazon.com/ecr/) by the CDK stack (see `preproc_image` in [/pipeline/\\_\\_init\\_\\_.py](../pipeline/__init__.py)). All we need to do here is look it up from the stack parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de79e673-4cb9-430c-a5ea-ed964722c477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pre-built custom container image:\n",
      "015943506230.dkr.ecr.us-east-1.amazonaws.com/sm-ocr-preprocs:pytorch-1.10-inf-cpu\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import FrameworkProcessor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "ecr_image_uri = config.preproc_image_uri\n",
    "print(f\"Using pre-built custom container image:\\n{ecr_image_uri}\")\n",
    "#015943506230.dkr.ecr.us-east-1.amazonaws.com/sm-ocr-preprocs:pytorch-1.10-inf-cpu\n",
    "\n",
    "# Output S3 locations:\n",
    "imgs_s3uri = f\"s3://{bucket_name}/{bucket_prefix}data/imgs-clean\"\n",
    "thumbs_s3uri = f\"s3://{bucket_name}/{bucket_prefix}data/thumbnails\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4cafa4-97a9-4b3d-a137-e9824e5536e5",
   "metadata": {},
   "source": [
    "> **Note:** The 'Non-augmented' manifest files used below for job data loading are still JSON-based, but a different format from the JSON-**Lines** manifests we use in most other places of this sample. You can find guidance on the [S3DataSource API doc](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_S3DataSource.html) for manifests as used here, and separate information in the [Ground Truth documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-input-data-input-manifest.html) on the \"augmented\" JSON-Lines manifests used elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b45cc00a-345d-4893-b20c-85b161899efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/raw-dataclean-input.manifest.json to s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/raw-dataclean-input.manifest.json\n",
      "Selected sample subset of documents\n"
     ]
    }
   ],
   "source": [
    "#### OPTION 2: For processing the sampled subset of raw docs only:\n",
    "\n",
    "# Load the list of docs from file and add final filters:\n",
    "with open(\"data/raw-sample.manifest.jsonl\") as fin:\n",
    "    doc_relpaths = [\n",
    "        json.loads(line)[\"raw-ref\"][len(raw_s3uri) + 1:]  # Relative file paths\n",
    "        for line in fin\n",
    "    ]\n",
    "\n",
    "# Prepare a true JSON (*NON-JSONLINES*) manifest file for SageMaker Processing:\n",
    "preproc_input_manifest_path = \"data/raw-dataclean-input.manifest.json\"\n",
    "with open(preproc_input_manifest_path, \"w\") as fout:\n",
    "    fout.write(json.dumps(\n",
    "        [{\"prefix\": raw_s3uri + \"/\"}]\n",
    "        + doc_relpaths\n",
    "    ))\n",
    "\n",
    "# Upload the manifest to S3:\n",
    "preproc_input_manifest_s3uri = f\"s3://{bucket_name}/{bucket_prefix}{preproc_input_manifest_path}\"\n",
    "!aws s3 cp {preproc_input_manifest_path} {preproc_input_manifest_s3uri}\n",
    "\n",
    "# Set the processing job inputs to reference the manifest:\n",
    "preproc_inputs = [\n",
    "    ProcessingInput(\n",
    "        destination=\"/opt/ml/processing/input/raw\",  # Expected input location, per our script\n",
    "        input_name=\"raw\",\n",
    "        s3_data_distribution_type=\"ShardedByS3Key\",  # Distribute between instances, if multiple\n",
    "        s3_data_type=\"ManifestFile\",\n",
    "        source=preproc_input_manifest_s3uri,  # Manifest of sample raw documents\n",
    "    ),\n",
    "]\n",
    "print(\"Selected sample subset of documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d3fae-0852-4f7c-b2d1-08e7b9b2525b",
   "metadata": {},
   "source": [
    "The cell below will **run the processing job** and show logs from the job as it progresses. You can also check up on the status and history of jobs in the [Processing page of the Amazon SageMaker Console](https://console.aws.amazon.com/sagemaker/home?#/processing-jobs).\n",
    "\n",
    "> ⏰ **Note:** In our tests, it took (including job start-up overheads) about 8 minutes to process the 120-document sample with 2x `ml.c5.2xlarge` instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e5d3223-5fa9-47b4-bbe7-3594bffd108a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................\u001b[35m2023-05-24 14:01:38,381 [preproc] INFO Parsed job args: Namespace(input='/opt/ml/processing/input/raw', n_workers=8, output='/opt/ml/processing/output/imgs-clean', thumbnails='/opt/ml/processing/output/thumbnails')\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:38,381 [preproc] INFO Additional thumbnail output is ENABLED\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:38,381 [preproc] INFO Reading raw files from /opt/ml/processing/input/raw\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:38,381 [preproc] INFO Processing 50 files across 8 processes\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:39,131 [preproc] INFO Processed doc 1 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:39,144 [preproc] INFO Processed doc 2 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:39,145 [preproc] INFO Processed doc 3 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:39,146 [preproc] INFO Processed doc 4 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:39,152 [preproc] INFO Processed doc 5 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:39,156 [preproc] INFO Processed doc 6 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:39,158 [preproc] INFO Processed doc 7 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:39,158 [preproc] INFO Processed doc 8 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:38,335 [preproc] INFO Parsed job args: Namespace(input='/opt/ml/processing/input/raw', n_workers=8, output='/opt/ml/processing/output/imgs-clean', thumbnails='/opt/ml/processing/output/thumbnails')\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:38,335 [preproc] INFO Additional thumbnail output is ENABLED\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:38,335 [preproc] INFO Reading raw files from /opt/ml/processing/input/raw\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:38,335 [preproc] INFO Processing 50 files across 8 processes\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:39,088 [preproc] INFO Processed doc 1 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:39,089 [preproc] INFO Processed doc 2 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:39,089 [preproc] INFO Processed doc 3 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:39,089 [preproc] INFO Processed doc 4 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:39,090 [preproc] INFO Processed doc 5 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:39,091 [preproc] INFO Processed doc 6 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:39,093 [preproc] INFO Processed doc 7 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:39,110 [preproc] INFO Processed doc 8 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:39,799 [preproc] INFO Processed doc 9 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:39,809 [preproc] INFO Processed doc 10 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:39,809 [preproc] INFO Processed doc 11 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:39,811 [preproc] INFO Processed doc 12 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:39,824 [preproc] INFO Processed doc 13 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:40,071 [preproc] INFO Processed doc 14 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:40,075 [preproc] INFO Processed doc 15 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:40,096 [preproc] INFO Processed doc 16 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:39,869 [preproc] INFO Processed doc 9 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:39,870 [preproc] INFO Processed doc 10 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:39,870 [preproc] INFO Processed doc 11 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:39,879 [preproc] INFO Processed doc 12 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:39,888 [preproc] INFO Processed doc 13 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:40,147 [preproc] INFO Processed doc 14 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:40,178 [preproc] INFO Processed doc 15 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:40,178 [preproc] INFO Processed doc 16 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:40,527 [preproc] INFO Processed doc 17 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:40,548 [preproc] INFO Processed doc 18 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:40,591 [preproc] INFO Processed doc 19 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:40,615 [preproc] INFO Processed doc 20 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:40,455 [preproc] INFO Processed doc 17 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:40,525 [preproc] INFO Processed doc 18 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:40,535 [preproc] INFO Processed doc 19 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:40,780 [preproc] INFO Processed doc 20 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:40,817 [preproc] INFO Processed doc 21 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:40,859 [preproc] INFO Processed doc 22 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:41,003 [preproc] INFO Processed doc 23 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:41,003 [preproc] INFO Processed doc 24 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:41,141 [preproc] INFO Processed doc 25 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:41,186 [preproc] INFO Processed doc 26 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:41,202 [preproc] INFO Processed doc 27 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:40,771 [preproc] INFO Processed doc 21 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:40,820 [preproc] INFO Processed doc 22 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:40,848 [preproc] INFO Processed doc 23 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:41,039 [preproc] INFO Processed doc 24 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:41,197 [preproc] INFO Processed doc 25 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:41,221 [preproc] INFO Processed doc 26 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:41,265 [preproc] INFO Processed doc 27 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:41,440 [preproc] INFO Processed doc 28 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:41,481 [preproc] INFO Processed doc 29 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:41,493 [preproc] INFO Processed doc 30 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:41,521 [preproc] INFO Processed doc 31 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:41,592 [preproc] INFO Processed doc 28 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:41,601 [preproc] INFO Processed doc 29 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:41,692 [preproc] INFO Processed doc 30 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:41,743 [preproc] INFO Processed doc 31 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:41,814 [preproc] INFO Processed doc 32 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:41,838 [preproc] INFO Processed doc 33 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:42,195 [preproc] INFO Processed doc 34 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:42,263 [preproc] INFO Processed doc 35 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:42,267 [preproc] INFO Processed doc 36 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:42,310 [preproc] INFO Processed doc 37 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:42,163 [preproc] INFO Processed doc 32 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:42,201 [preproc] INFO Processed doc 33 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:42,213 [preproc] INFO Processed doc 34 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:42,239 [preproc] INFO Processed doc 35 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:42,318 [preproc] INFO Processed doc 36 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:42,330 [preproc] INFO Processed doc 37 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:42,411 [preproc] INFO Processed doc 38 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:42,449 [preproc] INFO Processed doc 39 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:42,388 [preproc] INFO Processed doc 38 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:42,400 [preproc] INFO Processed doc 39 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:42,483 [preproc] INFO Processed doc 40 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:42,937 [preproc] INFO Processed doc 41 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:42,963 [preproc] INFO Processed doc 42 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:42,975 [preproc] INFO Processed doc 43 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:43,171 [preproc] INFO Processed doc 44 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:43,344 [preproc] INFO Processed doc 45 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:43,398 [preproc] INFO Processed doc 46 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:43,484 [preproc] INFO Processed doc 47 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:43,590 [preproc] INFO Processed doc 48 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:43,953 [preproc] INFO Processed doc 49 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:43,990 [preproc] INFO Processed doc 50 of 50\u001b[0m\n",
      "\u001b[34m2023-05-24 14:01:43,994 [preproc] INFO All done!\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:43,241 [preproc] INFO Processed doc 40 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:43,249 [preproc] INFO Processed doc 41 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:43,410 [preproc] INFO Processed doc 42 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:43,466 [preproc] INFO Processed doc 43 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:43,541 [preproc] INFO Processed doc 44 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:43,630 [preproc] INFO Processed doc 45 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:43,644 [preproc] INFO Processed doc 46 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:43,692 [preproc] INFO Processed doc 47 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:43,917 [preproc] INFO Processed doc 48 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:44,307 [preproc] INFO Processed doc 49 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:44,453 [preproc] INFO Processed doc 50 of 50\u001b[0m\n",
      "\u001b[35m2023-05-24 14:01:44,457 [preproc] INFO All done!\u001b[0m\n",
      "\n",
      "CPU times: user 638 ms, sys: 41 ms, total: 679 ms\n",
      "Wall time: 4min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "processor = FrameworkProcessor(\n",
    "    estimator_cls=util.preproc.DummyFramework,\n",
    "    image_uri=ecr_image_uri,\n",
    "    framework_version=\"\",  # Not needed as image URI already provided\n",
    "    base_job_name=\"ocr-img-dataclean\",\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    instance_count=2,\n",
    "    instance_type=\"ml.c5.2xlarge\",\n",
    "    volume_size_in_gb=15,\n",
    ")\n",
    "\n",
    "processor.run(\n",
    "    code=\"preproc.py\",  # PDF splitting / image conversion script\n",
    "    source_dir=\"preproc\",\n",
    "    inputs=preproc_inputs[:],  # Either whole corpus or sample, as above\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            destination=imgs_s3uri,\n",
    "            output_name=\"imgs-clean\",\n",
    "            s3_upload_mode=\"Continuous\",\n",
    "            source=\"/opt/ml/processing/output/imgs-clean\",  # Hi-res images for labelling\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            destination=thumbs_s3uri,\n",
    "            output_name=\"thumbnails\",\n",
    "            s3_upload_mode=\"Continuous\",\n",
    "            source=\"/opt/ml/processing/output/thumbnails\",  # Low-res images for model inputs\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18deaa89-6cb6-45c1-b721-22754cc5af12",
   "metadata": {},
   "source": [
    "Once the images have been extracted, we'll also **optionally** download them locally to the notebook for use in visualizations later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f0dfede-76cf-46f0-8541-b51d5292f8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cleaned images from s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/imgs-clean...\n",
      "Downloading thumbnail images from s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/thumbnails...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(f\"Downloading cleaned images from {imgs_s3uri}...\")\n",
    "!aws s3 sync --quiet {imgs_s3uri} data/imgs-clean\n",
    "print(f\"Downloading thumbnail images from {thumbs_s3uri}...\")\n",
    "!aws s3 sync --quiet {thumbs_s3uri} data/imgs-thumb\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cfa331-7e41-484b-8021-2fbe23cf06d3",
   "metadata": {},
   "source": [
    "You'll see that this job also generates uniformly resized \"thumbnail\" images per page when the second (optional) `thumbnails` output is specified. These aren't important for the human annotation process, but will be used later for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f08ef2c-08ee-4ed7-8abe-3586d6eb7100",
   "metadata": {},
   "source": [
    "### Collate OCR and image data for annotation\n",
    "\n",
    "Now we have a filtered corpus of documents with Amazon Textract results, plus cleaned and standardized images for each page - all available on Amazon S3.\n",
    "\n",
    "To prepare for data annotation and later model training, we'll need to collate these together with a **page-level manifest** in JSON-lines format, with records something like:\n",
    "\n",
    "```json\n",
    "{\"source-ref\": \"s3://doc-example-bucket/img-prefix/folder/filename-0001-01.png\", \"textract-ref\": \"s3://doc-example-bucket/tex-prefix/folder/filename.pdf/consolidated.json\", \"page-num\": 1}\n",
    "```\n",
    "\n",
    "Key features of the format are:\n",
    "- The `source-ref` is the path to a full-resolution cleaned page image (**not** a thumbnail), **but** model training in the next notebook will assume the equivalent thumbnail path is identical, except for some different s3://... bucket & prefix.\n",
    "- The `page-num` is one-based (always >= 1), and for model training must match the image to the appropriate page number **in the linked Textract JSON file**.\n",
    "    - For example if you have thumbnail `filename-0001-15.png` for page 15 of some long document, but for some reason your `textract-ref` JSON file contains *only* detections from page 15 of the document, you would set `\"page-num\": 1`.\n",
    "- Mapping through the `raw-ref` here is nice to have, but optional, as the model training won't refer to the original document.\n",
    "\n",
    "The key goal is to create a page-level catalogue that we're confident is correct, and for that reason the example function below will actually **validate that the artifacts are present on S3** in the expected locations.\n",
    "\n",
    "> ⏰ Because of these validation checks, the cell below may a minute or two to run against our 120-document sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea8ec1ae-a892-4f55-8ac2-2f493a5a58b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b789980bb44fafaea07818421fcbc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building data manifest...:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-24 15:38:12,793 trp [INFO] INFO: Detected K/V where key does not have content. Excluding key from output. \n",
      "Field\n",
      "==========\n",
      "Key: \n",
      "Value:  - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 18.713516235351562, 'Geometry': {'BoundingBox': {'Width': 0.08611905574798584, 'Height': 0.038271334022283554, 'Left': 0.553975522518158, 'Top': 0.2256677895784378}, 'Polygon': [{'X': 0.5539950132369995, 'Y': 0.2256677895784378}, {'X': 0.6400945782661438, 'Y': 0.22578750550746918}, {'X': 0.6400762796401978, 'Y': 0.26393911242485046}, {'X': 0.553975522518158, 'Y': 0.2638183534145355}]}, 'Id': '28026c6e-a69e-46fd-930d-5b1340f54feb', 'Relationships': [{'Type': 'VALUE', 'Ids': ['38f2f5fa-c1d1-4fcf-b61f-97d7df713f98']}], 'EntityTypes': ['KEY'], 'Page': 1}\n",
      "2023-05-24 15:38:12,945 trp [INFO] INFO: Detected K/V where key does not have content. Excluding key from output. \n",
      "Field\n",
      "==========\n",
      "Key: \n",
      "Value: TBC_Insurance0071375 - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 23.77922248840332, 'Geometry': {'BoundingBox': {'Width': 0.03384359925985336, 'Height': 0.011108193546533585, 'Left': 0.7917169332504272, 'Top': 0.9859501719474792}, 'Polygon': [{'X': 0.7917169332504272, 'Y': 0.9859501719474792}, {'X': 0.82555091381073, 'Y': 0.9859937429428101}, {'X': 0.8255605101585388, 'Y': 0.9970583915710449}, {'X': 0.7917264699935913, 'Y': 0.9970147013664246}]}, 'Id': 'd710ceca-d685-489c-953e-806e07dc84db', 'Relationships': [{'Type': 'VALUE', 'Ids': ['6c3a8274-0709-43c4-8214-230c5d41b74d']}], 'EntityTypes': ['KEY'], 'Page': 1}\n",
      "2023-05-24 15:38:13,081 trp [INFO] INFO: Detected K/V where key does not have content. Excluding key from output. \n",
      "Field\n",
      "==========\n",
      "Key: \n",
      "Value: TBC_Insurance0071376 - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 18.551057815551758, 'Geometry': {'BoundingBox': {'Width': 0.03181580454111099, 'Height': 0.012001476250588894, 'Left': 0.7936782240867615, 'Top': 0.9855995774269104}, 'Polygon': [{'X': 0.7936782240867615, 'Y': 0.9856054186820984}, {'X': 0.8254912495613098, 'Y': 0.9855995774269104}, {'X': 0.8254939913749695, 'Y': 0.9975953698158264}, {'X': 0.7936807870864868, 'Y': 0.9976010918617249}]}, 'Id': '8b7c503f-4be9-4bec-adb2-668ead24f917', 'Relationships': [{'Type': 'VALUE', 'Ids': ['6c91b4cc-00ae-4a06-8c8a-fd4d5f67ccdb']}], 'EntityTypes': ['KEY'], 'Page': 1}\n",
      "2023-05-24 15:38:13,225 trp [INFO] INFO: Detected K/V where key does not have content. Excluding key from output. \n",
      "Field\n",
      "==========\n",
      "Key: \n",
      "Value:  - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 15.955998420715332, 'Geometry': {'BoundingBox': {'Width': 0.035205207765102386, 'Height': 0.011626782827079296, 'Left': 0.7922948002815247, 'Top': 0.9859977960586548}, 'Polygon': [{'X': 0.7922948002815247, 'Y': 0.9860028624534607}, {'X': 0.8274922966957092, 'Y': 0.9859977960586548}, {'X': 0.82750004529953, 'Y': 0.9976196885108948}, {'X': 0.7923024296760559, 'Y': 0.9976245760917664}]}, 'Id': 'a16df93d-7ee0-496d-b34c-2d12a343f5de', 'Relationships': [{'Type': 'VALUE', 'Ids': ['68fd9d04-8b3e-4a32-91e0-a10f5fec0bcf']}], 'EntityTypes': ['KEY'], 'Page': 1}\n",
      "2023-05-24 15:38:13,984 trp [INFO] INFO: Detected K/V where key does not have content. Excluding key from output. \n",
      "Field\n",
      "==========\n",
      "Key: \n",
      "Value: TBC_Insurance0011214 - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 20.453649520874023, 'Geometry': {'BoundingBox': {'Width': 0.03321913629770279, 'Height': 0.011166322976350784, 'Left': 0.7917633652687073, 'Top': 0.9859945774078369}, 'Polygon': [{'X': 0.7917633652687073, 'Y': 0.9860183000564575}, {'X': 0.824981689453125, 'Y': 0.9859945774078369}, {'X': 0.8249825239181519, 'Y': 0.9971373081207275}, {'X': 0.7917641997337341, 'Y': 0.9971609115600586}]}, 'Id': '0be06ed4-7ec7-447e-a9e2-784e3250a71b', 'Relationships': [{'Type': 'VALUE', 'Ids': ['83f4b694-3315-42a1-82e0-03cbeee6112d']}], 'EntityTypes': ['KEY'], 'Page': 1}\n",
      "2023-05-24 15:38:14,145 trp [INFO] INFO: Detected K/V where key does not have content. Excluding key from output. \n",
      "Field\n",
      "==========\n",
      "Key: \n",
      "Value: TBC_Insurance0011599 - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 21.25178337097168, 'Geometry': {'BoundingBox': {'Width': 0.03339758887887001, 'Height': 0.011775698512792587, 'Left': 0.791449785232544, 'Top': 0.9857885837554932}, 'Polygon': [{'X': 0.791449785232544, 'Y': 0.9857897162437439}, {'X': 0.8248450756072998, 'Y': 0.9857885837554932}, {'X': 0.824847400188446, 'Y': 0.9975633025169373}, {'X': 0.7914518713951111, 'Y': 0.9975643157958984}]}, 'Id': '3af73fc7-e9e0-4811-9b26-43dd3c4dfa75', 'Relationships': [{'Type': 'VALUE', 'Ids': ['50499bcb-73fc-45f7-bfdd-212549af10e3']}], 'EntityTypes': ['KEY'], 'Page': 1}\n",
      "2023-05-24 15:38:14,940 trp [INFO] INFO: Detected K/V where key does not have content. Excluding key from output. \n",
      "Field\n",
      "==========\n",
      "Key: \n",
      "Value: http://www.mphinc.com - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 76.01237487792969, 'Geometry': {'BoundingBox': {'Width': 0.040094997733831406, 'Height': 0.010034700855612755, 'Left': 0.5565001964569092, 'Top': 0.29440340399742126}, 'Polygon': [{'X': 0.556502103805542, 'Y': 0.29440340399742126}, {'X': 0.5965951681137085, 'Y': 0.29442134499549866}, {'X': 0.5965932607650757, 'Y': 0.30443811416625977}, {'X': 0.5565001964569092, 'Y': 0.3044201731681824}]}, 'Id': '7896ab10-f0b2-499d-9319-7f9ee6d12e58', 'Relationships': [{'Type': 'VALUE', 'Ids': ['307df863-331d-4184-859f-561b3ccab673']}], 'EntityTypes': ['KEY'], 'Page': 1}\n",
      "2023-05-24 15:38:15,712 trp [INFO] INFO: Detected K/V where key does not have content. Excluding key from output. \n",
      "Field\n",
      "==========\n",
      "Key: \n",
      "Value: TBC_Insurance0008840 - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 36.19546127319336, 'Geometry': {'BoundingBox': {'Width': 0.03464001044631004, 'Height': 0.012438258156180382, 'Left': 0.7910675406455994, 'Top': 0.9857746958732605}, 'Polygon': [{'X': 0.7910681366920471, 'Y': 0.9857746958732605}, {'X': 0.8257075548171997, 'Y': 0.9857860803604126}, {'X': 0.8257070183753967, 'Y': 0.9982129335403442}, {'X': 0.7910675406455994, 'Y': 0.9982014894485474}]}, 'Id': '20712b66-fd93-4f44-a0bc-555248acfb43', 'Relationships': [{'Type': 'VALUE', 'Ids': ['8de048b6-6729-4a86-ad80-0a16e8af677a']}], 'EntityTypes': ['KEY'], 'Page': 1}\n",
      "2023-05-24 15:38:16,394 trp [INFO] INFO: Detected K/V where key does not have content. Excluding key from output. \n",
      "Field\n",
      "==========\n",
      "Key: \n",
      "Value:  - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 20.58942222595215, 'Geometry': {'BoundingBox': {'Width': 0.0323689728975296, 'Height': 0.011858541518449783, 'Left': 0.7910616397857666, 'Top': 0.9865580201148987}, 'Polygon': [{'X': 0.7910616397857666, 'Y': 0.9865580201148987}, {'X': 0.823423445224762, 'Y': 0.9865807294845581}, {'X': 0.8234306573867798, 'Y': 0.998416543006897}, {'X': 0.7910686135292053, 'Y': 0.9983937740325928}]}, 'Id': 'ba939434-b827-4a76-bb30-26c2bbff34ff', 'Relationships': [{'Type': 'VALUE', 'Ids': ['437ccb05-c237-43db-8b55-ef6411f03625']}], 'EntityTypes': ['KEY'], 'Page': 1}\n",
      "2023-05-24 15:38:17,518 trp [INFO] INFO: Detected K/V where key does not have content. Excluding key from output. \n",
      "Field\n",
      "==========\n",
      "Key: \n",
      "Value: TBC_Insurance0028031 - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 30.557029724121094, 'Geometry': {'BoundingBox': {'Width': 0.03266330435872078, 'Height': 0.011142070405185223, 'Left': 0.793186366558075, 'Top': 0.9858704805374146}, 'Polygon': [{'X': 0.7931875586509705, 'Y': 0.9858704805374146}, {'X': 0.8258496522903442, 'Y': 0.9859121441841125}, {'X': 0.8258486986160278, 'Y': 0.9970125555992126}, {'X': 0.793186366558075, 'Y': 0.9969705939292908}]}, 'Id': '8a9ce8c3-88b3-4f4f-97c1-6304d9c2e32c', 'Relationships': [{'Type': 'VALUE', 'Ids': ['36dfcd8f-8966-4697-8d00-bd4b66504373']}], 'EntityTypes': ['KEY'], 'Page': 1}\n"
     ]
    }
   ],
   "source": [
    "warnings = util.preproc.collate_data_manifest(\n",
    "    # Output file:\n",
    "    \"data/pages-all-sample.manifest.jsonl\",\n",
    "    # Input manifest:\n",
    "    input_manifest=\"data/textracted-all.manifest.jsonl\",\n",
    "    # s3://... base URI used to try and map 'textract-ref's to cleaned images:\n",
    "    textract_s3_prefix=textract_s3uri,\n",
    "    # The s3://... base URI under which page images are stored:\n",
    "    imgs_s3_prefix=imgs_s3uri,\n",
    "    # Optional s3://... base URI also used to try and map 'raw-ref's to images if present:\n",
    "    raw_s3_prefix=raw_s3uri,\n",
    "    # Other output manifest settings:\n",
    "    by=\"page\",\n",
    "    no_content=\"omit\",\n",
    ")\n",
    "\n",
    "if len(warnings):\n",
    "    raise ValueError(\n",
    "        \"Manifest usable but incomplete - %s docs failed. Please see `warnings` for details\"\n",
    "        % len(warnings)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bb7800-7bad-40bf-bcce-7e72296ad270",
   "metadata": {},
   "source": [
    "> ▶️ You should now have a page-level catalogue linking `source-ref`, `textract-ref`, `page-num` in [data/pages-all-sample.manifest.jsonl](data/pages-all-sample.manifest.jsonl)\n",
    "\n",
    "Let's briefly explore the catalogue we've created. Each line of the file is a JSON record identifying a particular page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38ff4bfe-31d7-4f13-8eb9-42b270679238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"raw-ref\": \"s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/raw/019112540_-_Juul_Labs_-_Francis_Howell_School_District-3.jpeg\", \"textract-ref\": \"s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/textracted/019112540_-_Juul_Labs_-_Francis_Howell_School_District-3.jpeg/consolidated.json\", \"source-ref\": \"s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/imgs-clean/019112540_-_Juul_Labs_-_Francis_Howell_School_District-3.jpeg\", \"page-num\": 1}\n",
      "{\"raw-ref\": \"s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/raw/019121420_-_Juul_Labs_-_Bronstein-4.jpeg\", \"textract-ref\": \"s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/textracted/019121420_-_Juul_Labs_-_Bronstein-4.jpeg/consolidated.json\", \"source-ref\": \"s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/imgs-clean/019121420_-_Juul_Labs_-_Bronstein-4.jpeg\", \"page-num\": 1}\n",
      "{\"raw-ref\": \"s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/raw/020031085_2020-03-06_-_Juul_Labs-Breathe_DC-3.jpeg\", \"textract-ref\": \"s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/textracted/020031085_2020-03-06_-_Juul_Labs-Breathe_DC-3.jpeg/consolidated.json\", \"source-ref\": \"s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/imgs-clean/020031085_2020-03-06_-_Juul_Labs-Breathe_DC-3.jpeg\", \"page-num\": 1}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/pages-all-sample.manifest.jsonl\", \"r\") as f:\n",
    "    for ix, line in enumerate(f):\n",
    "        print(line, end=\"\")\n",
    "        if ix >= 2:\n",
    "            print(\"...\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52809830-8c28-474c-ba0a-fd879e3021b0",
   "metadata": {},
   "source": [
    "The credit cards corpus has a very skewed distribution of number of pages per document, with a few outliers dragging up the average significantly. In our tests on corpus-wide statistics:\n",
    "\n",
    "- The overall average was **~6.7 pages per document**\n",
    "- The 25th percentile was 3 pages; the 50th percentile was 6 pages; and the 75th percentile was 11 pages\n",
    "- The longest document was 402 pages\n",
    "\n",
    "Your results for sub-sampled sets will likely vary - but can be analyzed as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ced078ea-1268-418c-96df-7ba6017a1d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document page count statistics\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    100.0\n",
       "mean       1.0\n",
       "std        0.0\n",
       "min        1.0\n",
       "25%        1.0\n",
       "50%        1.0\n",
       "75%        1.0\n",
       "max        1.0\n",
       "Name: textract-ref, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/pages-all-sample.manifest.jsonl\", \"r\") as f:\n",
    "    manifest_df = pd.DataFrame([json.loads(line) for line in f])\n",
    "page_counts_by_doc = manifest_df.groupby(\"textract-ref\")[\"textract-ref\"].count()\n",
    "\n",
    "print(\"Document page count statistics\")\n",
    "page_counts_by_doc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61da00fe-f0ed-4e7c-b1c8-d0ed13e5bfbf",
   "metadata": {},
   "source": [
    "---\n",
    "## Start the data labelling job\n",
    "\n",
    "Now we have a correlated set of cleaned page images and OCR results for each page, we're ready to start annotating entities to collect model training data. Typically this is an iterative process with multiple rounds of labelling to balance experimentation speed with model accuracy. Here though, we'll show setting up a single small labelling job and combine the results with pre-existing annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322cad31-3f79-4e25-8d12-c77bf13cd319",
   "metadata": {},
   "source": [
    "### Sample a dataset to label\n",
    "\n",
    "Below, we:\n",
    "\n",
    "- **Shuffle** our data (in a *reproducible*/deterministic way), to ensure we annotate documents/pages from a range of providers - not just concentrating on the first provider/doc(s)\n",
    "- **Exclude** any examples for which the page image has **already been labeled** in the `data/annotations` output folder\n",
    "- **Stratify** the sample, to obtain a specific (boosted) proportion of first-page samples, since we observed the first pages of documents to often be most useful for the fields of interest in the sample credit cards use case. (Many documents use the first page for a fact-sheet/summary, followed by subsequent pages of dense legal terms).\n",
    "\n",
    "Run the cells below to select a small subset of previously-unlabelled pages and build a manifest file listing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85916f48-eaa0-4a1f-afa2-df80eb7d1641",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_job_name = \"cfpb-workshop-1\"  # What will this job be called?\n",
    "N_JOB_EXAMPLES = 15  # Select 15 new pages to annotate\n",
    "PCT_FIRST_PAGE = .4  # 40% of samples should be page-num 1\n",
    "\n",
    "preannotated_img_uris = [\n",
    "    f\"{imgs_s3uri}/{path}\"\n",
    "    for path in util.preproc.list_preannotated_img_paths(\n",
    "        annotations_folder=\"data/annotations\",\n",
    "        exclude_job_names=[],\n",
    "        key_prefix=\"data/imgs-clean/\",\n",
    "    )\n",
    "]\n",
    "\n",
    "job_input_manifest_file = f\"data/manifests/{annotation_job_name}.jsonl\"\n",
    "os.makedirs(\"data/manifests\", exist_ok=True)\n",
    "print(f\"'{annotation_job_name}' saving to: {job_input_manifest_file}\")\n",
    "\n",
    "with open(job_input_manifest_file, \"w\") as f:\n",
    "    for ix, example in enumerate(\n",
    "        util.preproc.stratified_sample_first_page_examples(\n",
    "            input_manifest_path=\"data/pages-all-sample.manifest.jsonl\",\n",
    "            n_examples=N_JOB_EXAMPLES,  \n",
    "            pct_first_page=PCT_FIRST_PAGE,\n",
    "            exclude_source_ref_uris=preannotated_img_uris,\n",
    "        )\n",
    "    ):\n",
    "        if ix < 3:\n",
    "            print(example)\n",
    "        elif ix == 3:\n",
    "            print(\"...\")\n",
    "        f.write(json.dumps(example) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0955cd-cf0c-4f9f-8e3f-ce04f494527a",
   "metadata": {},
   "source": [
    "To create the labelling job in SageMaker, this manifest file will also need to be uploaded to Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650135a2-65d7-4bf3-85f7-bee1d301793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_manifest_s3uri = f\"s3://{bucket_name}/{bucket_prefix}{job_input_manifest_file}\"\n",
    "!aws s3 cp $job_input_manifest_file $input_manifest_s3uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785e618b-4dc8-4aca-bad5-424289813e8b",
   "metadata": {},
   "source": [
    "### Create the labelling job\n",
    "\n",
    "With a manifest file defining which pages should be included, and your \"work team\" already set up from earlier, you're ready to create your SageMaker Ground Truth labelling job.\n",
    "\n",
    "You could also explore creating this via the AWS Console for SageMaker, but the code below will set up the job with the correct settings for you automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809aa7b8-3f18-4ef8-803f-cf6da1de9682",
   "metadata": {},
   "outputs": [],
   "source": [
    "util.smgt.ensure_bucket_cors(bucket_name)\n",
    "\n",
    "print(f\"Starting labeling job {annotation_job_name}\\non data {input_manifest_s3uri}\\n\")\n",
    "create_labeling_job_resp = util.smgt.create_bbox_labeling_job(\n",
    "    annotation_job_name,\n",
    "    bucket_name=bucket_name,\n",
    "    execution_role_arn=sagemaker.get_execution_role(),\n",
    "    fields=fields,\n",
    "    input_manifest_s3uri=input_manifest_s3uri,\n",
    "    output_s3uri=annotations_base_s3uri,\n",
    "    workteam_arn=workteam_arn,\n",
    "    # To create a review/adjustment job from a manifest with existing labels in:\n",
    "    # reviewing_attribute_name=\"label\",\n",
    "    s3_inputs_prefix=f\"{bucket_prefix}data/manifests\",\n",
    ")\n",
    "print(f\"\\nLABELLING JOB STARTED:\\n{create_labeling_job_resp['LabelingJobArn']}\")\n",
    "print()\n",
    "print(input_manifest_s3uri)\n",
    "print(annotations_base_s3uri)\n",
    "print(sagemaker.get_execution_role())\n",
    "print(\"\\n\".join([\"\\nLabels:\", \"-------\"] + entity_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e294758e-1fd5-4558-b0a5-cf37798ba0ac",
   "metadata": {},
   "source": [
    "---\n",
    "## Before you label - build custom containers\n",
    "\n",
    "The entity recognition model we'll train later uses **customized containers**, which install extra libraries over the standard [SageMaker Hugging Face framework containers](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/index.html).\n",
    "\n",
    "> ⏰ Building these can take several minutes - so before you start labelling your documents in the SageMaker Ground Truth portal, **start the below cells running** to save some time.\n",
    ">\n",
    "> You don't need to wait for them to finish - just move on to the next \"Label the data\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af1d114b-4f62-4866-8440-b7de14fbc228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target training image: 015943506230.dkr.ecr.us-east-1.amazonaws.com/sm-ocr-training:hf-4.26-pt-gpu\n",
      "Target inference image: 015943506230.dkr.ecr.us-east-1.amazonaws.com/sm-ocr-inference:hf-4.26-pt-gpu\n"
     ]
    }
   ],
   "source": [
    "# Configurations:\n",
    "hf_version = \"4.17\"\n",
    "py_version = \"py38\"\n",
    "pt_version = \"1.10\"\n",
    "train_repo_name = \"sm-ocr-training\"\n",
    "#train_repo_tag = f\"hf-{hf_version}-pt-gpu\"\n",
    "train_repo_tag = \"hf-4.26-pt-gpu\"  # (Base HF version is overridden in Dockerfile)\n",
    "inf_repo_name = \"sm-ocr-inference\"\n",
    "inf_repo_tag = train_repo_tag\n",
    "\n",
    "account_id = sagemaker.Session().account_id()\n",
    "region = os.environ[\"AWS_REGION\"]\n",
    "\n",
    "base_image_params = {\n",
    "    \"framework\": \"huggingface\",\n",
    "    \"region\": region,\n",
    "    \"instance_type\": \"ml.p3.2xlarge\",  # (Just used to check whether GPUs/accelerators are used)\n",
    "    \"py_version\": py_version,\n",
    "    \"version\": hf_version,\n",
    "    \"base_framework_version\": f\"pytorch{pt_version}\",\n",
    "}\n",
    "\n",
    "train_base_uri = sagemaker.image_uris.retrieve(**base_image_params, image_scope=\"training\")\n",
    "inf_base_uri = sagemaker.image_uris.retrieve(**base_image_params, image_scope=\"inference\")\n",
    "\n",
    "# Combine together into the final URIs:\n",
    "train_image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{train_repo_name}:{train_repo_tag}\"\n",
    "print(f\"Target training image: {train_image_uri}\")\n",
    "inf_image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{inf_repo_name}:{inf_repo_tag}\"\n",
    "print(f\"Target inference image: {inf_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2310bdf-17a5-49ba-a125-7aef8134fce4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............[Container] 2023/05/24 17:17:28 Waiting for agent ping\n",
      "\n",
      "[Container] 2023/05/24 17:17:29 Waiting for DOWNLOAD_SOURCE\n",
      "[Container] 2023/05/24 17:17:31 Phase is DOWNLOAD_SOURCE\n",
      "[Container] 2023/05/24 17:17:31 CODEBUILD_SRC_DIR=/codebuild/output/src805522994/src\n",
      "[Container] 2023/05/24 17:17:31 YAML location is /codebuild/output/src805522994/src/buildspec.yml\n",
      "[Container] 2023/05/24 17:17:31 Setting HTTP client timeout to higher timeout for S3 source\n",
      "[Container] 2023/05/24 17:17:31 Processing environment variables\n",
      "[Container] 2023/05/24 17:17:31 No runtime version selected in buildspec.\n",
      "[Container] 2023/05/24 17:17:31 Moving to directory /codebuild/output/src805522994/src\n",
      "[Container] 2023/05/24 17:17:31 Configuring ssm agent with target id: codebuild:1a51358b-df4a-49a3-9bbf-436668c58010\n",
      "[Container] 2023/05/24 17:17:31 Successfully updated ssm agent configuration\n",
      "[Container] 2023/05/24 17:17:31 Registering with agent\n",
      "[Container] 2023/05/24 17:17:31 Phases found in YAML: 3\n",
      "[Container] 2023/05/24 17:17:31  PRE_BUILD: 9 commands\n",
      "[Container] 2023/05/24 17:17:31  BUILD: 4 commands\n",
      "[Container] 2023/05/24 17:17:31  POST_BUILD: 3 commands\n",
      "[Container] 2023/05/24 17:17:31 Phase complete: DOWNLOAD_SOURCE State: SUCCEEDED\n",
      "[Container] 2023/05/24 17:17:31 Phase context status code:  Message:\n",
      "[Container] 2023/05/24 17:17:31 Entering phase INSTALL\n",
      "[Container] 2023/05/24 17:17:31 Phase complete: INSTALL State: SUCCEEDED\n",
      "[Container] 2023/05/24 17:17:31 Phase context status code:  Message:\n",
      "[Container] 2023/05/24 17:17:31 Entering phase PRE_BUILD\n",
      "[Container] 2023/05/24 17:17:31 Running command echo Logging in to Amazon ECR...\n",
      "Logging in to Amazon ECR...\n",
      "\n",
      "[Container] 2023/05/24 17:17:31 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 17:17:32 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 763104351884)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 17:17:33 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 217643126080)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 17:17:33 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 727897471807)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 17:17:34 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 626614931356)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 17:17:34 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 683313688378)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 17:17:35 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 520713654638)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 17:17:36 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 462105765813)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 17:17:36 Phase complete: PRE_BUILD State: SUCCEEDED\n",
      "[Container] 2023/05/24 17:17:36 Phase context status code:  Message:\n",
      "[Container] 2023/05/24 17:17:36 Entering phase BUILD\n",
      "[Container] 2023/05/24 17:17:36 Running command echo Build started on `date`\n",
      "Build started on Wed May 24 17:17:36 UTC 2023\n",
      "\n",
      "[Container] 2023/05/24 17:17:36 Running command echo Building the Docker image...\n",
      "Building the Docker image...\n",
      "\n",
      "[Container] 2023/05/24 17:17:36 Running command docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG . --build-arg BASE_IMAGE=763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:1.10-transformers4.17-gpu-py38-cu113-ubuntu20.04\n",
      "Sending build context to Docker daemon  14.34kB\n",
      "Step 1/11 : ARG BASE_IMAGE\n",
      "Step 2/11 : FROM ${BASE_IMAGE}\n",
      "1.10-transformers4.17-gpu-py38-cu113-ubuntu20.04: Pulling from huggingface-pytorch-training\n",
      "d5fd17ec1767: Pulling fs layer\n",
      "602a45a9c0c5: Pulling fs layer\n",
      "e1bae4c1f40f: Pulling fs layer\n",
      "d9d586ab2510: Pulling fs layer\n",
      "2b44adc78060: Pulling fs layer\n",
      "730d884dbef8: Pulling fs layer\n",
      "50ad21df9a3e: Pulling fs layer\n",
      "9eafb11052ac: Pulling fs layer\n",
      "5fe87f5ae3ac: Pulling fs layer\n",
      "c8f6c9dd8923: Pulling fs layer\n",
      "31bf103fe6b3: Pulling fs layer\n",
      "562ac9a3d216: Pulling fs layer\n",
      "54fe2abe727c: Pulling fs layer\n",
      "dc7cd22e079c: Pulling fs layer\n",
      "2b44adc78060: Waiting\n",
      "d9d586ab2510: Waiting\n",
      "0eddd014f811: Pulling fs layer\n",
      "730d884dbef8: Waiting\n",
      "64f77656d17f: Pulling fs layer\n",
      "d6c570538b14: Pulling fs layer\n",
      "50ad21df9a3e: Waiting\n",
      "a533383da43a: Pulling fs layer\n",
      "35298f177473: Pulling fs layer\n",
      "9d5ee67f9f1f: Pulling fs layer\n",
      "3014f3448d61: Pulling fs layer\n",
      "31bf103fe6b3: Waiting\n",
      "9eafb11052ac: Waiting\n",
      "562ac9a3d216: Waiting\n",
      "f2be9444d784: Pulling fs layer\n",
      "a19ae770a881: Pulling fs layer\n",
      "7d260e48db29: Pulling fs layer\n",
      "d8e27c3d1895: Pulling fs layer\n",
      "5fe87f5ae3ac: Waiting\n",
      "c8f6c9dd8923: Waiting\n",
      "535794a75fce: Pulling fs layer\n",
      "54fe2abe727c: Waiting\n",
      "8818779e0684: Pulling fs layer\n",
      "d6c570538b14: Waiting\n",
      "64f77656d17f: Waiting\n",
      "abd39f77bdfc: Pulling fs layer\n",
      "0eddd014f811: Waiting\n",
      "9d5ee67f9f1f: Waiting\n",
      "dc7cd22e079c: Waiting\n",
      "a533383da43a: Waiting\n",
      "35298f177473: Waiting\n",
      "d29b5a4cfb05: Pulling fs layer\n",
      "763cd34b2834: Pulling fs layer\n",
      "989c8cbc23e4: Pulling fs layer\n",
      "3014f3448d61: Waiting\n",
      "3c5e96222af0: Pulling fs layer\n",
      "a19ae770a881: Waiting\n",
      "00161462f926: Pulling fs layer\n",
      "9d56caf04fdb: Pulling fs layer\n",
      "535794a75fce: Waiting\n",
      "7d260e48db29: Waiting\n",
      "963f539973b7: Pulling fs layer\n",
      "763cd34b2834: Waiting\n",
      "989c8cbc23e4: Waiting\n",
      "3c5e96222af0: Waiting\n",
      "9d56caf04fdb: Waiting\n",
      "7278be1128d0: Pulling fs layer\n",
      "8818779e0684: Waiting\n",
      "abd39f77bdfc: Waiting\n",
      "d8e27c3d1895: Waiting\n",
      "8cf3cf15916d: Pulling fs layer\n",
      "f2be9444d784: Waiting\n",
      "49b52e822b07: Pulling fs layer\n",
      "83a67dac4a1e: Pulling fs layer\n",
      "8cf3cf15916d: Waiting\n",
      "d5f9b62fcc5a: Pulling fs layer\n",
      "6e2956251efa: Pulling fs layer\n",
      "8b165a00ee12: Pulling fs layer\n",
      "f566c9c65b31: Pulling fs layer\n",
      "83a67dac4a1e: Waiting\n",
      "d5f9b62fcc5a: Waiting\n",
      "8932a548d301: Pulling fs layer\n",
      "8b165a00ee12: Waiting\n",
      "6e2956251efa: Waiting\n",
      "3cedeec97e56: Pulling fs layer\n",
      "392d23d51eea: Pulling fs layer\n",
      "e7e8664f7c7b: Pulling fs layer\n",
      "c29d0dc79985: Pulling fs layer\n",
      "c91e430fae61: Pulling fs layer\n",
      "5ce2e2174ce9: Pulling fs layer\n",
      "35d427b6cc06: Pulling fs layer\n",
      "392d23d51eea: Waiting\n",
      "8932a548d301: Waiting\n",
      "3cedeec97e56: Waiting\n",
      "e7e8664f7c7b: Waiting\n",
      "c29d0dc79985: Waiting\n",
      "35d427b6cc06: Waiting\n",
      "c91e430fae61: Waiting\n",
      "5ce2e2174ce9: Waiting\n",
      "963f539973b7: Waiting\n",
      "602a45a9c0c5: Verifying Checksum\n",
      "602a45a9c0c5: Download complete\n",
      "e1bae4c1f40f: Verifying Checksum\n",
      "e1bae4c1f40f: Download complete\n",
      "d9d586ab2510: Verifying Checksum\n",
      "d9d586ab2510: Download complete\n",
      "50ad21df9a3e: Verifying Checksum\n",
      "50ad21df9a3e: Download complete\n",
      "9eafb11052ac: Download complete\n",
      "d5fd17ec1767: Download complete\n",
      "730d884dbef8: Verifying Checksum\n",
      "730d884dbef8: Download complete\n",
      "31bf103fe6b3: Verifying Checksum\n",
      "31bf103fe6b3: Download complete\n",
      "562ac9a3d216: Verifying Checksum\n",
      "562ac9a3d216: Download complete\n",
      "d5fd17ec1767: Pull complete\n",
      "602a45a9c0c5: Pull complete\n",
      "e1bae4c1f40f: Pull complete\n",
      "d9d586ab2510: Pull complete\n",
      "2b44adc78060: Pull complete\n",
      "730d884dbef8: Pull complete\n",
      "50ad21df9a3e: Pull complete\n",
      "9eafb11052ac: Pull complete\n",
      "54fe2abe727c: Verifying Checksum\n",
      "54fe2abe727c: Download complete\n",
      "dc7cd22e079c: Verifying Checksum\n",
      "dc7cd22e079c: Download complete\n",
      "0eddd014f811: Verifying Checksum\n",
      "0eddd014f811: Download complete\n",
      "64f77656d17f: Verifying Checksum\n",
      "64f77656d17f: Download complete\n",
      "c8f6c9dd8923: Verifying Checksum\n",
      "c8f6c9dd8923: Download complete\n",
      "a533383da43a: Verifying Checksum\n",
      "a533383da43a: Download complete\n",
      "35298f177473: Download complete\n",
      "9d5ee67f9f1f: Verifying Checksum\n",
      "9d5ee67f9f1f: Download complete\n",
      "3014f3448d61: Download complete\n",
      "f2be9444d784: Verifying Checksum\n",
      "f2be9444d784: Download complete\n",
      "a19ae770a881: Verifying Checksum\n",
      "a19ae770a881: Download complete\n",
      "7d260e48db29: Verifying Checksum\n",
      "7d260e48db29: Download complete\n",
      "d8e27c3d1895: Verifying Checksum\n",
      "d8e27c3d1895: Download complete\n",
      "535794a75fce: Verifying Checksum\n",
      "535794a75fce: Download complete\n",
      "8818779e0684: Download complete\n",
      "abd39f77bdfc: Download complete\n",
      "d29b5a4cfb05: Verifying Checksum\n",
      "d29b5a4cfb05: Download complete\n",
      "763cd34b2834: Verifying Checksum\n",
      "763cd34b2834: Download complete\n",
      "989c8cbc23e4: Verifying Checksum\n",
      "989c8cbc23e4: Download complete\n",
      "3c5e96222af0: Verifying Checksum\n",
      "3c5e96222af0: Download complete\n",
      "00161462f926: Verifying Checksum\n",
      "00161462f926: Download complete\n",
      "9d56caf04fdb: Verifying Checksum\n",
      "9d56caf04fdb: Download complete\n",
      "963f539973b7: Download complete\n",
      "7278be1128d0: Verifying Checksum\n",
      "7278be1128d0: Download complete\n",
      "8cf3cf15916d: Verifying Checksum\n",
      "8cf3cf15916d: Download complete\n",
      "49b52e822b07: Download complete\n",
      "d6c570538b14: Verifying Checksum\n",
      "d6c570538b14: Download complete\n",
      "d5f9b62fcc5a: Verifying Checksum\n",
      "d5f9b62fcc5a: Download complete\n",
      "6e2956251efa: Download complete\n",
      "8b165a00ee12: Verifying Checksum\n",
      "8b165a00ee12: Download complete\n",
      "f566c9c65b31: Verifying Checksum\n",
      "f566c9c65b31: Download complete\n",
      "8932a548d301: Verifying Checksum\n",
      "8932a548d301: Download complete\n",
      "3cedeec97e56: Verifying Checksum\n",
      "3cedeec97e56: Download complete\n",
      "392d23d51eea: Verifying Checksum\n",
      "392d23d51eea: Download complete\n",
      "e7e8664f7c7b: Verifying Checksum\n",
      "e7e8664f7c7b: Download complete\n",
      "c29d0dc79985: Verifying Checksum\n",
      "c29d0dc79985: Download complete\n",
      "c91e430fae61: Verifying Checksum\n",
      "c91e430fae61: Download complete\n",
      "5ce2e2174ce9: Verifying Checksum\n",
      "5ce2e2174ce9: Download complete\n",
      "35d427b6cc06: Verifying Checksum\n",
      "35d427b6cc06: Download complete\n",
      "83a67dac4a1e: Verifying Checksum\n",
      "83a67dac4a1e: Download complete\n",
      "5fe87f5ae3ac: Verifying Checksum\n",
      "5fe87f5ae3ac: Download complete\n",
      "5fe87f5ae3ac: Pull complete\n",
      "c8f6c9dd8923: Pull complete\n",
      "31bf103fe6b3: Pull complete\n",
      "562ac9a3d216: Pull complete\n",
      "54fe2abe727c: Pull complete\n",
      "dc7cd22e079c: Pull complete\n",
      "0eddd014f811: Pull complete\n",
      "64f77656d17f: Pull complete\n",
      "d6c570538b14: Pull complete\n",
      "a533383da43a: Pull complete\n",
      "35298f177473: Pull complete\n",
      "9d5ee67f9f1f: Pull complete\n",
      "3014f3448d61: Pull complete\n",
      "f2be9444d784: Pull complete\n",
      "a19ae770a881: Pull complete\n",
      "7d260e48db29: Pull complete\n",
      "d8e27c3d1895: Pull complete\n",
      "535794a75fce: Pull complete\n",
      "8818779e0684: Pull complete\n",
      "abd39f77bdfc: Pull complete\n",
      "d29b5a4cfb05: Pull complete\n",
      "763cd34b2834: Pull complete\n",
      "989c8cbc23e4: Pull complete\n",
      "3c5e96222af0: Pull complete\n",
      "00161462f926: Pull complete\n",
      "9d56caf04fdb: Pull complete\n",
      "963f539973b7: Pull complete\n",
      "7278be1128d0: Pull complete\n",
      "8cf3cf15916d: Pull complete\n",
      "49b52e822b07: Pull complete\n",
      "83a67dac4a1e: Pull complete\n",
      "d5f9b62fcc5a: Pull complete\n",
      "6e2956251efa: Pull complete\n",
      "8b165a00ee12: Pull complete\n",
      "f566c9c65b31: Pull complete\n",
      "8932a548d301: Pull complete\n",
      "3cedeec97e56: Pull complete\n",
      "392d23d51eea: Pull complete\n",
      "e7e8664f7c7b: Pull complete\n",
      "c29d0dc79985: Pull complete\n",
      "c91e430fae61: Pull complete\n",
      "5ce2e2174ce9: Pull complete\n",
      "35d427b6cc06: Pull complete\n",
      "Digest: sha256:59feb63a9b7e0c60a9c3147f4acf8cfb9301f835d9c7281052f582826285a436\n",
      "Status: Downloaded newer image for 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:1.10-transformers4.17-gpu-py38-cu113-ubuntu20.04\n",
      " ---> c51c6b7cbd14\n",
      "Step 3/11 : RUN apt-get update -y && apt-get install -y --no-install-recommends build-essential gcc                                         libsndfile1\n",
      " ---> Running in 65510b96dd99\n",
      "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1581 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
      "Get:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1010 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2270 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [28.5 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2726 kB]\n",
      "Get:11 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1051 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3202 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1345 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.2 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2408 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\n",
      "Fetched 27.6 MB in 2s (12.7 MB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "gcc is already the newest version (4:9.3.0-1ubuntu2).\n",
      "gcc set to manually installed.\n",
      "build-essential is already the newest version (12.8ubuntu1.1).\n",
      "The following NEW packages will be installed:\n",
      "  libflac8 libsndfile1 libvorbisenc2\n",
      "0 upgraded, 3 newly installed, 0 to remove and 100 not upgraded.\n",
      "Need to get 344 kB of archives.\n",
      "After this operation, 1554 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libflac8 amd64 1.3.3-1ubuntu0.1 [103 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libvorbisenc2 amd64 1.3.6-2ubuntu1 [70.7 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libsndfile1 amd64 1.0.28-7ubuntu0.1 [170 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 344 kB in 1s (544 kB/s)\n",
      "Selecting previously unselected package libflac8:amd64.\n",
      "(Reading database ... 44929 files and directories currently installed.)\n",
      "Preparing to unpack .../libflac8_1.3.3-1ubuntu0.1_amd64.deb ...\n",
      "Unpacking libflac8:amd64 (1.3.3-1ubuntu0.1) ...\n",
      "Selecting previously unselected package libvorbisenc2:amd64.\n",
      "Preparing to unpack .../libvorbisenc2_1.3.6-2ubuntu1_amd64.deb ...\n",
      "Unpacking libvorbisenc2:amd64 (1.3.6-2ubuntu1) ...\n",
      "Selecting previously unselected package libsndfile1:amd64.\n",
      "Preparing to unpack .../libsndfile1_1.0.28-7ubuntu0.1_amd64.deb ...\n",
      "Unpacking libsndfile1:amd64 (1.0.28-7ubuntu0.1) ...\n",
      "Setting up libflac8:amd64 (1.3.3-1ubuntu0.1) ...\n",
      "Setting up libvorbisenc2:amd64 (1.3.6-2ubuntu1) ...\n",
      "Setting up libsndfile1:amd64 (1.0.28-7ubuntu0.1) ...\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
      "Removing intermediate container 65510b96dd99\n",
      " ---> 65c4c8a30f50\n",
      "Step 4/11 : RUN pip install SoundFile\n",
      " ---> Running in a60ac479f126\n",
      "Requirement already satisfied: SoundFile in /opt/conda/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from SoundFile) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->SoundFile) (2.21)\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container a60ac479f126\n",
      " ---> 30612d944d63\n",
      "Step 5/11 : RUN pip install librosa\n",
      " ---> Running in b6022ead369f\n",
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.8/site-packages (0.9.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.9.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from librosa) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.8/site-packages (from librosa) (0.11.0)\n",
      "Requirement already satisfied: numba>=0.45.1 in /opt/conda/lib/python3.8/site-packages (from librosa) (0.53.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /opt/conda/lib/python3.8/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.22.2)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.8/site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from numba>=0.45.1->librosa) (65.4.0)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.8/site-packages (from numba>=0.45.1->librosa) (0.36.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.12)\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container b6022ead369f\n",
      " ---> 1b573921fe72\n",
      "Step 6/11 : RUN pip install \"amazon-textract-response-parser>=0.1,<0.2\" \"Pillow>=8,<9\"     && PT_VER=`pip show torch | grep 'Version:' | sed 's/Version: //'`     && pip install git+https://github.com/facebookresearch/detectron2.git setuptools==59.5.0         torch==$PT_VER \"torchvision>=0.11.3,<0.15\" \"datasets>=2.4,<3\" \"protobuf<3.21\"         \"transformers>=4.25,<4.27\"\n",
      " ---> Running in ad21f5449a99\n",
      "Collecting amazon-textract-response-parser<0.2,>=0.1\n",
      "  Downloading amazon_textract_response_parser-0.1.46-py2.py3-none-any.whl (29 kB)\n",
      "Collecting Pillow<9,>=8\n",
      "  Downloading Pillow-8.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 114.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.8/site-packages (from amazon-textract-response-parser<0.2,>=0.1) (1.24.82)\n",
      "Collecting marshmallow<4,>=3.14\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.1/49.1 kB 15.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from marshmallow<4,>=3.14->amazon-textract-response-parser<0.2,>=0.1) (21.3)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from boto3->amazon-textract-response-parser<0.2,>=0.1) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.82 in /opt/conda/lib/python3.8/site-packages (from boto3->amazon-textract-response-parser<0.2,>=0.1) (1.27.82)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3->amazon-textract-response-parser<0.2,>=0.1) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.82->boto3->amazon-textract-response-parser<0.2,>=0.1) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.28.0,>=1.27.82->boto3->amazon-textract-response-parser<0.2,>=0.1) (1.26.12)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=17.0->marshmallow<4,>=3.14->amazon-textract-response-parser<0.2,>=0.1) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.82->boto3->amazon-textract-response-parser<0.2,>=0.1) (1.16.0)\n",
      "Installing collected packages: Pillow, marshmallow, amazon-textract-response-parser\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.2.0\n",
      "    Uninstalling Pillow-9.2.0:\n",
      "      Successfully uninstalled Pillow-9.2.0\n",
      "Successfully installed Pillow-8.4.0 amazon-textract-response-parser-0.1.46 marshmallow-3.19.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mCollecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-2pdn69u0\n",
      "\u001b[91m  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-2pdn69u0\n",
      "\u001b[0m  Resolved https://github.com/facebookresearch/detectron2.git to commit 3c7bb714795edc7a96c9a1a6dd83663ecd293e36\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting setuptools==59.5.0\n",
      "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 952.4/952.4 kB 62.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch==1.10.2+cu113 in /opt/conda/lib/python3.8/site-packages (1.10.2+cu113)\n",
      "Requirement already satisfied: torchvision<0.15,>=0.11.3 in /opt/conda/lib/python3.8/site-packages (0.11.3)\n",
      "Collecting datasets<3,>=2.4\n",
      "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 474.6/474.6 kB 70.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf<3.21 in /opt/conda/lib/python3.8/site-packages (3.19.5)\n",
      "Collecting transformers<4.27,>=4.25\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 112.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch==1.10.2+cu113) (4.3.0)\n",
      "Requirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (3.6.0)\n",
      "Collecting pycocotools>=2.0.2\n",
      "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting termcolor>=1.1\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting yacs>=0.1.8\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (0.8.10)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (2.2.0)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (4.64.0)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 119.9 MB/s eta 0:00:00\n",
      "Collecting fvcore<0.1.6,>=0.1.5\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.2/50.2 kB 17.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting iopath<0.1.10,>=0.1.7\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
      "Collecting omegaconf>=2.1\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 kB 27.5 MB/s eta 0:00:00\n",
      "Collecting hydra-core>=1.1\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 154.5/154.5 kB 42.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: black in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (22.8.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (21.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision<0.15,>=0.11.3) (1.22.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets<3,>=2.4) (1.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets<3,>=2.4) (3.8.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets<3,>=2.4) (2.28.1)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.8/site-packages (from datasets<3,>=2.4) (0.18.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets<3,>=2.4) (0.3.5.1)\n",
      "Collecting huggingface-hub<1.0.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 224.5/224.5 kB 53.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets<3,>=2.4) (0.70.13)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets<3,>=2.4) (3.0.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.8/site-packages (from datasets<3,>=2.4) (2022.8.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from datasets<3,>=2.4) (5.4.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets<3,>=2.4) (9.0.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers<4.27,>=4.25) (0.13.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers<4.27,>=4.25) (2022.9.13)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers<4.27,>=4.25) (3.8.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets<3,>=2.4) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets<3,>=2.4) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets<3,>=2.4) (1.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets<3,>=2.4) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets<3,>=2.4) (2.0.12)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets<3,>=2.4) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets<3,>=2.4) (1.8.1)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.8/site-packages (from hydra-core>=1.1->detectron2==0.6) (5.9.0)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 kB 42.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->detectron2==0.6) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (4.37.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (1.0.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets<3,>=2.4) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets<3,>=2.4) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets<3,>=2.4) (2022.9.24)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from black->detectron2==0.6) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from black->detectron2==0.6) (8.1.3)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.8/site-packages (from black->detectron2==0.6) (2.5.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.8/site-packages (from black->detectron2==0.6) (0.4.3)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from black->detectron2==0.6) (0.10.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets<3,>=2.4) (2022.2.1)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.54.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 137.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (0.37.1)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 39.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (2.2.2)\n",
      "Collecting protobuf<3.21\n",
      "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 111.1 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.18.1-py2.py3-none-any.whl (178 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 178.9/178.9 kB 47.3 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.9/93.9 kB 31.4 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 132.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.7.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.16.0)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 53.9 MB/s eta 0:00:00\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (4.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources->hydra-core>=1.1->detectron2==0.6) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 45.1 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime, pycocotools\n",
      "  Building wheel for detectron2 (setup.py): started\n",
      "  Building wheel for detectron2 (setup.py): finished with status 'done'\n",
      "  Created wheel for detectron2: filename=detectron2-0.6-cp38-cp38-linux_x86_64.whl size=890278 sha256=97c588e3f371cf8a4308e5cf0e170c7a4e1f849545640f2de9d4c9ee8ee241ee\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-ii4q2ene/wheels/19/ac/65/e48e5e4ec2702274d927c5a6efb75709b24014371d3bb778f2\n",
      "  Building wheel for fvcore (setup.py): started\n",
      "  Building wheel for fvcore (setup.py): finished with status 'done'\n",
      "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61406 sha256=90f22a87340636a1ac6dd946a394458f882ca0cade8a7a80f9c2ece894315acb\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=3654d85efebb22176e6fcb1299fae0e4495ee805c152a21adc64c8b7a0c2be82\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
      "  Building wheel for pycocotools (pyproject.toml): started\n",
      "  Building wheel for pycocotools (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp38-cp38-linux_x86_64.whl size=105340 sha256=4958cecdc9ca695191567ab6de00c0e06d20133437d4e25a0594570aae7e3188\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/08/ac/58126fe59992032701437336493f6132e1b72381a62d00b595\n",
      "Successfully built detectron2 fvcore antlr4-python3-runtime pycocotools\n",
      "Installing collected packages: antlr4-python3-runtime, yacs, termcolor, tensorboard-data-server, setuptools, pyasn1-modules, protobuf, portalocker, omegaconf, oauthlib, grpcio, cachetools, absl-py, requests-oauthlib, markdown, iopath, hydra-core, huggingface-hub, google-auth, transformers, pycocotools, google-auth-oauthlib, fvcore, tensorboard, datasets, detectron2\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.4.0\n",
      "    Uninstalling setuptools-65.4.0:\n",
      "      Successfully uninstalled setuptools-65.4.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.5\n",
      "    Uninstalling protobuf-3.19.5:\n",
      "      Successfully uninstalled protobuf-3.19.5\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.10.0\n",
      "    Uninstalling huggingface-hub-0.10.0:\n",
      "      Successfully uninstalled huggingface-hub-0.10.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.17.0\n",
      "    Uninstalling transformers-4.17.0:\n",
      "      Successfully uninstalled transformers-4.17.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 1.18.4\n",
      "    Uninstalling datasets-1.18.4:\n",
      "      Successfully uninstalled datasets-1.18.4\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sagemaker-training 4.2.9 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "smdebug 1.0.22b20220929 requires protobuf<=3.20.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 antlr4-python3-runtime-4.9.3 cachetools-5.3.0 datasets-2.12.0 detectron2-0.6 fvcore-0.1.5.post20221221 google-auth-2.18.1 google-auth-oauthlib-1.0.0 grpcio-1.54.2 huggingface-hub-0.14.1 hydra-core-1.3.2 iopath-0.1.9 markdown-3.4.3 oauthlib-3.2.2 omegaconf-2.3.0 portalocker-2.7.0 protobuf-3.20.3 pyasn1-modules-0.3.0 pycocotools-2.0.6 requests-oauthlib-1.3.1 setuptools-59.5.0 tensorboard-2.13.0 tensorboard-data-server-0.7.0 termcolor-2.3.0 transformers-4.26.1 yacs-0.1.8\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container ad21f5449a99\n",
      " ---> c3cf0acc4a9d\n",
      "Step 7/11 : RUN PT_VER=`pip show torch | grep 'Version:' | sed 's/Version: //'`     && pip install pytesseract torch==$PT_VER\n",
      " ---> Running in 19118bbb0a5f\n",
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: torch==1.10.2+cu113 in /opt/conda/lib/python3.8/site-packages (1.10.2+cu113)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch==1.10.2+cu113) (4.3.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.8/site-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from pytesseract) (8.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.10\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container 19118bbb0a5f\n",
      " ---> cc98cc67c074\n",
      "Step 8/11 : ARG INCLUDE_NOTEBOOK_KERNEL\n",
      " ---> Running in 640229a395a5\n",
      "Removing intermediate container 640229a395a5\n",
      " ---> 5ba3fa97a611\n",
      "Step 9/11 : RUN if test -z \"$INCLUDE_NOTEBOOK_KERNEL\" ;     then         echo Skipping notebook kernel dependencies     ; else         conda install -y -c conda-forge poppler tesseract &&         PT_VER=`pip show torch | grep 'Version:' | sed 's/Version: //'` &&         pip install easyocr ipykernel \"ipywidgets>=7,<8\" pdf2image pytesseract sagemaker             torch==$PT_VER &&         export TESSDATA_PREFIX='/opt/conda/share/tessdata' &&         python -m ipykernel install --sys-prefix     ; fi\n",
      " ---> Running in c3ef8d2db80b\n",
      "Skipping notebook kernel dependencies\n",
      "Removing intermediate container c3ef8d2db80b\n",
      " ---> e3bad89f19c1\n",
      "Step 10/11 : ENV USE_SMDEBUG=${INCLUDE_NOTEBOOK_KERNEL:+false}\n",
      " ---> Running in c2ff88867735\n",
      "Removing intermediate container c2ff88867735\n",
      " ---> f82ab47c3be3\n",
      "Step 11/11 : ENV USE_SMDEBUG=${USE_SMDEBUG:-true}\n",
      " ---> Running in d510f1166fe9\n",
      "Removing intermediate container d510f1166fe9\n",
      " ---> 25d2da08e255\n",
      "Successfully built 25d2da08e255\n",
      "Successfully tagged sm-ocr-training:hf-4.26-pt-gpu\n",
      "\n",
      "[Container] 2023/05/24 17:23:48 Running command docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "\n",
      "[Container] 2023/05/24 17:23:49 Phase complete: BUILD State: SUCCEEDED\n",
      "[Container] 2023/05/24 17:23:49 Phase context status code:  Message:\n",
      "[Container] 2023/05/24 17:23:49 Entering phase POST_BUILD\n",
      "[Container] 2023/05/24 17:23:49 Running command echo Build completed on `date`\n",
      "Build completed on Wed May 24 17:23:49 UTC 2023\n",
      "\n",
      "[Container] 2023/05/24 17:23:49 Running command echo Pushing the Docker image...\n",
      "Pushing the Docker image...\n",
      "\n",
      "[Container] 2023/05/24 17:23:49 Running command docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "The push refers to repository [015943506230.dkr.ecr.us-east-1.amazonaws.com/sm-ocr-training]\n",
      "1085662b703b: Preparing\n",
      "f89bccba45ef: Preparing\n",
      "ac227759051e: Preparing\n",
      "0e5415e5104c: Preparing\n",
      "091fd13f0f4a: Preparing\n",
      "33e1d370ef6f: Preparing\n",
      "a211db39931f: Preparing\n",
      "6f7979972917: Preparing\n",
      "0c2c96f19e7e: Preparing\n",
      "950537c911fb: Preparing\n",
      "ae4dbdaf0a42: Preparing\n",
      "a8314fdb7a9a: Preparing\n",
      "af46be8fe5b3: Preparing\n",
      "729f955cd7b6: Preparing\n",
      "9d2e456c4838: Preparing\n",
      "f1cef918b34b: Preparing\n",
      "bedf69f2a960: Preparing\n",
      "3d98fc0e4180: Preparing\n",
      "13287adca40d: Preparing\n",
      "da474668a1da: Preparing\n",
      "f151d62068aa: Preparing\n",
      "37a2fa00b4b5: Preparing\n",
      "07dd9026be78: Preparing\n",
      "a211db39931f: Waiting\n",
      "724832325ffe: Preparing\n",
      "729f955cd7b6: Waiting\n",
      "8cfa8ed5996e: Preparing\n",
      "6f7979972917: Waiting\n",
      "6991eda8000e: Preparing\n",
      "a8314fdb7a9a: Waiting\n",
      "75b7d929d919: Preparing\n",
      "0db32f284644: Preparing\n",
      "cc0318edd61c: Preparing\n",
      "af46be8fe5b3: Waiting\n",
      "151b234befb4: Preparing\n",
      "84cb160c6565: Preparing\n",
      "0c2c96f19e7e: Waiting\n",
      "b3b6ce9a03e1: Preparing\n",
      "950537c911fb: Waiting\n",
      "8b7b3ac71c19: Preparing\n",
      "65554af8799a: Preparing\n",
      "efb35d06e22a: Preparing\n",
      "770ea2bf418f: Preparing\n",
      "bedf69f2a960: Waiting\n",
      "aabc5635ad79: Preparing\n",
      "f1cef918b34b: Waiting\n",
      "3d98fc0e4180: Waiting\n",
      "21ff56507102: Preparing\n",
      "13287adca40d: Waiting\n",
      "209e9c00089a: Preparing\n",
      "ae4dbdaf0a42: Waiting\n",
      "0f2e9049a095: Preparing\n",
      "0fba11f2e9f4: Preparing\n",
      "f151d62068aa: Waiting\n",
      "60afc926faef: Preparing\n",
      "1b385db6ff56: Preparing\n",
      "37a2fa00b4b5: Waiting\n",
      "4998a58b44cd: Preparing\n",
      "07dd9026be78: Waiting\n",
      "bd232184a32a: Preparing\n",
      "61d1e896198b: Preparing\n",
      "724832325ffe: Waiting\n",
      "5419752ac5f2: Preparing\n",
      "79c61687bb4a: Preparing\n",
      "e0fc66b168a8: Preparing\n",
      "8cfa8ed5996e: Waiting\n",
      "f15b265376bf: Preparing\n",
      "6991eda8000e: Waiting\n",
      "b8262d5200e5: Preparing\n",
      "e592fe6d10a9: Preparing\n",
      "75b7d929d919: Waiting\n",
      "f42691182163: Preparing\n",
      "68016c5bb65c: Preparing\n",
      "0db32f284644: Waiting\n",
      "8034550a3bbe: Preparing\n",
      "bf8cedc62fb3: Preparing\n",
      "cc0318edd61c: Waiting\n",
      "151b234befb4: Waiting\n",
      "33e1d370ef6f: Waiting\n",
      "4998a58b44cd: Waiting\n",
      "21ff56507102: Waiting\n",
      "60afc926faef: Waiting\n",
      "b8262d5200e5: Waiting\n",
      "bd232184a32a: Waiting\n",
      "1b385db6ff56: Waiting\n",
      "84cb160c6565: Waiting\n",
      "209e9c00089a: Waiting\n",
      "e592fe6d10a9: Waiting\n",
      "0f2e9049a095: Waiting\n",
      "b3b6ce9a03e1: Waiting\n",
      "e0fc66b168a8: Waiting\n",
      "8b7b3ac71c19: Waiting\n",
      "efb35d06e22a: Waiting\n",
      "770ea2bf418f: Waiting\n",
      "5419752ac5f2: Waiting\n",
      "65554af8799a: Waiting\n",
      "aabc5635ad79: Waiting\n",
      "79c61687bb4a: Waiting\n",
      "f42691182163: Waiting\n",
      "bf8cedc62fb3: Waiting\n",
      "68016c5bb65c: Waiting\n",
      "8034550a3bbe: Waiting\n",
      "f15b265376bf: Waiting\n",
      "0e5415e5104c: Pushed\n",
      "1085662b703b: Pushed\n",
      "33e1d370ef6f: Layer already exists\n",
      "ac227759051e: Pushed\n",
      "a211db39931f: Layer already exists\n",
      "6f7979972917: Layer already exists\n",
      "0c2c96f19e7e: Layer already exists\n",
      "950537c911fb: Layer already exists\n",
      "ae4dbdaf0a42: Layer already exists\n",
      "a8314fdb7a9a: Layer already exists\n",
      "af46be8fe5b3: Layer already exists\n",
      "729f955cd7b6: Layer already exists\n",
      "9d2e456c4838: Layer already exists\n",
      "f1cef918b34b: Layer already exists\n",
      "bedf69f2a960: Layer already exists\n",
      "3d98fc0e4180: Layer already exists\n",
      "13287adca40d: Layer already exists\n",
      "da474668a1da: Layer already exists\n",
      "f151d62068aa: Layer already exists\n",
      "37a2fa00b4b5: Layer already exists\n",
      "07dd9026be78: Layer already exists\n",
      "724832325ffe: Layer already exists\n",
      "8cfa8ed5996e: Layer already exists\n",
      "6991eda8000e: Layer already exists\n",
      "75b7d929d919: Layer already exists\n",
      "0db32f284644: Layer already exists\n",
      "cc0318edd61c: Layer already exists\n",
      "84cb160c6565: Layer already exists\n",
      "151b234befb4: Layer already exists\n",
      "b3b6ce9a03e1: Layer already exists\n",
      "65554af8799a: Layer already exists\n",
      "8b7b3ac71c19: Layer already exists\n",
      "770ea2bf418f: Layer already exists\n",
      "efb35d06e22a: Layer already exists\n",
      "aabc5635ad79: Layer already exists\n",
      "21ff56507102: Layer already exists\n",
      "209e9c00089a: Layer already exists\n",
      "0f2e9049a095: Layer already exists\n",
      "0fba11f2e9f4: Layer already exists\n",
      "60afc926faef: Layer already exists\n",
      "1b385db6ff56: Layer already exists\n",
      "4998a58b44cd: Layer already exists\n",
      "bd232184a32a: Layer already exists\n",
      "61d1e896198b: Layer already exists\n",
      "5419752ac5f2: Layer already exists\n",
      "79c61687bb4a: Layer already exists\n",
      "e0fc66b168a8: Layer already exists\n",
      "f15b265376bf: Layer already exists\n",
      "b8262d5200e5: Layer already exists\n",
      "e592fe6d10a9: Layer already exists\n",
      "f42691182163: Layer already exists\n",
      "68016c5bb65c: Layer already exists\n",
      "8034550a3bbe: Layer already exists\n",
      "bf8cedc62fb3: Layer already exists\n",
      "\n",
      "091fd13f0f4a: Pushed\n",
      "f89bccba45ef: Pushed\n",
      "hf-4.26-pt-gpu: digest: sha256:a3772eed2368b135630438e5e22e486c28859639232f286250e27e6c6fd593fe size: 12097\n",
      "\n",
      "[Container] 2023/05/24 17:23:58 Phase complete: POST_BUILD State: SUCCEEDED\n",
      "[Container] 2023/05/24 17:23:58 Phase context status code:  Message:\n",
      "Image URI: 015943506230.dkr.ecr.us-east-1.amazonaws.com/sm-ocr-training:hf-4.26-pt-gpu\n",
      "CPU times: user 7.95 s, sys: 1.54 s, total: 9.49 s\n",
      "Wall time: 8min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# (No need to re-run this cell if your train image is already in ECR)\n",
    "\n",
    "# Build and push the training image:\n",
    "!cd custom-containers/train-inf && sm-docker build . \\\n",
    "    --compute-type BUILD_GENERAL1_LARGE \\\n",
    "    --repository {train_repo_name}:{train_repo_tag} \\\n",
    "    --role {config.sm_image_build_role} \\\n",
    "    --build-arg BASE_IMAGE={train_base_uri}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4bb843-284e-4b9e-b322-59c2ec98afff",
   "metadata": {},
   "source": [
    "Note that although our training and inference containers use the [same Dockerfile](custom-containers/train-inf/Dockerfile), they're built from different parent images so both are needed in ECR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f6fd214-1739-4dc0-a14f-6702f5a9ecb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............[Container] 2023/05/24 15:52:47 Waiting for agent ping\n",
      "\n",
      "[Container] 2023/05/24 15:52:50 Waiting for DOWNLOAD_SOURCE\n",
      "[Container] 2023/05/24 15:52:53 Phase is DOWNLOAD_SOURCE\n",
      "[Container] 2023/05/24 15:52:53 CODEBUILD_SRC_DIR=/codebuild/output/src459522155/src\n",
      "[Container] 2023/05/24 15:52:53 YAML location is /codebuild/output/src459522155/src/buildspec.yml\n",
      "[Container] 2023/05/24 15:52:53 Setting HTTP client timeout to higher timeout for S3 source\n",
      "[Container] 2023/05/24 15:52:53 Processing environment variables\n",
      "[Container] 2023/05/24 15:52:53 No runtime version selected in buildspec.\n",
      "[Container] 2023/05/24 15:52:53 Moving to directory /codebuild/output/src459522155/src\n",
      "[Container] 2023/05/24 15:52:53 Configuring ssm agent with target id: codebuild:ef6931f4-24d9-49ae-9bfa-381b019e8a91\n",
      "[Container] 2023/05/24 15:52:53 Successfully updated ssm agent configuration\n",
      "[Container] 2023/05/24 15:52:53 Registering with agent\n",
      "[Container] 2023/05/24 15:52:53 Phases found in YAML: 3\n",
      "[Container] 2023/05/24 15:52:53  PRE_BUILD: 9 commands\n",
      "[Container] 2023/05/24 15:52:53  BUILD: 4 commands\n",
      "[Container] 2023/05/24 15:52:53  POST_BUILD: 3 commands\n",
      "[Container] 2023/05/24 15:52:53 Phase complete: DOWNLOAD_SOURCE State: SUCCEEDED\n",
      "[Container] 2023/05/24 15:52:53 Phase context status code:  Message:\n",
      "[Container] 2023/05/24 15:52:53 Entering phase INSTALL\n",
      "[Container] 2023/05/24 15:52:53 Phase complete: INSTALL State: SUCCEEDED\n",
      "[Container] 2023/05/24 15:52:53 Phase context status code:  Message:\n",
      "[Container] 2023/05/24 15:52:53 Entering phase PRE_BUILD\n",
      "[Container] 2023/05/24 15:52:53 Running command echo Logging in to Amazon ECR...\n",
      "Logging in to Amazon ECR...\n",
      "\n",
      "[Container] 2023/05/24 15:52:53 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 15:52:54 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 763104351884)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 15:52:54 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 217643126080)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 15:52:55 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 727897471807)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 15:52:55 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 626614931356)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 15:52:56 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 683313688378)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 15:52:56 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 520713654638)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 15:52:57 Running command $(aws ecr get-login --no-include-email --region $AWS_DEFAULT_REGION --registry-ids 462105765813)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /root/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "[Container] 2023/05/24 15:52:57 Phase complete: PRE_BUILD State: SUCCEEDED\n",
      "[Container] 2023/05/24 15:52:57 Phase context status code:  Message:\n",
      "[Container] 2023/05/24 15:52:57 Entering phase BUILD\n",
      "[Container] 2023/05/24 15:52:57 Running command echo Build started on `date`\n",
      "Build started on Wed May 24 15:52:57 UTC 2023\n",
      "\n",
      "[Container] 2023/05/24 15:52:57 Running command echo Building the Docker image...\n",
      "Building the Docker image...\n",
      "\n",
      "[Container] 2023/05/24 15:52:57 Running command docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG . --build-arg BASE_IMAGE=763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.10-transformers4.17-gpu-py38-cu113-ubuntu20.04\n",
      "Sending build context to Docker daemon  14.34kB\n",
      "Step 1/11 : ARG BASE_IMAGE\n",
      "Step 2/11 : FROM ${BASE_IMAGE}\n",
      "1.10-transformers4.17-gpu-py38-cu113-ubuntu20.04: Pulling from huggingface-pytorch-inference\n",
      "d5fd17ec1767: Pulling fs layer\n",
      "602a45a9c0c5: Pulling fs layer\n",
      "e1bae4c1f40f: Pulling fs layer\n",
      "d9d586ab2510: Pulling fs layer\n",
      "2b44adc78060: Pulling fs layer\n",
      "4661d2000a2b: Pulling fs layer\n",
      "35df3dae375c: Pulling fs layer\n",
      "251b562af5ee: Pulling fs layer\n",
      "4777f9177f23: Pulling fs layer\n",
      "13aee822afa1: Pulling fs layer\n",
      "05d325eb80b4: Pulling fs layer\n",
      "7db49f926d6d: Pulling fs layer\n",
      "d9d586ab2510: Waiting\n",
      "d03f7b84fec8: Pulling fs layer\n",
      "2b44adc78060: Waiting\n",
      "4661d2000a2b: Waiting\n",
      "14576d6c5f79: Pulling fs layer\n",
      "349de6509daa: Pulling fs layer\n",
      "35df3dae375c: Waiting\n",
      "0c8e79862051: Pulling fs layer\n",
      "251b562af5ee: Waiting\n",
      "590505fcb4db: Pulling fs layer\n",
      "13aee822afa1: Waiting\n",
      "4777f9177f23: Waiting\n",
      "746149b30c68: Pulling fs layer\n",
      "aa08096ce9d7: Pulling fs layer\n",
      "bc5ed5ce5bd2: Pulling fs layer\n",
      "0f7c567c85bd: Pulling fs layer\n",
      "05d325eb80b4: Waiting\n",
      "7db49f926d6d: Waiting\n",
      "b8b80bf3671c: Pulling fs layer\n",
      "d03f7b84fec8: Waiting\n",
      "349de6509daa: Waiting\n",
      "14576d6c5f79: Waiting\n",
      "ea7db7615731: Pulling fs layer\n",
      "0c8e79862051: Waiting\n",
      "65a9027471c2: Pulling fs layer\n",
      "2b47564ffeba: Pulling fs layer\n",
      "590505fcb4db: Waiting\n",
      "1256480abccc: Pulling fs layer\n",
      "aa08096ce9d7: Waiting\n",
      "ea7db7615731: Waiting\n",
      "0f7c567c85bd: Waiting\n",
      "65a9027471c2: Waiting\n",
      "2b47564ffeba: Waiting\n",
      "746149b30c68: Waiting\n",
      "b8b80bf3671c: Waiting\n",
      "602a45a9c0c5: Verifying Checksum\n",
      "602a45a9c0c5: Download complete\n",
      "e1bae4c1f40f: Verifying Checksum\n",
      "e1bae4c1f40f: Download complete\n",
      "d9d586ab2510: Verifying Checksum\n",
      "d9d586ab2510: Download complete\n",
      "2b44adc78060: Download complete\n",
      "d5fd17ec1767: Verifying Checksum\n",
      "d5fd17ec1767: Download complete\n",
      "4661d2000a2b: Verifying Checksum\n",
      "4661d2000a2b: Download complete\n",
      "d5fd17ec1767: Pull complete\n",
      "602a45a9c0c5: Pull complete\n",
      "e1bae4c1f40f: Pull complete\n",
      "d9d586ab2510: Pull complete\n",
      "2b44adc78060: Pull complete\n",
      "4661d2000a2b: Pull complete\n",
      "4777f9177f23: Verifying Checksum\n",
      "4777f9177f23: Download complete\n",
      "13aee822afa1: Verifying Checksum\n",
      "13aee822afa1: Download complete\n",
      "05d325eb80b4: Verifying Checksum\n",
      "05d325eb80b4: Download complete\n",
      "7db49f926d6d: Verifying Checksum\n",
      "7db49f926d6d: Download complete\n",
      "d03f7b84fec8: Download complete\n",
      "251b562af5ee: Verifying Checksum\n",
      "251b562af5ee: Download complete\n",
      "349de6509daa: Download complete\n",
      "0c8e79862051: Download complete\n",
      "590505fcb4db: Download complete\n",
      "746149b30c68: Download complete\n",
      "aa08096ce9d7: Verifying Checksum\n",
      "aa08096ce9d7: Download complete\n",
      "14576d6c5f79: Verifying Checksum\n",
      "14576d6c5f79: Download complete\n",
      "bc5ed5ce5bd2: Verifying Checksum\n",
      "bc5ed5ce5bd2: Download complete\n",
      "0f7c567c85bd: Verifying Checksum\n",
      "0f7c567c85bd: Download complete\n",
      "b8b80bf3671c: Verifying Checksum\n",
      "b8b80bf3671c: Download complete\n",
      "65a9027471c2: Verifying Checksum\n",
      "65a9027471c2: Download complete\n",
      "2b47564ffeba: Verifying Checksum\n",
      "2b47564ffeba: Download complete\n",
      "1256480abccc: Verifying Checksum\n",
      "1256480abccc: Download complete\n",
      "ea7db7615731: Verifying Checksum\n",
      "ea7db7615731: Download complete\n",
      "35df3dae375c: Verifying Checksum\n",
      "35df3dae375c: Download complete\n",
      "35df3dae375c: Pull complete\n",
      "251b562af5ee: Pull complete\n",
      "4777f9177f23: Pull complete\n",
      "13aee822afa1: Pull complete\n",
      "05d325eb80b4: Pull complete\n",
      "7db49f926d6d: Pull complete\n",
      "d03f7b84fec8: Pull complete\n",
      "14576d6c5f79: Pull complete\n",
      "349de6509daa: Pull complete\n",
      "0c8e79862051: Pull complete\n",
      "590505fcb4db: Pull complete\n",
      "746149b30c68: Pull complete\n",
      "aa08096ce9d7: Pull complete\n",
      "bc5ed5ce5bd2: Pull complete\n",
      "0f7c567c85bd: Pull complete\n",
      "b8b80bf3671c: Pull complete\n",
      "ea7db7615731: Pull complete\n",
      "65a9027471c2: Pull complete\n",
      "2b47564ffeba: Pull complete\n",
      "1256480abccc: Pull complete\n",
      "Digest: sha256:17e776fd3295cc6dfee4e122618f5bab7ef04e87ed0490ce6b64722a60f03333\n",
      "Status: Downloaded newer image for 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.10-transformers4.17-gpu-py38-cu113-ubuntu20.04\n",
      " ---> 27b277000343\n",
      "Step 3/11 : RUN apt-get update -y && apt-get install -y --no-install-recommends build-essential gcc                                         libsndfile1\n",
      " ---> Running in 1fda3c144ff2\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1581 B]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:5 http://ppa.launchpad.net/openjdk-r/ppa/ubuntu focal InRelease [23.8 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1010 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.2 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2408 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1345 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3202 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
      "Get:18 http://ppa.launchpad.net/openjdk-r/ppa/ubuntu focal/main amd64 Packages [16.5 kB]\n",
      "Get:19 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2270 kB]\n",
      "Get:20 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1051 kB]\n",
      "Get:21 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2726 kB]\n",
      "Get:22 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [28.5 kB]\n",
      "Fetched 27.6 MB in 5s (5895 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "gcc is already the newest version (4:9.3.0-1ubuntu2).\n",
      "gcc set to manually installed.\n",
      "build-essential is already the newest version (12.8ubuntu1.1).\n",
      "libsndfile1 is already the newest version (1.0.28-7ubuntu0.1).\n",
      "libsndfile1 set to manually installed.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 106 not upgraded.\n",
      "Removing intermediate container 1fda3c144ff2\n",
      " ---> f7acc94353d5\n",
      "Step 4/11 : RUN pip install SoundFile\n",
      " ---> Running in 23875a529f65\n",
      "Requirement already satisfied: SoundFile in /opt/conda/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from SoundFile) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->SoundFile) (2.21)\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container 23875a529f65\n",
      " ---> 4068e4953020\n",
      "Step 5/11 : RUN pip install librosa\n",
      " ---> Running in fe6c20ff2ee6\n",
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.8/site-packages (0.9.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.2.0)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /opt/conda/lib/python3.8/site-packages (from librosa) (0.11.0)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.9.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: numba>=0.45.1 in /opt/conda/lib/python3.8/site-packages (from librosa) (0.56.2)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.8/site-packages (from librosa) (3.0.0)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /opt/conda/lib/python3.8/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from librosa) (0.4.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.23.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.8/site-packages (from numba>=0.45.1->librosa) (5.0.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /opt/conda/lib/python3.8/site-packages (from numba>=0.45.1->librosa) (0.39.1)\n",
      "Requirement already satisfied: setuptools<60 in /opt/conda/lib/python3.8/site-packages (from numba>=0.45.1->librosa) (59.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->librosa) (3.0.9)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa) (2.28.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.12)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata->numba>=0.45.1->librosa) (3.8.1)\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container fe6c20ff2ee6\n",
      " ---> 7e3f3f26ad43\n",
      "Step 6/11 : RUN pip install \"amazon-textract-response-parser>=0.1,<0.2\" \"Pillow>=8,<9\"     && PT_VER=`pip show torch | grep 'Version:' | sed 's/Version: //'`     && pip install git+https://github.com/facebookresearch/detectron2.git setuptools==59.5.0         torch==$PT_VER \"torchvision>=0.11.3,<0.15\" \"datasets>=2.4,<3\" \"protobuf<3.21\"         \"transformers>=4.25,<4.27\"\n",
      " ---> Running in 18bb735e6172\n",
      "Collecting amazon-textract-response-parser<0.2,>=0.1\n",
      "  Downloading amazon_textract_response_parser-0.1.46-py2.py3-none-any.whl (29 kB)\n",
      "Collecting Pillow<9,>=8\n",
      "  Downloading Pillow-8.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 105.6 MB/s eta 0:00:00\n",
      "Collecting marshmallow<4,>=3.14\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.1/49.1 kB 14.8 MB/s eta 0:00:00\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.26.139-py3-none-any.whl (135 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 34.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from marshmallow<4,>=3.14->amazon-textract-response-parser<0.2,>=0.1) (21.3)\n",
      "Collecting botocore<1.30.0,>=1.29.139\n",
      "  Downloading botocore-1.29.139-py3-none-any.whl (10.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.8/10.8 MB 113.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3->amazon-textract-response-parser<0.2,>=0.1) (1.0.1)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.8/79.8 kB 24.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.8/site-packages (from botocore<1.30.0,>=1.29.139->boto3->amazon-textract-response-parser<0.2,>=0.1) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.30.0,>=1.29.139->boto3->amazon-textract-response-parser<0.2,>=0.1) (1.26.11)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=17.0->marshmallow<4,>=3.14->amazon-textract-response-parser<0.2,>=0.1) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.139->boto3->amazon-textract-response-parser<0.2,>=0.1) (1.16.0)\n",
      "Installing collected packages: Pillow, marshmallow, botocore, s3transfer, boto3, amazon-textract-response-parser\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.2.0\n",
      "    Uninstalling Pillow-9.2.0:\n",
      "      Successfully uninstalled Pillow-9.2.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.27.84\n",
      "    Uninstalling botocore-1.27.84:\n",
      "      Successfully uninstalled botocore-1.27.84\n",
      "Successfully installed Pillow-8.4.0 amazon-textract-response-parser-0.1.46 boto3-1.26.139 botocore-1.29.139 marshmallow-3.19.0 s3transfer-0.6.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mCollecting git+https://github.com/facebookresearch/detectron2.git\n",
      "  Cloning https://github.com/facebookresearch/detectron2.git to /home/model-server/tmp/pip-req-build-z8r2tl13\n",
      "\u001b[91m  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /home/model-server/tmp/pip-req-build-z8r2tl13\n",
      "\u001b[0m  Resolved https://github.com/facebookresearch/detectron2.git to commit 3c7bb714795edc7a96c9a1a6dd83663ecd293e36\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting setuptools==59.5.0\n",
      "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 952.4/952.4 kB 44.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: torch==1.10.2+cu113 in /opt/conda/lib/python3.8/site-packages (1.10.2+cu113)\n",
      "Collecting torchvision<0.15,>=0.11.3\n",
      "  Downloading torchvision-0.14.1-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.2/24.2 MB 73.7 MB/s eta 0:00:00\n",
      "Collecting datasets<3,>=2.4\n",
      "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 474.6/474.6 kB 78.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf<3.21 in /opt/conda/lib/python3.8/site-packages (3.19.6)\n",
      "Collecting transformers<4.27,>=4.25\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.3/6.3 MB 123.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch==1.10.2+cu113) (4.3.0)\n",
      "Requirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (8.4.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.2/9.2 MB 121.7 MB/s eta 0:00:00\n",
      "Collecting pycocotools>=2.0.2\n",
      "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting termcolor>=1.1\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting yacs>=0.1.8\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (0.8.10)\n",
      "Collecting cloudpickle\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (4.64.1)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 132.7 MB/s eta 0:00:00\n",
      "Collecting fvcore<0.1.6,>=0.1.5\n",
      "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 50.2/50.2 kB 15.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting iopath<0.1.10,>=0.1.7\n",
      "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
      "Collecting omegaconf>=2.1\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 kB 24.4 MB/s eta 0:00:00\n",
      "Collecting hydra-core>=1.1\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 154.5/154.5 kB 41.9 MB/s eta 0:00:00\n",
      "Collecting black\n",
      "  Downloading black-23.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 116.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from detectron2==0.6) (21.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision<0.15,>=0.11.3) (1.23.3)\n",
      "Collecting torchvision<0.15,>=0.11.3\n",
      "  Downloading torchvision-0.14.0-cp38-cp38-manylinux1_x86_64.whl (24.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.3/24.3 MB 63.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from torchvision<0.15,>=0.11.3) (2.28.1)\n",
      "  Downloading torchvision-0.13.1-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.1/19.1 MB 74.0 MB/s eta 0:00:00\n",
      "  Downloading torchvision-0.13.0-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.1/19.1 MB 90.7 MB/s eta 0:00:00\n",
      "  Downloading torchvision-0.12.0-cp38-cp38-manylinux1_x86_64.whl (21.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.0/21.0 MB 100.4 MB/s eta 0:00:00\n",
      "  Downloading torchvision-0.11.3-cp38-cp38-manylinux1_x86_64.whl (23.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.2/23.2 MB 99.5 MB/s eta 0:00:00\n",
      "Collecting fsspec[http]>=2021.11.1\n",
      "  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 160.1/160.1 kB 39.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from datasets<3,>=2.4) (6.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 112.6 MB/s eta 0:00:00\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.3/12.3 MB 46.9 MB/s eta 0:00:00\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 213.0/213.0 kB 44.1 MB/s eta 0:00:00\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Downloading pyarrow-12.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 39.0/39.0 MB 60.0 MB/s eta 0:00:00\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 110.5/110.5 kB 28.4 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 224.5/224.5 kB 52.0 MB/s eta 0:00:00\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 132.0/132.0 kB 29.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers<4.27,>=4.25) (2022.9.13)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers<4.27,>=4.25) (0.13.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers<4.27,>=4.25) (3.8.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (266 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 266.9/266.9 kB 52.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets<3,>=2.4) (22.1.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets<3,>=2.4) (2.0.12)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.3/161.3 kB 39.2 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 24.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.8/site-packages (from hydra-core>=1.1->detectron2==0.6) (5.9.0)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.0/117.0 kB 27.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->detectron2==0.6) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 100.7 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 107.8 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.0/300.0 kB 54.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision<0.15,>=0.11.3) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision<0.15,>=0.11.3) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->torchvision<0.15,>=0.11.3) (1.26.11)\n",
      "Collecting platformdirs>=2\n",
      "  Downloading platformdirs-3.5.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from black->detectron2==0.6) (8.1.3)\n",
      "Collecting pathspec>=0.9.0\n",
      "  Downloading pathspec-0.11.1-py3-none-any.whl (29 kB)\n",
      "Collecting packaging\n",
      "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 15.4 MB/s eta 0:00:00\n",
      "Collecting tomli>=1.1.0\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting mypy-extensions>=0.4.3\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 341.8/341.8 kB 55.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets<3,>=2.4) (2022.4)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 38.4 MB/s eta 0:00:00\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.54.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 123.8 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 94.7 MB/s eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.5/242.5 kB 39.5 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.9/93.9 kB 26.9 MB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.18.1-py2.py3-none-any.whl (178 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 178.9/178.9 kB 39.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard->detectron2==0.6) (0.37.1)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 44.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (1.16.0)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources->hydra-core>=1.1->detectron2==0.6) (3.8.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (5.0.0)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.9/83.9 kB 24.9 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 43.5 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime, pycocotools\n",
      "  Building wheel for detectron2 (setup.py): started\n",
      "  Building wheel for detectron2 (setup.py): finished with status 'done'\n",
      "  Created wheel for detectron2: filename=detectron2-0.6-cp38-cp38-linux_x86_64.whl size=6427715 sha256=40a17ca2525615e9b4ee5e368347f4da4c2307995d598276343c98f4e7eae3d6\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-ovvobkpb/wheels/19/ac/65/e48e5e4ec2702274d927c5a6efb75709b24014371d3bb778f2\n",
      "  Building wheel for fvcore (setup.py): started\n",
      "  Building wheel for fvcore (setup.py): finished with status 'done'\n",
      "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61431 sha256=1e1814f1d2a5b9bd178136fa73b2d0cf8260b6806e8beadb9283ace7883ed659\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): started\n",
      "  Building wheel for antlr4-python3-runtime (setup.py): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=b46de0ddaa0cc12ccfc99cab594b2b601685d0af9c5ca812d585551188ae5cbf\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/a3/c2/6df046c09459b73cc9bb6c4401b0be6c47048baf9a1617c485\n",
      "  Building wheel for pycocotools (pyproject.toml): started\n",
      "  Building wheel for pycocotools (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp38-cp38-linux_x86_64.whl size=425678 sha256=d642f7aa38ebdef53aa2a6decc1b7485605e16c664750e7dd20d65bbcc23cf93\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/08/ac/58126fe59992032701437336493f6132e1b72381a62d00b595\n",
      "Successfully built detectron2 fvcore antlr4-python3-runtime pycocotools\n",
      "Installing collected packages: antlr4-python3-runtime, yacs, xxhash, tzdata, tomli, termcolor, tensorboard-data-server, setuptools, pyasn1, pyarrow, portalocker, platformdirs, pathspec, packaging, omegaconf, oauthlib, mypy-extensions, multidict, MarkupSafe, kiwisolver, grpcio, fsspec, frozenlist, fonttools, dill, cycler, contourpy, cloudpickle, cachetools, async-timeout, absl-py, yarl, werkzeug, torchvision, rsa, responses, requests-oauthlib, pyasn1-modules, pandas, multiprocess, matplotlib, markdown, iopath, hydra-core, huggingface-hub, black, aiosignal, transformers, pycocotools, google-auth, fvcore, aiohttp, google-auth-oauthlib, tensorboard, datasets, detectron2\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 59.8.0\n",
      "    Uninstalling setuptools-59.8.0:\n",
      "      Successfully uninstalled setuptools-59.8.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.10.0\n",
      "    Uninstalling huggingface-hub-0.10.0:\n",
      "      Successfully uninstalled huggingface-hub-0.10.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.17.0\n",
      "    Uninstalling transformers-4.17.0:\n",
      "      Successfully uninstalled transformers-4.17.0\n",
      "Successfully installed MarkupSafe-2.1.2 absl-py-1.4.0 aiohttp-3.8.4 aiosignal-1.3.1 antlr4-python3-runtime-4.9.3 async-timeout-4.0.2 black-23.3.0 cachetools-5.3.0 cloudpickle-2.2.1 contourpy-1.0.7 cycler-0.11.0 datasets-2.12.0 detectron2-0.6 dill-0.3.6 fonttools-4.39.4 frozenlist-1.3.3 fsspec-2023.5.0 fvcore-0.1.5.post20221221 google-auth-2.18.1 google-auth-oauthlib-1.0.0 grpcio-1.54.2 huggingface-hub-0.14.1 hydra-core-1.3.2 iopath-0.1.9 kiwisolver-1.4.4 markdown-3.4.3 matplotlib-3.7.1 multidict-6.0.4 multiprocess-0.70.14 mypy-extensions-1.0.0 oauthlib-3.2.2 omegaconf-2.3.0 packaging-23.1 pandas-2.0.1 pathspec-0.11.1 platformdirs-3.5.1 portalocker-2.7.0 pyarrow-12.0.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycocotools-2.0.6 requests-oauthlib-1.3.1 responses-0.18.0 rsa-4.9 setuptools-59.5.0 tensorboard-2.13.0 tensorboard-data-server-0.7.0 termcolor-2.3.0 tomli-2.0.1 torchvision-0.11.3 transformers-4.26.1 tzdata-2023.3 werkzeug-2.3.4 xxhash-3.2.0 yacs-0.1.8 yarl-1.9.2\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container 18bb735e6172\n",
      " ---> dc880aba1c30\n",
      "Step 7/11 : RUN PT_VER=`pip show torch | grep 'Version:' | sed 's/Version: //'`     && pip install pytesseract torch==$PT_VER\n",
      " ---> Running in b03c35ad5c53\n",
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: torch==1.10.2+cu113 in /opt/conda/lib/python3.8/site-packages (1.10.2+cu113)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch==1.10.2+cu113) (4.3.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/conda/lib/python3.8/site-packages (from pytesseract) (23.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.8/site-packages (from pytesseract) (8.4.0)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.10\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91m\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\u001b[0mRemoving intermediate container b03c35ad5c53\n",
      " ---> dd2ccb4a48a8\n",
      "Step 8/11 : ARG INCLUDE_NOTEBOOK_KERNEL\n",
      " ---> Running in 668121b06c57\n",
      "Removing intermediate container 668121b06c57\n",
      " ---> 0351a3642269\n",
      "Step 9/11 : RUN if test -z \"$INCLUDE_NOTEBOOK_KERNEL\" ;     then         echo Skipping notebook kernel dependencies     ; else         conda install -y -c conda-forge poppler tesseract &&         PT_VER=`pip show torch | grep 'Version:' | sed 's/Version: //'` &&         pip install easyocr ipykernel \"ipywidgets>=7,<8\" pdf2image pytesseract sagemaker             torch==$PT_VER &&         export TESSDATA_PREFIX='/opt/conda/share/tessdata' &&         python -m ipykernel install --sys-prefix     ; fi\n",
      " ---> Running in b1bdc76ca33b\n",
      "Skipping notebook kernel dependencies\n",
      "Removing intermediate container b1bdc76ca33b\n",
      " ---> 69f426745c66\n",
      "Step 10/11 : ENV USE_SMDEBUG=${INCLUDE_NOTEBOOK_KERNEL:+false}\n",
      " ---> Running in b7b523b565f0\n",
      "Removing intermediate container b7b523b565f0\n",
      " ---> e69fb043dc91\n",
      "Step 11/11 : ENV USE_SMDEBUG=${USE_SMDEBUG:-true}\n",
      " ---> Running in 073b4b025fab\n",
      "Removing intermediate container 073b4b025fab\n",
      " ---> af73c82ab35d\n",
      "Successfully built af73c82ab35d\n",
      "Successfully tagged sm-ocr-inference:hf-4.17-pt-gpu\n",
      "\n",
      "[Container] 2023/05/24 15:57:46 Running command docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "\n",
      "[Container] 2023/05/24 15:57:46 Phase complete: BUILD State: SUCCEEDED\n",
      "[Container] 2023/05/24 15:57:46 Phase context status code:  Message:\n",
      "[Container] 2023/05/24 15:57:46 Entering phase POST_BUILD\n",
      "[Container] 2023/05/24 15:57:46 Running command echo Build completed on `date`\n",
      "Build completed on Wed May 24 15:57:46 UTC 2023\n",
      "\n",
      "[Container] 2023/05/24 15:57:46 Running command echo Pushing the Docker image...\n",
      "Pushing the Docker image...\n",
      "\n",
      "[Container] 2023/05/24 15:57:46 Running command docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG\n",
      "The push refers to repository [015943506230.dkr.ecr.us-east-1.amazonaws.com/sm-ocr-inference]\n",
      "175acddb4f0b: Preparing\n",
      "1dab9bf3aa8e: Preparing\n",
      "928e25181548: Preparing\n",
      "d5e4d45b6b53: Preparing\n",
      "d42111f4f5fc: Preparing\n",
      "3ba6fe4b2b66: Preparing\n",
      "b0134fef65ae: Preparing\n",
      "1bfa98cef2c8: Preparing\n",
      "b8bcd343d9df: Preparing\n",
      "83e6952e8e57: Preparing\n",
      "721041a08a77: Preparing\n",
      "ca548dd9f6b6: Preparing\n",
      "ac0871e16dd1: Preparing\n",
      "981540c7bf62: Preparing\n",
      "57c2137bc54a: Preparing\n",
      "3ba6fe4b2b66: Waiting\n",
      "553f00fe9414: Preparing\n",
      "1bfa98cef2c8: Waiting\n",
      "c290b09be722: Preparing\n",
      "b8bcd343d9df: Waiting\n",
      "2e36dd432e28: Preparing\n",
      "b0134fef65ae: Waiting\n",
      "335dafe074cd: Preparing\n",
      "83e6952e8e57: Waiting\n",
      "ac0871e16dd1: Waiting\n",
      "8480a7f24d40: Preparing\n",
      "981540c7bf62: Waiting\n",
      "a688b15f64fd: Preparing\n",
      "542221373db2: Preparing\n",
      "9295157e90fd: Preparing\n",
      "0430d270e456: Preparing\n",
      "d2d399deceb2: Preparing\n",
      "721041a08a77: Waiting\n",
      "e995384f1642: Preparing\n",
      "ca548dd9f6b6: Waiting\n",
      "e592fe6d10a9: Preparing\n",
      "f42691182163: Preparing\n",
      "57c2137bc54a: Waiting\n",
      "68016c5bb65c: Preparing\n",
      "8034550a3bbe: Preparing\n",
      "bf8cedc62fb3: Preparing\n",
      "2e36dd432e28: Waiting\n",
      "335dafe074cd: Waiting\n",
      "8480a7f24d40: Waiting\n",
      "a688b15f64fd: Waiting\n",
      "542221373db2: Waiting\n",
      "e592fe6d10a9: Waiting\n",
      "f42691182163: Waiting\n",
      "9295157e90fd: Waiting\n",
      "0430d270e456: Waiting\n",
      "c290b09be722: Waiting\n",
      "68016c5bb65c: Waiting\n",
      "553f00fe9414: Waiting\n",
      "8034550a3bbe: Waiting\n",
      "bf8cedc62fb3: Waiting\n",
      "e995384f1642: Waiting\n",
      "928e25181548: Pushed\n",
      "d5e4d45b6b53: Pushed\n",
      "3ba6fe4b2b66: Layer already exists\n",
      "175acddb4f0b: Pushed\n",
      "b0134fef65ae: Layer already exists\n",
      "1bfa98cef2c8: Layer already exists\n",
      "b8bcd343d9df: Layer already exists\n",
      "83e6952e8e57: Layer already exists\n",
      "ca548dd9f6b6: Layer already exists\n",
      "721041a08a77: Layer already exists\n",
      "ac0871e16dd1: Layer already exists\n",
      "981540c7bf62: Layer already exists\n",
      "57c2137bc54a: Layer already exists\n",
      "553f00fe9414: Layer already exists\n",
      "c290b09be722: Layer already exists\n",
      "2e36dd432e28: Layer already exists\n",
      "335dafe074cd: Layer already exists\n",
      "8480a7f24d40: Layer already exists\n",
      "a688b15f64fd: Layer already exists\n",
      "542221373db2: Layer already exists\n",
      "9295157e90fd: Layer already exists\n",
      "0430d270e456: Layer already exists\n",
      "e995384f1642: Layer already exists\n",
      "e592fe6d10a9: Layer already exists\n",
      "d2d399deceb2: Layer already exists\n",
      "8034550a3bbe: Layer already exists\n",
      "f42691182163: Layer already exists\n",
      "68016c5bb65c: Layer already exists\n",
      "bf8cedc62fb3: Layer already exists\n",
      "d42111f4f5fc: Pushed\n",
      "1dab9bf3aa8e: Pushed\n",
      "hf-4.17-pt-gpu: digest: sha256:6ee7a0191f53df00e7751d21f2f035df2a5ec0cfe142a1c37e021ce8bbaf4911 size: 6828\n",
      "\n",
      "[Container] 2023/05/24 15:58:22 Phase complete: POST_BUILD State: SUCCEEDED\n",
      "[Container] 2023/05/24 15:58:22 Phase context status code:  Message:\n",
      "\n",
      "Image URI: 015943506230.dkr.ecr.us-east-1.amazonaws.com/sm-ocr-inference:hf-4.17-pt-gpu\n",
      "CPU times: user 7.42 s, sys: 1.4 s, total: 8.82 s\n",
      "Wall time: 8min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# (No need to re-run this cell if your inference image is already in ECR)\n",
    "\n",
    "# Build and push the inference image:\n",
    "!cd custom-containers/train-inf && sm-docker build . \\\n",
    "    --compute-type BUILD_GENERAL1_LARGE \\\n",
    "    --repository {inf_repo_name}:{inf_repo_tag} \\\n",
    "    --role {config.sm_image_build_role} \\\n",
    "    --build-arg BASE_IMAGE={inf_base_uri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "186cc52b-59ea-4d09-8c2e-893ed668eb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 015943506230.dkr.ecr.us-east-1.amazonaws.com/sm-ocr-training:hf-4.17-pt-gpu\n",
      "Found 015943506230.dkr.ecr.us-east-1.amazonaws.com/sm-ocr-inference:hf-4.17-pt-gpu\n"
     ]
    }
   ],
   "source": [
    "# Check from notebook whether the images were successfully created:\n",
    "ecr = boto3.client(\"ecr\")\n",
    "for repo, tag, uri in (\n",
    "    (train_repo_name, train_repo_tag, train_image_uri),\n",
    "    (inf_repo_name, inf_repo_tag, inf_image_uri)\n",
    "):\n",
    "    imgs_desc = ecr.describe_images(\n",
    "        registryId=account_id,\n",
    "        repositoryName=repo,\n",
    "        imageIds=[{\"imageTag\": tag}],\n",
    "    )\n",
    "    assert len(imgs_desc[\"imageDetails\"]) > 0, f\"Couldn't find ECR image {uri} after build\"\n",
    "    print(f\"Found {uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3576ffea-d0ae-4f45-924a-c1457a5a5af4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Label the data!\n",
    "\n",
    "Shortly after the labeling job has been created, you'll see a new task for your user in the SageMaker Ground Truth **labeling portal**. If you lost the portal link from your email, you can access it from the *Private* tab of the [SageMaker Ground Truth Workforces console](https://console.aws.amazon.com/sagemaker/groundtruth?#/labeling-workforces).\n",
    "\n",
    "▶️ Click **Start working** and annotate the examples until the all are finished and you're returned to the portal homepage.\n",
    "\n",
    "▶️ **Try to be as consistent as possible** in how you annotate the classes, because inconsistent annotations can significantly degrade final model accuracy. Refer to the guidance (in this notebook and the 'Full Instructions') that we applied when annotating the example set.\n",
    "\n",
    "![](img/smgt-task-pending.png \"Screenshot of SMGT labeling portal with pending task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b2a5c2-f399-4f15-93ee-61715a141c2e",
   "metadata": {},
   "source": [
    "### Sync the results locally (and iterate?)\n",
    "\n",
    "Once you've finished annotating and the job shows as \"Complete\" in the [SMGT Console](https://console.aws.amazon.com/sagemaker/groundtruth?#/labeling-jobs) (which **might take an extra minute or two**, while your annotations are consolidated), you can download the results here to the notebook via the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb096a-3ecf-4112-a2bd-3899d59d7f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync --quiet $annotations_base_s3uri ./data/annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84178ce6-4794-49cf-8223-a00b7d4e06f1",
   "metadata": {},
   "source": [
    "You should see a subfolder created with the name of your annotation job, under which the **`manifests/output/output.manifest`** file contains the consolidated results of your labelling - again in the open JSON-Lines format.\n",
    "\n",
    "▶️ **Check** your results appear as expected, and explore the file format.\n",
    "\n",
    "> Because label outputs are in JSON-Lines, it's easy to consolidate, transform, and manipulate these results as required using open source tools!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ee9463-88eb-4eec-98eb-0d0b6eb10a64",
   "metadata": {},
   "source": [
    "---\n",
    "## Consolidate annotated data\n",
    "\n",
    "To construct a model training set, we'll typically need to consolidate the results of multiple SageMaker Ground Truth labelling jobs: Perhaps because the work was split up into more manageable chunks - or maybe because additional review/adjustment jobs were run to improve label quality.\n",
    "\n",
    "Inside your `data/annotations` folder, you'll find some **pre-annotated augmentation data** provided for you already (in the `augmentation-` subfolders). These datasets are not especially large or externally useful, but will help you train an example model without too much (or even any!) manual annotation effort.\n",
    "\n",
    "▶️ **Edit** the `include_jobs` line below to control which datasets (pre-provided and your own) will be included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5524dde5-560f-4893-8b1e-1b3848624d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2 annotated manifests:\n",
      "data/annotations/BT_annotations/layoutlm-boxes-2023-04-27-0251/manifests/output/output.manifest\n",
      "data/annotations/BT_annotations/layoutlm-boxes-2023-05-02-0045/manifests/output/output.manifest\n"
     ]
    }
   ],
   "source": [
    "include_jobs = [\n",
    "    \"layoutlm-boxes-2023-04-27-0251\",\n",
    "    \"layoutlm-boxes-2023-05-02-0045\",\n",
    "    # TODO: Can edit the below to include your custom data, if you were able to label it:\n",
    "    # \"cfpb-workshop-1\",\n",
    "]\n",
    "\n",
    "\n",
    "source_manifests = []\n",
    "for job_name in sorted(filter(\n",
    "    lambda n: os.path.isdir(f\"data/annotations/BT_annotations/{n}\"),\n",
    "    os.listdir(\"data/annotations/BT_annotations\")\n",
    ")):\n",
    "    if job_name not in include_jobs:\n",
    "        logger.warning(f\"Skipping {job_name} (not in include_jobs list)\")\n",
    "        continue\n",
    "    job_manifest_path = f\"data/annotations/BT_annotations/{job_name}/manifests/output/output.manifest\"\n",
    "    if not os.path.isfile(job_manifest_path):\n",
    "        raise RuntimeError(f\"Could not find job output manifest {job_manifest_path}\")\n",
    "    source_manifests.append({\"job_name\": job_name, \"manifest_path\": job_manifest_path})\n",
    "\n",
    "print(f\"Got {len(source_manifests)} annotated manifests:\")\n",
    "print(\"\\n\".join(map(lambda o: o[\"manifest_path\"], source_manifests)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09939f-b6c3-41c3-b1ae-95bce8535e39",
   "metadata": {},
   "source": [
    "Note that to **combine multiple output manifests to a single dataset**:\n",
    "\n",
    "- The labels must be stored in the same attribute on every record (records use the labeling job name by default, which will be different between jobs).\n",
    "- If importing data collected from some other account (like the `augmentation-` sets), we'll need to **map the S3 URIs** to equivalent links on your own bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "dec049d0-7fc2-4f28-b2c9-0ea74aa5e122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data/annotations/annotations-all.manifest.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d11890ae67c402e9a313ef861c0a40f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Consolidating manifests...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "standard_label_field = \"label\"\n",
    "\n",
    "print(\"Writing data/annotations/annotations-all.manifest.jsonl\")\n",
    "with open(\"data/annotations/annotations-all.manifest.jsonl\", \"w\") as fout:\n",
    "    util.preproc.consolidate_data_manifests(\n",
    "        source_manifests,\n",
    "        fout,\n",
    "        standard_label_field=standard_label_field,\n",
    "        bucket_mappings={\"DOC-EXAMPLE-BUCKET\": bucket_name},\n",
    "        prefix_mappings={\"EXAMPLE-PREFIX/\": bucket_prefix},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6ae7d66d-9d3a-4a26-9ed6-4dfad717d362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_s3_path(s3_path):\n",
    "    path_parts=s3_path.replace(\"s3://\",\"\").split(\"/\")\n",
    "    bucket=path_parts.pop(0)\n",
    "    key=\"/\".join(path_parts [:-1])\n",
    "    filename = path_parts[-1]\n",
    "    return bucket, key, filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6bbe5993-8e85-4241-a225-22de402af01d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# populate the dictionary of our annotation manafests created in Gound Truth \n",
    "annotation_manafest_dict = {}\n",
    "with open(\"data/annotations/annotations-all.manifest.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        annotation_json = json.loads(line)\n",
    "        bucket, key, filename = split_s3_path(  annotation_json['source-ref'])\n",
    "\n",
    "        # update the soure ref to our use our thumbnails we created.\n",
    "        # this is useful if you use LayoutLM2 and beyond\n",
    "        new_source_ref = r's3://' + bucket_name + r'/' + bucket_prefix + r'data/thumbnails/' + filename\n",
    "        annotation_json['source-ref'] = new_source_ref\n",
    "        #print (annotation_json)\n",
    "        annotation_manafest_dict[filename] = annotation_json\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b776a872-a0b6-46ff-8bd6-6b2dcdc7c821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# enhance the textracks json that we will use for training data; we need\n",
    "# to add our Ground Truth annatations \n",
    "with open(\"data/textracted-BT-enhanced.manifest.jsonl\", \"w\") as updated_json:\n",
    "    with open(\"data/textracted-all.manifest.jsonl\", \"r\") as f:\n",
    "        for line in f:\n",
    "            texttracts_json = json.loads(line)\n",
    "            bucket, key, filename = split_s3_path( texttracts_json['raw-ref'])\n",
    "            #print (bucket)\n",
    "            #print (key)\n",
    "            #print (filename)\n",
    "\n",
    "            # get the annotation json that matches the texttrack source file name\n",
    "            annotation_json = annotation_manafest_dict[filename]\n",
    "\n",
    "            # add the attributres form the annotation json to the text track json \n",
    "            texttracts_json['source-ref'] = annotation_json['source-ref']\n",
    "            texttracts_json['label'] = annotation_json['label'] \n",
    "            #print (texttracts_json)\n",
    "            #print ()\n",
    "            \n",
    "            json.dump(texttracts_json, updated_json)\n",
    "            updated_json.write(\"\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "50bac145-c037-4f61-9ef6-04bbd3a49a38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0be7ade24e41a18e1a0363ca1eef80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building data manifest...:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings = util.preproc.collate_data_manifest(\n",
    "    # Output file:\n",
    "    \"data/pages-all-sample.manifest.jsonl\",\n",
    "    # Input manifest:\n",
    "    #input_manifest=\"data/textracted-all.manifest2.jsonl\",\n",
    "    input_manifest=\"data/textracted-BT-enhanced.manifest.jsonl\",\n",
    "    # s3://... base URI used to try and map 'textract-ref's to cleaned images:\n",
    "    textract_s3_prefix=textract_s3uri,\n",
    "    # The s3://... base URI under which page images are stored:\n",
    "    imgs_s3_prefix=imgs_s3uri,\n",
    "    # Optional s3://... base URI also used to try and map 'raw-ref's to images if present:\n",
    "    raw_s3_prefix=raw_s3uri,\n",
    "    # Other output manifest settings:\n",
    "    by=\"page\",\n",
    "    no_content=\"omit\",\n",
    ")\n",
    "\n",
    "if len(warnings):\n",
    "    raise ValueError(\n",
    "        \"Manifest usable but incomplete - %s docs failed. Please see `warnings` for details\"\n",
    "        % len(warnings)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127578f-1f89-4aa0-8cca-3f988026482f",
   "metadata": {},
   "source": [
    "### Split training and test sets\n",
    "\n",
    "To get some insight on how well our model is generalizing to real-world data, we'll need to reserve some annotated data as a testing/validation set.\n",
    "\n",
    "Below, we randomly partition the data into training and test sets and then upload the two manifests to S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1db93c29-1f24-40dc-a792-31b983c9c9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-26 01:32:27,417 root [INFO] Reading data/pages-all-sample.manifest.jsonl\n",
      "2023-05-26 01:32:27,436 root [INFO] Shuffling records\n",
      "2023-05-26 01:32:27,454 root [INFO] Writing 90 records to data/annotations/annotations-train.manifest.jsonl\n",
      "2023-05-26 01:32:27,491 root [INFO] Writing 10 records to data/annotations/annotations-test.manifest.jsonl\n"
     ]
    }
   ],
   "source": [
    "# TO DO:  Can we build a  \"data/annotations/annotations-all.manifest.jsonl\" with the .json docs?\n",
    "\n",
    "\n",
    "def split_manifest(f_in, f_train, f_test, train_pct=0.9, random_seed=1337):\n",
    "    \"\"\"Split `f_in` manifest file into `f_train`, `f_test`\"\"\"\n",
    "    logger.info(f\"Reading {f_in}\")\n",
    "    with open(f_in, \"r\") as fin:\n",
    "        lines = list(filter(lambda line: line, fin))\n",
    "    logger.info(\"Shuffling records\")\n",
    "    random.Random(random_seed).shuffle(lines)\n",
    "    n_train = round(len(lines) * train_pct)\n",
    "\n",
    "    with open(f_train, \"w\") as ftrain:\n",
    "        logger.info(f\"Writing {n_train} records to {f_train}\")\n",
    "        for line in lines[:n_train]:\n",
    "            \n",
    "            #line = line.replace('source-ref','textract-ref')\n",
    "            #line = line.replace('.jpeg','.json')\n",
    "            #line = line.replace('DynamicTableParser/4_TrainingData/Cycle-1','DynamicTableParser/data/textracted')           \n",
    "            #line = line.replace('DynamicTableParser/4_TrainingData/Cycle-0','DynamicTableParser/data/textracted')           \n",
    "                                   \n",
    "            #print (line)\n",
    "            #print ()\n",
    "            #print ()\n",
    "            \n",
    "            ftrain.write(line)\n",
    "            \n",
    "    with open(f_test, \"w\") as ftest:\n",
    "        logger.info(f\"Writing {len(lines) - n_train} records to {f_test}\")\n",
    "        for line in lines[n_train:]:\n",
    "            templine = line\n",
    "            \n",
    "            #line = line.replace('source-ref','textract-ref')\n",
    "            #line = line.replace('.jpeg','.json')\n",
    "            #line = line.replace('DynamicTableParser/4_TrainingData/Cycle-1','DynamicTableParser/data/textracted')           \n",
    "            #line = line.replace('DynamicTableParser/4_TrainingData/Cycle-0','DynamicTableParser/data/textracted')           \n",
    "            \n",
    "            #print ()\n",
    "            #print (templine)\n",
    "            #print ()\n",
    "            #print (line)\n",
    "            #print ()\n",
    "            #print ()\n",
    "            \n",
    "            ftest.write(line)\n",
    "            \n",
    "\n",
    "\n",
    "split_manifest(\n",
    "   # \"data/annotations/annotations-all.manifest.jsonl\",\n",
    "    \"data/pages-all-sample.manifest.jsonl\",\n",
    "    \"data/annotations/annotations-train.manifest.jsonl\",\n",
    "    \"data/annotations/annotations-test.manifest.jsonl\",\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "294ea8f9-214c-4a3e-ada9-92b295f7c9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/annotations/annotations-train.manifest.jsonl to s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/annotations/annotations-train.manifest.jsonl\n",
      "\n",
      "upload: data/annotations/annotations-test.manifest.jsonl to s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/annotations/annotations-test.manifest.jsonl\n"
     ]
    }
   ],
   "source": [
    "train_manifest_s3uri = f\"s3://{bucket_name}/{bucket_prefix}data/annotations/annotations-train.manifest.jsonl\"\n",
    "!aws s3 cp data/annotations/annotations-train.manifest.jsonl $train_manifest_s3uri\n",
    "\n",
    "print ()\n",
    "test_manifest_s3uri = f\"s3://{bucket_name}/{bucket_prefix}data/annotations/annotations-test.manifest.jsonl\"\n",
    "!aws s3 cp data/annotations/annotations-test.manifest.jsonl $test_manifest_s3uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff1563-6a77-468e-bea5-94efb4ee62f0",
   "metadata": {},
   "source": [
    "### Visualize the data\n",
    "\n",
    "Before training the model, we'll sense-check the data by plotting a few examples.\n",
    "\n",
    "The utility function below will overlay the page image with the annotated bounding boxes, the locations of `WORD` blocks detected from the Amazon Textract results, and the resulting classification of individual Textract `WORD`s. To render these results, the Amazon Textract OCR results need to be downloaded locally to the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6d2fbd5d-e416-46c5-9652-066fe5041f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 ms, sys: 11.6 ms, total: 27.4 ms\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!aws s3 sync --quiet $textract_s3uri ./data/textracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f05876b7-a669-4c21-bc5f-188c40eaf215",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data/annotations/annotations-test.manifest.jsonl\", \"r\") as fman:\n",
    "    test_examples = [json.loads(line) for line in filter(lambda l: l, fman)]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1008cf47-fd81-495c-8aae-d4a3c84f37a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "with open(\"data/annotations/annotations-test.manifest.jsonl\", \"r\") as fman:\n",
    "    test_examples = [json.loads(line) for line in filter(lambda l: l, fman)]\n",
    "\n",
    "util.viz.draw_from_manifest_items(\n",
    "    test_examples,\n",
    "    standard_label_field,\n",
    "    entity_classes,\n",
    "    imgs_s3uri[len(\"s3://\"):].partition(\"/\")[2],\n",
    "    textract_s3key_prefix=textract_s3uri[len(\"s3://\"):].partition(\"/\")[2],\n",
    "    imgs_local_prefix=\"data/imgs-clean\",\n",
    "    textract_local_prefix=\"data/textracted\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf34f40-949a-470e-9e76-ad29fb15a20e",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Train the entity recognition model\n",
    "\n",
    "We now have all the data needed to train and validate an layout- and page-image-aware entity recognition model in a [SageMaker Training Job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html).\n",
    "\n",
    "In this process:\n",
    "\n",
    "- SageMaker will run the job on a dedicated, managed instance of type we choose (we'll use `ml.p*` or `ml.g*` GPU-accelerated types), allowing us to keep this notebook's resources modest and only pay for the seconds of GPU time the training job needs.\n",
    "- The data as specified in the manifest files will be downloaded from Amazon S3.\n",
    "- The bundle of scripts we provide (in `src/`) will be transparently uploaded to S3 and then run inside the specified SageMaker-provided [framework container](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers-prebuilt.html). There's no need for us to build our own container image or implement a serving stack for inference (although fully-custom containers are [also supported](https://docs.aws.amazon.com/sagemaker/latest/dg/docker-containers.html)).\n",
    "- Job hyperparameters will be passed through to our `src/` scripts as CLI arguments.\n",
    "- SageMaker will analyze the logs from the job (i.e. `print()` or `logger` calls from our script) with the regular expressions specified in `metric_definitions`, to scrape structured timeseries metrics like loss and accuracy.\n",
    "- When the job finishes, the contents of the `model` folder in the container will be automatically tarballed and uploaded to a `model.tar.gz` in Amazon S3.\n",
    "\n",
    "You can also refer to [Hugging Face's own docs for training on SageMaker](https://huggingface.co/transformers/sagemaker.html) for more information and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d6213b0b-22ac-41ce-bbee-be6a2ccefb72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::015943506230:role/service-role/AmazonSageMaker-ExecutionRole-20210311T163542\n"
     ]
    }
   ],
   "source": [
    "print (sagemaker.get_execution_role() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "de122f49-cf2b-4331-86a4-08ba0c6bfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace as HuggingFaceEstimator\n",
    "\n",
    "hyperparameters = {\n",
    "    # 2023-05-24\n",
    "    \"model_name_or_path\": \"microsoft/layoutxlm-base\",\n",
    "    #\"model_name_or_path\": \"microsoft/layoutlm-base-uncased\",  \n",
    "    #\"model_name_or_path\": \"microsoft/layoutlmv2-base-uncased\"\n",
    "\n",
    "    # (See src/code/config.py for more info on script parameters)\n",
    "    \"annotation_attr\": standard_label_field,\n",
    "    \"images_prefix\": imgs_s3uri[len(\"s3://\"):].partition(\"/\")[2],\n",
    "    \"textract_prefix\": textract_s3uri[len(\"s3://\"):].partition(\"/\")[2],\n",
    "    \"num_labels\": len(fields) + 1,  # +1 for \"other\"\n",
    "\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "\n",
    "    \"num_train_epochs\": 20,\n",
    "    \"early_stopping_patience\": 15,\n",
    "    \"metric_for_best_model\": \"eval_focus_else_acc_minus_one\",\n",
    "    \"greater_is_better\": \"true\",\n",
    "\n",
    "    # Early stopping implies checkpointing every evaluation (epoch), so limit the total checkpoints\n",
    "    # kept to avoid filling up disk:\n",
    "    \"save_total_limit\": 10,\n",
    "}\n",
    "\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"epoch\", \"Regex\": util.training.get_hf_metric_regex(\"epoch\")},\n",
    "    {\"Name\": \"learning_rate\", \"Regex\": util.training.get_hf_metric_regex(\"learning_rate\")},\n",
    "    {\"Name\": \"train:loss\", \"Regex\": util.training.get_hf_metric_regex(\"loss\")},\n",
    "    {\n",
    "        \"Name\": \"validation:n_examples\",\n",
    "        \"Regex\": util.training.get_hf_metric_regex(\"eval_n_examples\"),\n",
    "    },\n",
    "    {\"Name\": \"validation:loss_avg\", \"Regex\": util.training.get_hf_metric_regex(\"eval_loss\")},\n",
    "    {\"Name\": \"validation:acc\", \"Regex\": util.training.get_hf_metric_regex(\"eval_acc\")},\n",
    "    {\n",
    "        \"Name\": \"validation:n_focus_examples\",\n",
    "        \"Regex\": util.training.get_hf_metric_regex(\"eval_n_focus_examples\"),\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"validation:focus_acc\",\n",
    "        \"Regex\": util.training.get_hf_metric_regex(\"eval_focus_acc\"),\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"validation:target\",\n",
    "        \"Regex\": util.training.get_hf_metric_regex(\"eval_focus_else_acc_minus_one\"),\n",
    "    },\n",
    "]\n",
    "\n",
    "estimator = HuggingFaceEstimator(\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"src\",\n",
    "    py_version=py_version,\n",
    "    pytorch_version=pt_version,\n",
    "    transformers_version=hf_version,\n",
    "    image_uri=train_image_uri,  # Use customized training container image\n",
    "\n",
    "    base_job_name=\"ws-xlm-cfpb-hf\",\n",
    "    output_path=f\"s3://{bucket_name}/{bucket_prefix}trainjobs\",\n",
    "\n",
    "    instance_type=\"ml.p3.2xlarge\",  # Could also consider ml.g4dn.xlarge\n",
    "    instance_count=1,\n",
    "    volume_size=80,\n",
    "\n",
    "    debugger_hook_config=False,\n",
    "\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    environment={\n",
    "        # Required for our custom dataset loading code (which depends on tokenizer):\n",
    "        \"TOKENIZERS_PARALLELISM\": \"false\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "52d9cdff-d997-4008-a340-3eb62beb1280",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/thumbnails\n",
      "\n",
      "s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/annotations/annotations-train.manifest.jsonl\n",
      "\n",
      "s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/textracted\n",
      "\n",
      "s3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/annotations/annotations-test.manifest.jsonl\n"
     ]
    }
   ],
   "source": [
    "print (thumbs_s3uri)\n",
    "print ()\n",
    "print (train_manifest_s3uri)\n",
    "print ()\n",
    "print (textract_s3uri)\n",
    "print ()\n",
    "print (test_manifest_s3uri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a23a1-2307-4e13-88c3-02059d64dbd2",
   "metadata": {},
   "source": [
    "Finally, the below cell will actually kick off the training job and stream logs from the running container.\n",
    "\n",
    "> ℹ️ You'll also be able to check the status of the job in the [Training jobs page of the SageMaker Console](https://console.aws.amazon.com/sagemaker/home?#/jobs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e327065b-bb2d-47c4-8920-343cdf8dd181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-26 11:15:50 Starting - Starting the training job...\n",
      "2023-05-26 11:16:15 Starting - Preparing the instances for training......\n",
      "2023-05-26 11:17:30 Downloading - Downloading input data...\n",
      "2023-05-26 11:17:50 Training - Downloading the training image...........................\n",
      "2023-05-26 11:22:12 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-05-26 11:22:36,756 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-05-26 11:22:36,784 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-05-26 11:22:36,787 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-05-26 11:22:37,010 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.2.2 -> 23.1.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-05-26 11:22:39,393 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-05-26 11:22:39,393 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-05-26 11:22:39,480 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"images\": \"/opt/ml/input/data/images\",\n",
      "        \"textract\": \"/opt/ml/input/data/textract\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"annotation_attr\": \"label\",\n",
      "        \"early_stopping_patience\": 15,\n",
      "        \"greater_is_better\": \"true\",\n",
      "        \"images_prefix\": \"DynamicTableParser/data/imgs-clean\",\n",
      "        \"metric_for_best_model\": \"eval_focus_else_acc_minus_one\",\n",
      "        \"model_name_or_path\": \"microsoft/layoutxlm-base\",\n",
      "        \"num_labels\": 7,\n",
      "        \"num_train_epochs\": 20,\n",
      "        \"per_device_eval_batch_size\": 4,\n",
      "        \"per_device_train_batch_size\": 2,\n",
      "        \"save_total_limit\": 10,\n",
      "        \"textract_prefix\": \"DynamicTableParser/data/textracted\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"images\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"textract\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"job_name\": \"ws-xlm-cfpb-hf-2023-05-26-11-15-49-226\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-015943506230/ws-xlm-cfpb-hf-2023-05-26-11-15-49-226/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"annotation_attr\":\"label\",\"early_stopping_patience\":15,\"greater_is_better\":\"true\",\"images_prefix\":\"DynamicTableParser/data/imgs-clean\",\"metric_for_best_model\":\"eval_focus_else_acc_minus_one\",\"model_name_or_path\":\"microsoft/layoutxlm-base\",\"num_labels\":7,\"num_train_epochs\":20,\"per_device_eval_batch_size\":4,\"per_device_train_batch_size\":2,\"save_total_limit\":10,\"textract_prefix\":\"DynamicTableParser/data/textracted\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"images\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"textract\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"images\",\"textract\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-015943506230/ws-xlm-cfpb-hf-2023-05-26-11-15-49-226/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"images\":\"/opt/ml/input/data/images\",\"textract\":\"/opt/ml/input/data/textract\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"annotation_attr\":\"label\",\"early_stopping_patience\":15,\"greater_is_better\":\"true\",\"images_prefix\":\"DynamicTableParser/data/imgs-clean\",\"metric_for_best_model\":\"eval_focus_else_acc_minus_one\",\"model_name_or_path\":\"microsoft/layoutxlm-base\",\"num_labels\":7,\"num_train_epochs\":20,\"per_device_eval_batch_size\":4,\"per_device_train_batch_size\":2,\"save_total_limit\":10,\"textract_prefix\":\"DynamicTableParser/data/textracted\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"images\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"textract\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"job_name\":\"ws-xlm-cfpb-hf-2023-05-26-11-15-49-226\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-015943506230/ws-xlm-cfpb-hf-2023-05-26-11-15-49-226/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--annotation_attr\",\"label\",\"--early_stopping_patience\",\"15\",\"--greater_is_better\",\"true\",\"--images_prefix\",\"DynamicTableParser/data/imgs-clean\",\"--metric_for_best_model\",\"eval_focus_else_acc_minus_one\",\"--model_name_or_path\",\"microsoft/layoutxlm-base\",\"--num_labels\",\"7\",\"--num_train_epochs\",\"20\",\"--per_device_eval_batch_size\",\"4\",\"--per_device_train_batch_size\",\"2\",\"--save_total_limit\",\"10\",\"--textract_prefix\",\"DynamicTableParser/data/textracted\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_IMAGES=/opt/ml/input/data/images\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEXTRACT=/opt/ml/input/data/textract\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_ANNOTATION_ATTR=label\u001b[0m\n",
      "\u001b[34mSM_HP_EARLY_STOPPING_PATIENCE=15\u001b[0m\n",
      "\u001b[34mSM_HP_GREATER_IS_BETTER=true\u001b[0m\n",
      "\u001b[34mSM_HP_IMAGES_PREFIX=DynamicTableParser/data/imgs-clean\u001b[0m\n",
      "\u001b[34mSM_HP_METRIC_FOR_BEST_MODEL=eval_focus_else_acc_minus_one\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME_OR_PATH=microsoft/layoutxlm-base\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_LABELS=7\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_EVAL_BATCH_SIZE=4\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=2\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_TOTAL_LIMIT=10\u001b[0m\n",
      "\u001b[34mSM_HP_TEXTRACT_PREFIX=DynamicTableParser/data/textracted\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.22b20220929-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 train.py --annotation_attr label --early_stopping_patience 15 --greater_is_better true --images_prefix DynamicTableParser/data/imgs-clean --metric_for_best_model eval_focus_else_acc_minus_one --model_name_or_path microsoft/layoutxlm-base --num_labels 7 --num_train_epochs 20 --per_device_eval_batch_size 4 --per_device_train_batch_size 2 --save_total_limit 10 --textract_prefix DynamicTableParser/data/textracted\u001b[0m\n",
      "\u001b[34m[2023-05-26 11:22:41.296: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:68] Found unsupported HuggingFace version 4.26.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34mDefaulting CUBLAS_WORKSPACE_CONFIG=':4096:8' to enable deterministic ops as `seed` is set.\u001b[0m\n",
      "\u001b[34m2023-05-26 11:22:44,448 [main] INFO Loaded arguments:\u001b[0m\n",
      "\u001b[34mModelArguments(cache_dir='/tmp/transformers/cache', config_name=None, model_name_or_path='microsoft/layoutxlm-base', model_revision='main', tokenizer_name=None, use_auth_token=False)\u001b[0m\n",
      "\u001b[34mDataTrainingArguments(annotation_attr='label', dataproc_batch_size=16, max_seq_length=512, pad_to_multiple_of=8, max_train_samples=None, task_name='ner', textract='/opt/ml/input/data/textract', textract_prefix='DynamicTableParser/data/textracted', train='/opt/ml/input/data/train', validation='/opt/ml/input/data/validation', images='/opt/ml/input/data/images', images_prefix='DynamicTableParser/data/imgs-clean', num_labels=7, mlm_probability=0.15, tiam_probability=0.15, tim_probability=0.2)\u001b[0m\n",
      "\u001b[34mSageMakerTrainingArguments(\u001b[0m\n",
      "\u001b[34m_n_gpu=1,\u001b[0m\n",
      "\u001b[34madafactor=False,\u001b[0m\n",
      "\u001b[34madam_beta1=0.9,\u001b[0m\n",
      "\u001b[34madam_beta2=0.999,\u001b[0m\n",
      "\u001b[34madam_epsilon=1e-08,\u001b[0m\n",
      "\u001b[34mauto_find_batch_size=False,\u001b[0m\n",
      "\u001b[34mbf16=False,\u001b[0m\n",
      "\u001b[34mbf16_full_eval=False,\u001b[0m\n",
      "\u001b[34mdata_seed=None,\u001b[0m\n",
      "\u001b[34mdataloader_drop_last=False,\u001b[0m\n",
      "\u001b[34mdataloader_num_workers=6,\u001b[0m\n",
      "\u001b[34mdataloader_pin_memory=True,\u001b[0m\n",
      "\u001b[34mdataproc_num_workers=6,\u001b[0m\n",
      "\u001b[34mddp_bucket_cap_mb=None,\u001b[0m\n",
      "\u001b[34mddp_find_unused_parameters=True,\u001b[0m\n",
      "\u001b[34mddp_timeout=1800,\u001b[0m\n",
      "\u001b[34mdebug=[],\u001b[0m\n",
      "\u001b[34mdeepspeed=None,\u001b[0m\n",
      "\u001b[34mdisable_tqdm=True,\u001b[0m\n",
      "\u001b[34mdo_eval=True,\u001b[0m\n",
      "\u001b[34mdo_predict=False,\u001b[0m\n",
      "\u001b[34mdo_train=True,\u001b[0m\n",
      "\u001b[34mearly_stopping_patience=15,\u001b[0m\n",
      "\u001b[34mearly_stopping_threshold=0.0,\u001b[0m\n",
      "\u001b[34meval_accumulation_steps=None,\u001b[0m\n",
      "\u001b[34meval_delay=0,\u001b[0m\n",
      "\u001b[34meval_steps=None,\u001b[0m\n",
      "\u001b[34mevaluation_strategy=epoch,\u001b[0m\n",
      "\u001b[34mfp16=False,\u001b[0m\n",
      "\u001b[34mfp16_backend=auto,\u001b[0m\n",
      "\u001b[34mfp16_full_eval=False,\u001b[0m\n",
      "\u001b[34mfp16_opt_level=O1,\u001b[0m\n",
      "\u001b[34mfsdp=[],\u001b[0m\n",
      "\u001b[34mfsdp_min_num_params=0,\u001b[0m\n",
      "\u001b[34mfsdp_transformer_layer_cls_to_wrap=None,\u001b[0m\n",
      "\u001b[34mfull_determinism=True,\u001b[0m\n",
      "\u001b[34mgradient_accumulation_steps=1,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing=False,\u001b[0m\n",
      "\u001b[34mgreater_is_better=True,\u001b[0m\n",
      "\u001b[34mgroup_by_length=False,\u001b[0m\n",
      "\u001b[34mhalf_precision_backend=auto,\u001b[0m\n",
      "\u001b[34mhub_model_id=None,\u001b[0m\n",
      "\u001b[34mhub_private_repo=False,\u001b[0m\n",
      "\u001b[34mhub_strategy=every_save,\u001b[0m\n",
      "\u001b[34mhub_token=<HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mignore_data_skip=False,\u001b[0m\n",
      "\u001b[34minclude_inputs_for_metrics=False,\u001b[0m\n",
      "\u001b[34mjit_mode_eval=False,\u001b[0m\n",
      "\u001b[34mlabel_names=None,\u001b[0m\n",
      "\u001b[34mlabel_smoothing_factor=0.0,\u001b[0m\n",
      "\u001b[34mlearning_rate=5e-05,\u001b[0m\n",
      "\u001b[34mlength_column_name=length,\u001b[0m\n",
      "\u001b[34mload_best_model_at_end=True,\u001b[0m\n",
      "\u001b[34mlocal_rank=-1,\u001b[0m\n",
      "\u001b[34mlog_level=passive,\u001b[0m\n",
      "\u001b[34mlog_level_replica=passive,\u001b[0m\n",
      "\u001b[34mlog_on_each_node=True,\u001b[0m\n",
      "\u001b[34mlogging_dir=/tmp/transformers/checkpoints/runs/May26_11-22-44_algo-1,\u001b[0m\n",
      "\u001b[34mlogging_first_step=False,\u001b[0m\n",
      "\u001b[34mlogging_nan_inf_filter=True,\u001b[0m\n",
      "\u001b[34mlogging_steps=500,\u001b[0m\n",
      "\u001b[34mlogging_strategy=steps,\u001b[0m\n",
      "\u001b[34mlr_scheduler_type=linear,\u001b[0m\n",
      "\u001b[34mmax_grad_norm=1.0,\u001b[0m\n",
      "\u001b[34mmax_steps=-1,\u001b[0m\n",
      "\u001b[34mmetric_for_best_model=eval_focus_else_acc_minus_one,\u001b[0m\n",
      "\u001b[34mmodel_dir=/opt/ml/model,\u001b[0m\n",
      "\u001b[34mmp_parameters=,\u001b[0m\n",
      "\u001b[34mno_cuda=False,\u001b[0m\n",
      "\u001b[34mnum_train_epochs=20.0,\u001b[0m\n",
      "\u001b[34moptim=adamw_hf,\u001b[0m\n",
      "\u001b[34moptim_args=None,\u001b[0m\n",
      "\u001b[34moutput_dir=/tmp/transformers/checkpoints,\u001b[0m\n",
      "\u001b[34moverwrite_output_dir=True,\u001b[0m\n",
      "\u001b[34mpast_index=-1,\u001b[0m\n",
      "\u001b[34mper_device_eval_batch_size=4,\u001b[0m\n",
      "\u001b[34mper_device_train_batch_size=2,\u001b[0m\n",
      "\u001b[34mprediction_loss_only=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub_model_id=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_organization=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mray_scope=last,\u001b[0m\n",
      "\u001b[34mremove_unused_columns=False,\u001b[0m\n",
      "\u001b[34mreport_to=['tensorboard'],\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint=None,\u001b[0m\n",
      "\u001b[34mrun_name=/tmp/transformers/checkpoints,\u001b[0m\n",
      "\u001b[34msave_on_each_node=False,\u001b[0m\n",
      "\u001b[34msave_steps=500,\u001b[0m\n",
      "\u001b[34msave_strategy=epoch,\u001b[0m\n",
      "\u001b[34msave_total_limit=10,\u001b[0m\n",
      "\u001b[34mseed=42,\u001b[0m\n",
      "\u001b[34msharded_ddp=[],\u001b[0m\n",
      "\u001b[34mskip_memory_metrics=True,\u001b[0m\n",
      "\u001b[34mtf32=None,\u001b[0m\n",
      "\u001b[34mtorch_compile=False,\u001b[0m\n",
      "\u001b[34mtorch_compile_backend=None,\u001b[0m\n",
      "\u001b[34mtorch_compile_mode=None,\u001b[0m\n",
      "\u001b[34mtorchdynamo=None,\u001b[0m\n",
      "\u001b[34mtpu_metrics_debug=False,\u001b[0m\n",
      "\u001b[34mtpu_num_cores=None,\u001b[0m\n",
      "\u001b[34muse_ipex=False,\u001b[0m\n",
      "\u001b[34muse_legacy_prediction_loop=False,\u001b[0m\n",
      "\u001b[34muse_mps_device=False,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.0,\u001b[0m\n",
      "\u001b[34mwarmup_steps=0,\u001b[0m\n",
      "\u001b[34mweight_decay=0.0,\u001b[0m\n",
      "\u001b[34mxpu_backend=None,\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m2023-05-26 11:22:44,449 [main] INFO Starting!\u001b[0m\n",
      "\u001b[34m2023-05-26 11:22:44,449 [main] INFO Started with local_rank -1\u001b[0m\n",
      "\u001b[34m2023-05-26 11:22:44,450 [main] INFO Creating config and model\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json: 100%|██████████| 1.02k/1.02k [00:00<00:00, 140kB/s]\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:660] 2023-05-26 11:22:44,507 >> loading configuration file config.json from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:660] 2023-05-26 11:22:44,507 >> loading configuration file config.json from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/config.json\u001b[0m\n",
      "\u001b[34mDownloading (…)n/config.4.13.0.json:   0%|          | 0.00/947 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)n/config.4.13.0.json: 100%|██████████| 947/947 [00:00<00:00, 159kB/s]\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:660] 2023-05-26 11:22:44,551 >> loading configuration file config.4.13.0.json from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/config.4.13.0.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:660] 2023-05-26 11:22:44,551 >> loading configuration file config.4.13.0.json from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/config.4.13.0.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:712] 2023-05-26 11:22:44,552 >> Model config LayoutLMv2Config {\n",
      "  \"_name_or_path\": \"microsoft/layoutxlm-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"convert_sync_batchnorm\": true,\n",
      "  \"coordinate_size\": 128,\n",
      "  \"detectron2_config_args\": {\n",
      "    \"MODEL.ANCHOR_GENERATOR.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.BACKBONE.NAME\": \"build_resnet_fpn_backbone\",\n",
      "    \"MODEL.FPN.IN_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.MASK_ON\": true,\n",
      "    \"MODEL.PIXEL_STD\": [\n",
      "      57.375,\n",
      "      57.12,\n",
      "      58.395\n",
      "    ],\n",
      "    \"MODEL.POST_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RESNETS.ASPECT_RATIOS\": [\n",
      "      [\n",
      "        0.5,\n",
      "        1.0,\n",
      "        2.0\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.DEPTH\": 101,\n",
      "    \"MODEL.RESNETS.NUM_GROUPS\": 32,\n",
      "    \"MODEL.RESNETS.OUT_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.RESNETS.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.STRIDE_IN_1X1\": false,\n",
      "    \"MODEL.RESNETS.WIDTH_PER_GROUP\": 8,\n",
      "    \"MODEL.ROI_BOX_HEAD.NAME\": \"FastRCNNConvFCHead\",\n",
      "    \"MODEL.ROI_BOX_HEAD.NUM_FC\": 2,\n",
      "    \"MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION\": 14,\n",
      "    \"MODEL.ROI_HEADS.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\"\n",
      "    ],\n",
      "    \"MODEL.ROI_HEADS.NAME\": \"StandardROIHeads\",\n",
      "    \"MODEL.ROI_HEADS.NUM_CLASSES\": 5,\n",
      "    \"MODEL.ROI_MASK_HEAD.NAME\": \"MaskRCNNConvUpsampleHead\",\n",
      "    \"MODEL.ROI_MASK_HEAD.NUM_CONV\": 4,\n",
      "    \"MODEL.ROI_MASK_HEAD.POOLER_RESOLUTION\": 7,\n",
      "    \"MODEL.RPN.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\",\n",
      "      \"p6\"\n",
      "    ],\n",
      "    \"MODEL.RPN.POST_NMS_TOPK_TRAIN\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TRAIN\": 2000\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"fast_qkv\": false,\n",
      "  \"finetuning_task\": \"ner\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"has_relative_attention_bias\": false,\n",
      "  \"has_spatial_attention_bias\": false,\n",
      "  \"has_visual_segment_embedding\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"0\",\n",
      "    \"1\": \"1\",\n",
      "    \"2\": \"2\",\n",
      "    \"3\": \"3\",\n",
      "    \"4\": \"4\",\n",
      "    \"5\": \"5\",\n",
      "    \"6\": \"6\"\n",
      "  },\n",
      "  \"image_feature_pool_shape\": [\n",
      "    7,\n",
      "    7,\n",
      "    256\n",
      "  ],\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"0\": 0,\n",
      "    \"1\": 1,\n",
      "    \"2\": 2,\n",
      "    \"3\": 3,\n",
      "    \"4\": 4,\n",
      "    \"5\": 5,\n",
      "    \"6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_2d_position_embeddings\": 1024,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"max_rel_2d_pos\": 256,\n",
      "  \"max_rel_pos\": 128,\n",
      "  \"model_type\": \"layoutlmv2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"rel_2d_pos_bins\": 64,\n",
      "  \"rel_pos_bins\": 32,\n",
      "  \"shape_size\": 128,\n",
      "  \"tokenizer_class\": \"LayoutXLMTokenizer\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:712] 2023-05-26 11:22:44,552 >> Model config LayoutLMv2Config {\n",
      "  \"_name_or_path\": \"microsoft/layoutxlm-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"convert_sync_batchnorm\": true,\n",
      "  \"coordinate_size\": 128,\n",
      "  \"detectron2_config_args\": {\n",
      "    \"MODEL.ANCHOR_GENERATOR.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.BACKBONE.NAME\": \"build_resnet_fpn_backbone\",\n",
      "    \"MODEL.FPN.IN_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.MASK_ON\": true,\n",
      "    \"MODEL.PIXEL_STD\": [\n",
      "      57.375,\n",
      "      57.12,\n",
      "      58.395\n",
      "    ],\n",
      "    \"MODEL.POST_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RESNETS.ASPECT_RATIOS\": [\n",
      "      [\n",
      "        0.5,\n",
      "        1.0,\n",
      "        2.0\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.DEPTH\": 101,\n",
      "    \"MODEL.RESNETS.NUM_GROUPS\": 32,\n",
      "    \"MODEL.RESNETS.OUT_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.RESNETS.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.STRIDE_IN_1X1\": false,\n",
      "    \"MODEL.RESNETS.WIDTH_PER_GROUP\": 8,\n",
      "    \"MODEL.ROI_BOX_HEAD.NAME\": \"FastRCNNConvFCHead\",\n",
      "    \"MODEL.ROI_BOX_HEAD.NUM_FC\": 2,\n",
      "    \"MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION\": 14,\n",
      "    \"MODEL.ROI_HEADS.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\"\n",
      "    ],\n",
      "    \"MODEL.ROI_HEADS.NAME\": \"StandardROIHeads\",\n",
      "    \"MODEL.ROI_HEADS.NUM_CLASSES\": 5,\n",
      "    \"MODEL.ROI_MASK_HEAD.NAME\": \"MaskRCNNConvUpsampleHead\",\n",
      "    \"MODEL.ROI_MASK_HEAD.NUM_CONV\": 4,\n",
      "    \"MODEL.ROI_MASK_HEAD.POOLER_RESOLUTION\": 7,\n",
      "    \"MODEL.RPN.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\",\n",
      "      \"p6\"\n",
      "    ],\n",
      "    \"MODEL.RPN.POST_NMS_TOPK_TRAIN\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TRAIN\": 2000\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"fast_qkv\": false,\n",
      "  \"finetuning_task\": \"ner\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"has_relative_attention_bias\": false,\n",
      "  \"has_spatial_attention_bias\": false,\n",
      "  \"has_visual_segment_embedding\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"0\",\n",
      "    \"1\": \"1\",\n",
      "    \"2\": \"2\",\n",
      "    \"3\": \"3\",\n",
      "    \"4\": \"4\",\n",
      "    \"5\": \"5\",\n",
      "    \"6\": \"6\"\n",
      "  },\n",
      "  \"image_feature_pool_shape\": [\n",
      "    7,\n",
      "    7,\n",
      "    256\n",
      "  ],\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"0\": 0,\n",
      "    \"1\": 1,\n",
      "    \"2\": 2,\n",
      "    \"3\": 3,\n",
      "    \"4\": 4,\n",
      "    \"5\": 5,\n",
      "    \"6\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_2d_position_embeddings\": 1024,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"max_rel_2d_pos\": 256,\n",
      "  \"max_rel_pos\": 128,\n",
      "  \"model_type\": \"layoutlmv2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"rel_2d_pos_bins\": 64,\n",
      "  \"rel_pos_bins\": 32,\n",
      "  \"shape_size\": 128,\n",
      "  \"tokenizer_class\": \"LayoutXLMTokenizer\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mDownloading (…)rocessor_config.json:   0%|          | 0.00/135 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)rocessor_config.json: 100%|██████████| 135/135 [00:00<00:00, 158kB/s]\u001b[0m\n",
      "\u001b[34m[INFO|image_processing_utils.py:296] 2023-05-26 11:22:44,590 >> loading configuration file preprocessor_config.json from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/preprocessor_config.json\u001b[0m\n",
      "\u001b[34m[INFO|image_processing_utils.py:296] 2023-05-26 11:22:44,590 >> loading configuration file preprocessor_config.json from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/preprocessor_config.json\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/transformers/models/layoutlmv2/feature_extraction_layoutlmv2.py:30: FutureWarning: The class LayoutLMv2FeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use LayoutLMv2ImageProcessor instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[INFO|image_processing_utils.py:520] 2023-05-26 11:22:44,590 >> size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}), got 224. Converted to {'height': 224, 'width': 224}.\u001b[0m\n",
      "\u001b[34m[INFO|image_processing_utils.py:520] 2023-05-26 11:22:44,590 >> size should be a dictionary on of the following set of keys: ({'width', 'height'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}), got 224. Converted to {'height': 224, 'width': 224}.\u001b[0m\n",
      "\u001b[34m[INFO|image_processing_utils.py:341] 2023-05-26 11:22:44,591 >> Image processor LayoutLMv2FeatureExtractor {\n",
      "  \"apply_ocr\": false,\n",
      "  \"do_resize\": false,\n",
      "  \"feature_extractor_type\": \"LayoutLMv2FeatureExtractor\",\n",
      "  \"image_processor_type\": \"LayoutLMv2FeatureExtractor\",\n",
      "  \"ocr_lang\": null,\n",
      "  \"resample\": 2,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  },\n",
      "  \"tesseract_config\": \"\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|image_processing_utils.py:341] 2023-05-26 11:22:44,591 >> Image processor LayoutLMv2FeatureExtractor {\n",
      "  \"apply_ocr\": false,\n",
      "  \"do_resize\": false,\n",
      "  \"feature_extractor_type\": \"LayoutLMv2FeatureExtractor\",\n",
      "  \"image_processor_type\": \"LayoutLMv2FeatureExtractor\",\n",
      "  \"ocr_lang\": null,\n",
      "  \"resample\": 2,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  },\n",
      "  \"tesseract_config\": \"\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mDownloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:00<00:00, 161MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)/main/tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)/main/tokenizer.json: 100%|██████████| 9.10M/9.10M [00:00<00:00, 187MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-05-26 11:22:45,364 >> loading file sentencepiece.bpe.model from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/sentencepiece.bpe.model\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-05-26 11:22:45,364 >> loading file sentencepiece.bpe.model from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/sentencepiece.bpe.model\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-05-26 11:22:45,364 >> loading file tokenizer.json from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/tokenizer.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-05-26 11:22:45,364 >> loading file added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-05-26 11:22:45,364 >> loading file special_tokens_map.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-05-26 11:22:45,364 >> loading file tokenizer.json from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/tokenizer.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-05-26 11:22:45,364 >> loading file added_tokens.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-05-26 11:22:45,364 >> loading file special_tokens_map.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-05-26 11:22:45,364 >> loading file tokenizer_config.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:1802] 2023-05-26 11:22:45,364 >> loading file tokenizer_config.json from cache at None\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:660] 2023-05-26 11:22:45,365 >> loading configuration file config.json from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:660] 2023-05-26 11:22:45,365 >> loading configuration file config.json from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:660] 2023-05-26 11:22:45,365 >> loading configuration file config.4.13.0.json from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/config.4.13.0.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:660] 2023-05-26 11:22:45,365 >> loading configuration file config.4.13.0.json from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/config.4.13.0.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:712] 2023-05-26 11:22:45,367 >> Model config LayoutLMv2Config {\n",
      "  \"_name_or_path\": \"microsoft/layoutxlm-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"convert_sync_batchnorm\": true,\n",
      "  \"coordinate_size\": 128,\n",
      "  \"detectron2_config_args\": {\n",
      "    \"MODEL.ANCHOR_GENERATOR.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.BACKBONE.NAME\": \"build_resnet_fpn_backbone\",\n",
      "    \"MODEL.FPN.IN_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.MASK_ON\": true,\n",
      "    \"MODEL.PIXEL_STD\": [\n",
      "      57.375,\n",
      "      57.12,\n",
      "      58.395\n",
      "    ],\n",
      "    \"MODEL.POST_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RESNETS.ASPECT_RATIOS\": [\n",
      "      [\n",
      "        0.5,\n",
      "        1.0,\n",
      "        2.0\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.DEPTH\": 101,\n",
      "    \"MODEL.RESNETS.NUM_GROUPS\": 32,\n",
      "    \"MODEL.RESNETS.OUT_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.RESNETS.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.STRIDE_IN_1X1\": false,\n",
      "    \"MODEL.RESNETS.WIDTH_PER_GROUP\": 8,\n",
      "    \"MODEL.ROI_BOX_HEAD.NAME\": \"FastRCNNConvFCHead\",\n",
      "    \"MODEL.ROI_BOX_HEAD.NUM_FC\": 2,\n",
      "    \"MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION\": 14,\n",
      "    \"MODEL.ROI_HEADS.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\"\n",
      "    ],\n",
      "    \"MODEL.ROI_HEADS.NAME\": \"StandardROIHeads\",\n",
      "    \"MODEL.ROI_HEADS.NUM_CLASSES\": 5,\n",
      "    \"MODEL.ROI_MASK_HEAD.NAME\": \"MaskRCNNConvUpsampleHead\",\n",
      "    \"MODEL.ROI_MASK_HEAD.NUM_CONV\": 4,\n",
      "    \"MODEL.ROI_MASK_HEAD.POOLER_RESOLUTION\": 7,\n",
      "    \"MODEL.RPN.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\",\n",
      "      \"p6\"\n",
      "    ],\n",
      "    \"MODEL.RPN.POST_NMS_TOPK_TRAIN\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TRAIN\": 2000\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"fast_qkv\": false,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"has_relative_attention_bias\": false,\n",
      "  \"has_spatial_attention_bias\": false,\n",
      "  \"has_visual_segment_embedding\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_feature_pool_shape\": [\n",
      "    7,\n",
      "    7,\n",
      "    256\n",
      "  ],\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_2d_position_embeddings\": 1024,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"max_rel_2d_pos\": 256,\n",
      "  \"max_rel_pos\": 128,\n",
      "  \"model_type\": \"layoutlmv2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"rel_2d_pos_bins\": 64,\n",
      "  \"rel_pos_bins\": 32,\n",
      "  \"shape_size\": 128,\n",
      "  \"tokenizer_class\": \"LayoutXLMTokenizer\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:712] 2023-05-26 11:22:45,367 >> Model config LayoutLMv2Config {\n",
      "  \"_name_or_path\": \"microsoft/layoutxlm-base\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"convert_sync_batchnorm\": true,\n",
      "  \"coordinate_size\": 128,\n",
      "  \"detectron2_config_args\": {\n",
      "    \"MODEL.ANCHOR_GENERATOR.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.BACKBONE.NAME\": \"build_resnet_fpn_backbone\",\n",
      "    \"MODEL.FPN.IN_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.MASK_ON\": true,\n",
      "    \"MODEL.PIXEL_STD\": [\n",
      "      57.375,\n",
      "      57.12,\n",
      "      58.395\n",
      "    ],\n",
      "    \"MODEL.POST_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RESNETS.ASPECT_RATIOS\": [\n",
      "      [\n",
      "        0.5,\n",
      "        1.0,\n",
      "        2.0\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.DEPTH\": 101,\n",
      "    \"MODEL.RESNETS.NUM_GROUPS\": 32,\n",
      "    \"MODEL.RESNETS.OUT_FEATURES\": [\n",
      "      \"res2\",\n",
      "      \"res3\",\n",
      "      \"res4\",\n",
      "      \"res5\"\n",
      "    ],\n",
      "    \"MODEL.RESNETS.SIZES\": [\n",
      "      [\n",
      "        32\n",
      "      ],\n",
      "      [\n",
      "        64\n",
      "      ],\n",
      "      [\n",
      "        128\n",
      "      ],\n",
      "      [\n",
      "        256\n",
      "      ],\n",
      "      [\n",
      "        512\n",
      "      ]\n",
      "    ],\n",
      "    \"MODEL.RESNETS.STRIDE_IN_1X1\": false,\n",
      "    \"MODEL.RESNETS.WIDTH_PER_GROUP\": 8,\n",
      "    \"MODEL.ROI_BOX_HEAD.NAME\": \"FastRCNNConvFCHead\",\n",
      "    \"MODEL.ROI_BOX_HEAD.NUM_FC\": 2,\n",
      "    \"MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION\": 14,\n",
      "    \"MODEL.ROI_HEADS.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\"\n",
      "    ],\n",
      "    \"MODEL.ROI_HEADS.NAME\": \"StandardROIHeads\",\n",
      "    \"MODEL.ROI_HEADS.NUM_CLASSES\": 5,\n",
      "    \"MODEL.ROI_MASK_HEAD.NAME\": \"MaskRCNNConvUpsampleHead\",\n",
      "    \"MODEL.ROI_MASK_HEAD.NUM_CONV\": 4,\n",
      "    \"MODEL.ROI_MASK_HEAD.POOLER_RESOLUTION\": 7,\n",
      "    \"MODEL.RPN.IN_FEATURES\": [\n",
      "      \"p2\",\n",
      "      \"p3\",\n",
      "      \"p4\",\n",
      "      \"p5\",\n",
      "      \"p6\"\n",
      "    ],\n",
      "    \"MODEL.RPN.POST_NMS_TOPK_TRAIN\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TEST\": 1000,\n",
      "    \"MODEL.RPN.PRE_NMS_TOPK_TRAIN\": 2000\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"fast_qkv\": false,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"has_relative_attention_bias\": false,\n",
      "  \"has_spatial_attention_bias\": false,\n",
      "  \"has_visual_segment_embedding\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"image_feature_pool_shape\": [\n",
      "    7,\n",
      "    7,\n",
      "    256\n",
      "  ],\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_2d_position_embeddings\": 1024,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"max_rel_2d_pos\": 256,\n",
      "  \"max_rel_pos\": 128,\n",
      "  \"model_type\": \"layoutlmv2\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"rel_2d_pos_bins\": 64,\n",
      "  \"rel_pos_bins\": 32,\n",
      "  \"shape_size\": 128,\n",
      "  \"tokenizer_class\": \"LayoutXLMTokenizer\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 250002\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   0%|          | 0.00/1.48G [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   1%|▏         | 21.0M/1.48G [00:00<00:15, 92.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   3%|▎         | 41.9M/1.48G [00:00<00:14, 100MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   4%|▍         | 62.9M/1.48G [00:00<00:12, 113MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   6%|▌         | 83.9M/1.48G [00:00<00:11, 120MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   7%|▋         | 105M/1.48G [00:00<00:11, 121MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:   9%|▊         | 126M/1.48G [00:01<00:11, 117MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  10%|▉         | 147M/1.48G [00:01<00:11, 111MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  11%|█▏        | 168M/1.48G [00:01<00:11, 111MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  13%|█▎        | 189M/1.48G [00:01<00:12, 107MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  14%|█▍        | 210M/1.48G [00:01<00:12, 101MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  16%|█▌        | 231M/1.48G [00:02<00:12, 103MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  17%|█▋        | 252M/1.48G [00:02<00:12, 101MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  18%|█▊        | 273M/1.48G [00:02<00:11, 103MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  19%|█▉        | 283M/1.48G [00:02<00:13, 91.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  21%|██        | 304M/1.48G [00:02<00:12, 97.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  22%|██▏       | 325M/1.48G [00:03<00:12, 94.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  23%|██▎       | 346M/1.48G [00:03<00:11, 99.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  25%|██▍       | 367M/1.48G [00:03<00:11, 98.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  26%|██▋       | 388M/1.48G [00:03<00:10, 108MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  28%|██▊       | 409M/1.48G [00:03<00:10, 106MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  29%|██▉       | 430M/1.48G [00:04<00:10, 104MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  31%|███       | 451M/1.48G [00:04<00:10, 97.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  31%|███       | 461M/1.48G [00:04<00:15, 66.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  33%|███▎      | 482M/1.48G [00:04<00:13, 75.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  33%|███▎      | 493M/1.48G [00:05<00:13, 74.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  35%|███▍      | 514M/1.48G [00:05<00:11, 85.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  36%|███▌      | 535M/1.48G [00:05<00:09, 94.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  38%|███▊      | 556M/1.48G [00:05<00:09, 98.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  38%|███▊      | 566M/1.48G [00:05<00:09, 94.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  40%|███▉      | 587M/1.48G [00:05<00:08, 110MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  41%|████      | 608M/1.48G [00:06<00:08, 108MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  43%|████▎     | 629M/1.48G [00:06<00:07, 106MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  44%|████▍     | 650M/1.48G [00:06<00:07, 109MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  45%|████▌     | 671M/1.48G [00:06<00:07, 115MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  47%|████▋     | 692M/1.48G [00:06<00:07, 112MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  48%|████▊     | 713M/1.48G [00:07<00:06, 120MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  50%|████▉     | 734M/1.48G [00:07<00:05, 126MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  51%|█████     | 755M/1.48G [00:07<00:07, 95.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  53%|█████▎    | 776M/1.48G [00:07<00:07, 99.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  54%|█████▍    | 797M/1.48G [00:07<00:06, 97.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  55%|█████▌    | 818M/1.48G [00:08<00:07, 83.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  57%|█████▋    | 839M/1.48G [00:08<00:07, 83.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  58%|█████▊    | 849M/1.48G [00:08<00:07, 81.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  59%|█████▉    | 870M/1.48G [00:08<00:06, 94.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  60%|██████    | 891M/1.48G [00:09<00:07, 74.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  62%|██████▏   | 912M/1.48G [00:09<00:06, 83.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  63%|██████▎   | 933M/1.48G [00:09<00:06, 78.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  64%|██████▍   | 944M/1.48G [00:09<00:06, 81.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  65%|██████▌   | 965M/1.48G [00:09<00:05, 90.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  67%|██████▋   | 986M/1.48G [00:10<00:05, 91.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  68%|██████▊   | 1.01G/1.48G [00:10<00:06, 77.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  70%|██████▉   | 1.03G/1.48G [00:10<00:05, 77.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  70%|███████   | 1.04G/1.48G [00:10<00:05, 77.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  71%|███████   | 1.05G/1.48G [00:11<00:06, 69.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  72%|███████▏  | 1.06G/1.48G [00:11<00:06, 68.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  73%|███████▎  | 1.08G/1.48G [00:11<00:04, 80.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  74%|███████▍  | 1.09G/1.48G [00:11<00:04, 79.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  75%|███████▍  | 1.10G/1.48G [00:11<00:04, 76.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  76%|███████▌  | 1.12G/1.48G [00:11<00:03, 101MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  77%|███████▋  | 1.14G/1.48G [00:12<00:03, 108MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  79%|███████▉  | 1.16G/1.48G [00:12<00:02, 106MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  80%|████████  | 1.18G/1.48G [00:12<00:02, 101MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  82%|████████▏ | 1.21G/1.48G [00:12<00:02, 112MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  83%|████████▎ | 1.23G/1.48G [00:12<00:02, 93.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  85%|████████▍ | 1.25G/1.48G [00:13<00:02, 107MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  87%|████████▋ | 1.28G/1.48G [00:13<00:01, 134MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  88%|████████▊ | 1.30G/1.48G [00:13<00:01, 124MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  89%|████████▉ | 1.32G/1.48G [00:13<00:01, 131MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  91%|█████████ | 1.34G/1.48G [00:13<00:00, 138MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  92%|█████████▏| 1.36G/1.48G [00:13<00:00, 130MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  94%|█████████▎| 1.38G/1.48G [00:14<00:00, 117MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  95%|█████████▌| 1.41G/1.48G [00:14<00:00, 119MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  97%|█████████▋| 1.43G/1.48G [00:14<00:00, 130MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  98%|█████████▊| 1.45G/1.48G [00:14<00:00, 133MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin:  99%|█████████▉| 1.47G/1.48G [00:14<00:00, 128MB/s]\u001b[0m\n",
      "\u001b[34mDownloading pytorch_model.bin: 100%|██████████| 1.48G/1.48G [00:14<00:00, 98.9MB/s]\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2275] 2023-05-26 11:23:01,210 >> loading weights file pytorch_model.bin from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:2275] 2023-05-26 11:23:01,210 >> loading weights file pytorch_model.bin from cache at /tmp/transformers/cache/models--microsoft--layoutxlm-base/snapshots/8e04ebc4d3ba0013cf943b697c0aedf19b06472a/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_layoutlmv2.py:574] 2023-05-26 11:23:06,721 >> using `AvgPool2d` instead of `AdaptiveAvgPool2d`\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_layoutlmv2.py:574] 2023-05-26 11:23:06,721 >> using `AvgPool2d` instead of `AdaptiveAvgPool2d`\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:2847] 2023-05-26 11:23:07,840 >> Some weights of the model checkpoint at microsoft/layoutxlm-base were not used when initializing LayoutLMv2ForTokenClassification: ['layoutlmv2.visual.backbone.bottom_up.res5.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.stem.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv2.norm.num_batches_tracked']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing LayoutLMv2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing LayoutLMv2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:2859] 2023-05-26 11:23:07,841 >> Some weights of LayoutLMv2ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutxlm-base and are newly initialized: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:2847] 2023-05-26 11:23:07,840 >> Some weights of the model checkpoint at microsoft/layoutxlm-base were not used when initializing LayoutLMv2ForTokenClassification: ['layoutlmv2.visual.backbone.bottom_up.res5.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.6.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.17.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.4.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.16.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.22.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.13.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.10.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.stem.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.12.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.21.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.15.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.9.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.14.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.7.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.8.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.5.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.0.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.2.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.11.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res2.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.1.conv1.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.18.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.0.shortcut.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.3.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res5.2.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.20.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res3.3.conv3.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.19.conv2.norm.num_batches_tracked', 'layoutlmv2.visual.backbone.bottom_up.res4.0.conv2.norm.num_batches_tracked']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing LayoutLMv2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing LayoutLMv2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m[WARNING|modeling_utils.py:2859] 2023-05-26 11:23:07,841 >> Some weights of LayoutLMv2ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutxlm-base and are newly initialized: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:07,884 [main] INFO Loading datasets\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:07,885 [data.ner] INFO Getting NER datasets\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset json/default to /tmp/transformers/cache/json/default-f191a39c51cb5174/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\u001b[0m\n",
      "\u001b[34mDataset json downloaded and prepared to /tmp/transformers/cache/json/default-f191a39c51cb5174/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:07,951 [data.base] INFO Loading text and images... (progress bar disabled)\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:08,440 [trp] INFO INFO: Detected K/V where key does not have content. Excluding key from output. \u001b[0m\n",
      "\u001b[34mField\u001b[0m\n",
      "\u001b[34m==========\u001b[0m\n",
      "\u001b[34mKey: \u001b[0m\n",
      "\u001b[34mValue: http://www.mphinc.com - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 76.01237487792969, 'Geometry': {'BoundingBox': {'Width': 0.040094997733831406, 'Height': 0.010034700855612755, 'Left': 0.5565001964569092, 'Top': 0.29440340399742126}, 'Polygon': [{'X': 0.556502103805542, 'Y': 0.29440340399742126}, {'X': 0.5965951681137085, 'Y': 0.29442134499549866}, {'X': 0.5965932607650757, 'Y': 0.30443811416625977}, {'X': 0.5565001964569092, 'Y': 0.3044201731681824}]}, 'Id': '7896ab10-f0b2-499d-9319-7f9ee6d12e58', 'Relationships': [{'Type': 'VALUE', 'Ids': ['307df863-331d-4184-859f-561b3ccab673']}], 'EntityTypes': ['KEY'], 'Page': 1}\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:08,489 [trp] INFO INFO: Detected K/V where key does not have content. Excluding key from output. \u001b[0m\n",
      "\u001b[34mField\u001b[0m\n",
      "\u001b[34m==========\u001b[0m\n",
      "\u001b[34mKey: \u001b[0m\n",
      "\u001b[34mValue: TBC_Insurance0071375 - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 23.77922248840332, 'Geometry': {'BoundingBox': {'Width': 0.03384359925985336, 'Height': 0.011108193546533585, 'Left': 0.7917169332504272, 'Top': 0.9859501719474792}, 'Polygon': [{'X': 0.7917169332504272, 'Y': 0.9859501719474792}, {'X': 0.82555091381073, 'Y': 0.9859937429428101}, {'X': 0.8255605101585388, 'Y': 0.9970583915710449}, {'X': 0.7917264699935913, 'Y': 0.9970147013664246}]}, 'Id': 'd710ceca-d685-489c-953e-806e07dc84db', 'Relationships': [{'Type': 'VALUE', 'Ids': ['6c3a8274-0709-43c4-8214-230c5d41b74d']}], 'EntityTypes': ['KEY'], 'Page': 1}\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:08,588 [trp] INFO INFO: Detected K/V where key does not have content. Excluding key from output. \u001b[0m\n",
      "\u001b[34mField\u001b[0m\n",
      "\u001b[34m==========\u001b[0m\n",
      "\u001b[34mKey: \u001b[0m\n",
      "\u001b[34mValue:  - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 18.713516235351562, 'Geometry': {'BoundingBox': {'Width': 0.08611905574798584, 'Height': 0.038271334022283554, 'Left': 0.553975522518158, 'Top': 0.2256677895784378}, 'Polygon': [{'X': 0.5539950132369995, 'Y': 0.2256677895784378}, {'X': 0.6400945782661438, 'Y': 0.22578750550746918}, {'X': 0.6400762796401978, 'Y': 0.26393911242485046}, {'X': 0.553975522518158, 'Y': 0.2638183534145355}]}, 'Id': '28026c6e-a69e-46fd-930d-5b1340f54feb', 'Relationships': [{'Type': 'VALUE', 'Ids': ['38f2f5fa-c1d1-4fcf-b61f-97d7df713f98']}], 'EntityTypes': ['KEY'], 'Page': 1}\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:08,588 [trp] INFO INFO: Detected K/V where key does not have content. Excluding key from output. \u001b[0m\n",
      "\u001b[34mField\u001b[0m\n",
      "\u001b[34m==========\u001b[0m\n",
      "\u001b[34mKey: \u001b[0m\n",
      "\u001b[34mValue: TBC_Insurance0011214 - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 20.453649520874023, 'Geometry': {'BoundingBox': {'Width': 0.03321913629770279, 'Height': 0.011166322976350784, 'Left': 0.7917633652687073, 'Top': 0.9859945774078369}, 'Polygon': [{'X': 0.7917633652687073, 'Y': 0.9860183000564575}, {'X': 0.824981689453125, 'Y': 0.9859945774078369}, {'X': 0.8249825239181519, 'Y': 0.9971373081207275}, {'X': 0.7917641997337341, 'Y': 0.9971609115600586}]}, 'Id': '0be06ed4-7ec7-447e-a9e2-784e3250a71b', 'Relationships': [{'Type': 'VALUE', 'Ids': ['83f4b694-3315-42a1-82e0-03cbeee6112d']}], 'EntityTypes': ['KEY'], 'Page': 1}\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:08,597 [trp] INFO INFO: Detected K/V where key does not have content. Excluding key from output. \u001b[0m\n",
      "\u001b[34mField\u001b[0m\n",
      "\u001b[34m==========\u001b[0m\n",
      "\u001b[34mKey: \u001b[0m\n",
      "\u001b[34mValue:  - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 20.58942222595215, 'Geometry': {'BoundingBox': {'Width': 0.0323689728975296, 'Height': 0.011858541518449783, 'Left': 0.7910616397857666, 'Top': 0.9865580201148987}, 'Polygon': [{'X': 0.7910616397857666, 'Y': 0.9865580201148987}, {'X': 0.823423445224762, 'Y': 0.9865807294845581}, {'X': 0.8234306573867798, 'Y': 0.998416543006897}, {'X': 0.7910686135292053, 'Y': 0.9983937740325928}]}, 'Id': 'ba939434-b827-4a76-bb30-26c2bbff34ff', 'Relationships': [{'Type': 'VALUE', 'Ids': ['437ccb05-c237-43db-8b55-ef6411f03625']}], 'EntityTypes': ['KEY'], 'Page': 1}\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:08,754 [trp] INFO INFO: Detected K/V where key does not have content. Excluding key from output. \u001b[0m\n",
      "\u001b[34mField\u001b[0m\n",
      "\u001b[34m==========\u001b[0m\n",
      "\u001b[34mKey: \u001b[0m\n",
      "\u001b[34mValue: TBC_Insurance0011599 - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 21.25178337097168, 'Geometry': {'BoundingBox': {'Width': 0.03339758887887001, 'Height': 0.011775698512792587, 'Left': 0.791449785232544, 'Top': 0.9857885837554932}, 'Polygon': [{'X': 0.791449785232544, 'Y': 0.9857897162437439}, {'X': 0.8248450756072998, 'Y': 0.9857885837554932}, {'X': 0.824847400188446, 'Y': 0.9975633025169373}, {'X': 0.7914518713951111, 'Y': 0.9975643157958984}]}, 'Id': '3af73fc7-e9e0-4811-9b26-43dd3c4dfa75', 'Relationships': [{'Type': 'VALUE', 'Ids': ['50499bcb-73fc-45f7-bfdd-212549af10e3']}], 'EntityTypes': ['KEY'], 'Page': 1}\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:08,780 [trp] INFO INFO: Detected K/V where key does not have content. Excluding key from output. \u001b[0m\n",
      "\u001b[34mField\u001b[0m\n",
      "\u001b[34m==========\u001b[0m\n",
      "\u001b[34mKey: \u001b[0m\n",
      "\u001b[34mValue: TBC_Insurance0028031 - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 30.557029724121094, 'Geometry': {'BoundingBox': {'Width': 0.03266330435872078, 'Height': 0.011142070405185223, 'Left': 0.793186366558075, 'Top': 0.9858704805374146}, 'Polygon': [{'X': 0.7931875586509705, 'Y': 0.9858704805374146}, {'X': 0.8258496522903442, 'Y': 0.9859121441841125}, {'X': 0.8258486986160278, 'Y': 0.9970125555992126}, {'X': 0.793186366558075, 'Y': 0.9969705939292908}]}, 'Id': '8a9ce8c3-88b3-4f4f-97c1-6304d9c2e32c', 'Relationships': [{'Type': 'VALUE', 'Ids': ['36dfcd8f-8966-4697-8d00-bd4b66504373']}], 'EntityTypes': ['KEY'], 'Page': 1}\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:08,814 [trp] INFO INFO: Detected K/V where key does not have content. Excluding key from output. \u001b[0m\n",
      "\u001b[34mField\u001b[0m\n",
      "\u001b[34m==========\u001b[0m\n",
      "\u001b[34mKey: \u001b[0m\n",
      "\u001b[34mValue: TBC_Insurance0071376 - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 18.551057815551758, 'Geometry': {'BoundingBox': {'Width': 0.03181580454111099, 'Height': 0.012001476250588894, 'Left': 0.7936782240867615, 'Top': 0.9855995774269104}, 'Polygon': [{'X': 0.7936782240867615, 'Y': 0.9856054186820984}, {'X': 0.8254912495613098, 'Y': 0.9855995774269104}, {'X': 0.8254939913749695, 'Y': 0.9975953698158264}, {'X': 0.7936807870864868, 'Y': 0.9976010918617249}]}, 'Id': '8b7c503f-4be9-4bec-adb2-668ead24f917', 'Relationships': [{'Type': 'VALUE', 'Ids': ['6c91b4cc-00ae-4a06-8c8a-fd4d5f67ccdb']}], 'EntityTypes': ['KEY'], 'Page': 1}\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:08,833 [trp] INFO INFO: Detected K/V where key does not have content. Excluding key from output. \u001b[0m\n",
      "\u001b[34mField\u001b[0m\n",
      "\u001b[34m==========\u001b[0m\n",
      "\u001b[34mKey: \u001b[0m\n",
      "\u001b[34mValue:  - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 15.955998420715332, 'Geometry': {'BoundingBox': {'Width': 0.035205207765102386, 'Height': 0.011626782827079296, 'Left': 0.7922948002815247, 'Top': 0.9859977960586548}, 'Polygon': [{'X': 0.7922948002815247, 'Y': 0.9860028624534607}, {'X': 0.8274922966957092, 'Y': 0.9859977960586548}, {'X': 0.82750004529953, 'Y': 0.9976196885108948}, {'X': 0.7923024296760559, 'Y': 0.9976245760917664}]}, 'Id': 'a16df93d-7ee0-496d-b34c-2d12a343f5de', 'Relationships': [{'Type': 'VALUE', 'Ids': ['68fd9d04-8b3e-4a32-91e0-a10f5fec0bcf']}], 'EntityTypes': ['KEY'], 'Page': 1}\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:15,601 [data.base] INFO Pre-warming tokenizer before split .map()\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:15,877 [data.base] INFO Tokenizer pre-warm done\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:15,878 [data.base] INFO Splitting long pages... (progress bar disabled)\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:24,743 [data.ner] INFO Train dataset ready: Dataset({\n",
      "    features: ['raw-ref', 'textract-ref', 'source-ref', 'label', 'page-num', 'text', 'boxes', 'images', 'word_labels'],\n",
      "    num_rows: 117\u001b[0m\n",
      "\u001b[34m})\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset json/default to /tmp/transformers/cache/json/default-ec79428d105e2f29/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\u001b[0m\n",
      "\u001b[34mDataset json downloaded and prepared to /tmp/transformers/cache/json/default-ec79428d105e2f29/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:24,792 [data.base] INFO Loading text and images... (progress bar disabled)\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:25,063 [trp] INFO INFO: Detected K/V where key does not have content. Excluding key from output. \u001b[0m\n",
      "\u001b[34mField\u001b[0m\n",
      "\u001b[34m==========\u001b[0m\n",
      "\u001b[34mKey: \u001b[0m\n",
      "\u001b[34mValue: TBC_Insurance0008840 - {'BlockType': 'KEY_VALUE_SET', 'Confidence': 36.19546127319336, 'Geometry': {'BoundingBox': {'Width': 0.03464001044631004, 'Height': 0.012438258156180382, 'Left': 0.7910675406455994, 'Top': 0.9857746958732605}, 'Polygon': [{'X': 0.7910681366920471, 'Y': 0.9857746958732605}, {'X': 0.8257075548171997, 'Y': 0.9857860803604126}, {'X': 0.8257070183753967, 'Y': 0.9982129335403442}, {'X': 0.7910675406455994, 'Y': 0.9982014894485474}]}, 'Id': '20712b66-fd93-4f44-a0bc-555248acfb43', 'Relationships': [{'Type': 'VALUE', 'Ids': ['8de048b6-6729-4a86-ad80-0a16e8af677a']}], 'EntityTypes': ['KEY'], 'Page': 1}\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:26,604 [data.base] INFO Pre-warming tokenizer before split .map()\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:26,881 [data.base] INFO Tokenizer pre-warm done\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:26,881 [data.base] INFO Splitting long pages... (progress bar disabled)\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:29,711 [data.ner] INFO Validation dataset ready: Dataset({\n",
      "    features: ['raw-ref', 'textract-ref', 'source-ref', 'label', 'page-num', 'text', 'boxes', 'images', 'word_labels'],\n",
      "    num_rows: 11\u001b[0m\n",
      "\u001b[34m})\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:29,712 [main] INFO train dataset has 117 samples\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:29,712 [main] INFO validation dataset has 11 samples\u001b[0m\n",
      "\u001b[34m2023-05-26 11:23:29,712 [main] INFO Setting up trainer\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1650] 2023-05-26 11:23:35,680 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1650] 2023-05-26 11:23:35,680 >> ***** Running training *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1651] 2023-05-26 11:23:35,680 >>   Num examples = 117\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1651] 2023-05-26 11:23:35,680 >>   Num examples = 117\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1652] 2023-05-26 11:23:35,680 >>   Num Epochs = 20\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1653] 2023-05-26 11:23:35,680 >>   Instantaneous batch size per device = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1652] 2023-05-26 11:23:35,680 >>   Num Epochs = 20\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1653] 2023-05-26 11:23:35,680 >>   Instantaneous batch size per device = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1654] 2023-05-26 11:23:35,680 >>   Total train batch size (w. parallel, distributed & accumulation) = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1655] 2023-05-26 11:23:35,680 >>   Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1654] 2023-05-26 11:23:35,680 >>   Total train batch size (w. parallel, distributed & accumulation) = 2\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1655] 2023-05-26 11:23:35,680 >>   Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1656] 2023-05-26 11:23:35,680 >>   Total optimization steps = 1180\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1656] 2023-05-26 11:23:35,680 >>   Total optimization steps = 1180\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1657] 2023-05-26 11:23:35,682 >>   Number of trainable parameters = 368231687\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1657] 2023-05-26 11:23:35,682 >>   Number of trainable parameters = 368231687\u001b[0m\n",
      "\u001b[34m[2023-05-26 11:23:35.798: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:68] Found unsupported HuggingFace version 4.26.1 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\u001b[0m\n",
      "\u001b[34m[2023-05-26 11:23:35.853 algo-1:48 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2023-05-26 11:23:36.028 algo-1:48 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:24:07,806 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:24:07,806 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:24:07,807 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:24:07,807 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:24:07,807 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:24:07,807 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:24:09,807 [data.ner] INFO Evaluation class prediction ratios: {0: 0.049854150092813576, 1: 0.0954653937947494, 2: 0.43595863166268894, 3: 0.04826306019623442, 4: 0.012993900822063113, 5: 0.017767170511800583, 6: 0.33969769291964996}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.26496419310569763, 'eval_n_examples': 11, 'eval_acc': 0.9271599399651133, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.7585654111289465, 'eval_focus_else_acc_minus_one': 0.7585654111289465, 'eval_runtime': 2.0012, 'eval_samples_per_second': 5.497, 'eval_steps_per_second': 1.499, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:24:09,809 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-59\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:24:09,809 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-59\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:24:09,811 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-59/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:24:09,811 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-59/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:24:13,288 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-59/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:24:13,288 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-59/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:24:51,827 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:24:51,827 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:24:51,828 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:24:51,828 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:24:51,828 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:24:51,828 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:24:53,825 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05064969504110316, 1: 0.08804030761071334, 2: 0.42269954919119596, 3: 0.04322460885706709, 4: 0.0196234420578096, 5: 0.0503845133916733, 6: 0.32537788385043753}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.15560774505138397, 'eval_n_examples': 11, 'eval_acc': 0.9546540893528653, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8764468385544141, 'eval_focus_else_acc_minus_one': 0.8764468385544141, 'eval_runtime': 1.9988, 'eval_samples_per_second': 5.503, 'eval_steps_per_second': 1.501, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:24:53,828 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-118\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:24:53,828 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-118\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:24:53,829 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-118/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:24:53,829 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-118/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:24:57,337 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-118/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:24:57,337 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-118/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:25:36,256 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:25:36,256 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:25:36,256 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:25:36,256 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:25:36,256 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:25:36,256 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:25:38,366 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05118005833996288, 1: 0.09069212410501193, 2: 0.4399363564041368, 3: 0.05462741978255105, 4: 0.018032352161230444, 5: 0.03818615751789976, 6: 0.3073455316892071}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.0947495624423027, 'eval_n_examples': 11, 'eval_acc': 0.9561819433548903, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8631536438572396, 'eval_focus_else_acc_minus_one': 0.8631536438572396, 'eval_runtime': 2.1106, 'eval_samples_per_second': 5.212, 'eval_steps_per_second': 1.421, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:25:38,368 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-177\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:25:38,368 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-177\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:25:38,370 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-177/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:25:38,370 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-177/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:25:42,040 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-177/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:25:42,040 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-177/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:26:21,132 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:26:21,132 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:26:21,132 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:26:21,132 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:26:21,132 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:26:21,132 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:26:23,213 [data.ner] INFO Evaluation class prediction ratios: {0: 0.050119331742243436, 1: 0.08936621585786264, 2: 0.4274728188809334, 3: 0.049058605144524, 4: 0.02386634844868735, 5: 0.03818615751789976, 6: 0.32193052240784936}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.06923899054527283, 'eval_n_examples': 11, 'eval_acc': 0.981334935092404, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.9286571972055843, 'eval_focus_else_acc_minus_one': 0.9286571972055843, 'eval_runtime': 2.0813, 'eval_samples_per_second': 5.285, 'eval_steps_per_second': 1.441, 'epoch': 4.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:26:23,215 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-236\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:26:23,215 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-236\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:26:23,217 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-236/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:26:23,217 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-236/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:26:26,911 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-236/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:26:26,911 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-236/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:27:06,248 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:27:06,248 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:27:06,248 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:27:06,249 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:27:06,248 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:27:06,249 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:27:08,322 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05064969504110316, 1: 0.083001856271546, 2: 0.4274728188809334, 3: 0.05171042163882259, 4: 0.0196234420578096, 5: 0.03977724741447892, 6: 0.32776451869530626}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.10598030686378479, 'eval_n_examples': 11, 'eval_acc': 0.9709161287289428, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.9021554918887957, 'eval_focus_else_acc_minus_one': 0.9021554918887957, 'eval_runtime': 2.0743, 'eval_samples_per_second': 5.303, 'eval_steps_per_second': 1.446, 'epoch': 5.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:27:08,324 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-295\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:27:08,324 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-295\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:27:08,326 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-295/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:27:08,326 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-295/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:27:12,011 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-295/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:27:12,011 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-295/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:27:51,229 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:27:51,229 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:27:51,230 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:27:51,230 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:27:51,230 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:27:51,230 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:27:53,302 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05144523998939273, 1: 0.08989657915672236, 2: 0.4356934500132591, 3: 0.05383187483426147, 4: 0.01909307875894988, 5: 0.03898170246618934, 6: 0.31105807478122516}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.09480838477611542, 'eval_n_examples': 11, 'eval_acc': 0.9742817295225451, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.9026964510473466, 'eval_focus_else_acc_minus_one': 0.9026964510473466, 'eval_runtime': 2.0736, 'eval_samples_per_second': 5.305, 'eval_steps_per_second': 1.447, 'epoch': 6.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:27:53,305 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-354\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:27:53,305 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-354\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:27:53,307 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-354/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:27:53,307 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-354/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:27:56,978 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-354/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:27:56,978 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-354/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:28:35,936 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:28:35,936 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:28:35,936 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:28:35,936 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:28:35,936 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:28:35,936 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:28:38,043 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05144523998939273, 1: 0.08035003977724742, 2: 0.4394059931052771, 3: 0.05303632988597189, 4: 0.01909307875894988, 5: 0.03898170246618934, 6: 0.31768761601697165}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.1709899753332138, 'eval_n_examples': 11, 'eval_acc': 0.9497676958561382, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8587312673857351, 'eval_focus_else_acc_minus_one': 0.8587312673857351, 'eval_runtime': 2.1081, 'eval_samples_per_second': 5.218, 'eval_steps_per_second': 1.423, 'epoch': 7.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:28:38,046 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-413\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:28:38,046 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-413\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:28:38,048 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-413/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:28:38,048 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-413/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:28:41,693 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-413/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:28:41,693 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-413/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:29:20,817 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:29:20,817 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:29:20,817 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:29:20,817 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:29:20,817 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:29:20,817 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:29:22,887 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05144523998939273, 1: 0.08565367276584461, 2: 0.4356934500132591, 3: 0.05356669318483161, 4: 0.01935826040837974, 5: 0.03871652081675948, 6: 0.31556616282153277}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.13934005796909332, 'eval_n_examples': 11, 'eval_acc': 0.9663778464538815, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8874794717218943, 'eval_focus_else_acc_minus_one': 0.8874794717218943, 'eval_runtime': 2.0708, 'eval_samples_per_second': 5.312, 'eval_steps_per_second': 1.449, 'epoch': 8.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:29:22,889 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-472\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:29:22,889 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-472\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:29:22,891 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-472/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:29:22,891 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-472/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:29:26,646 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-472/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:29:26,646 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-472/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m{'loss': 0.194, 'learning_rate': 2.88135593220339e-05, 'epoch': 8.47}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:30:05,078 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:30:05,078 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:30:05,078 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:30:05,078 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:30:05,078 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:30:05,078 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:30:07,105 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05091487669053302, 1: 0.08565367276584461, 2: 0.4354282683638292, 3: 0.049323786793953855, 4: 0.01909307875894988, 5: 0.042694245558207375, 6: 0.31689207106868206}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.12783366441726685, 'eval_n_examples': 11, 'eval_acc': 0.963637483007719, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8764238476332795, 'eval_focus_else_acc_minus_one': 0.8764238476332795, 'eval_runtime': 2.028, 'eval_samples_per_second': 5.424, 'eval_steps_per_second': 1.479, 'epoch': 9.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:30:07,108 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-531\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:30:07,108 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-531\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:30:07,109 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-531/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:30:07,109 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-531/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:30:10,526 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-531/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:30:10,526 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-531/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:30:48,882 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:30:48,882 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:30:48,882 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:30:48,882 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:30:48,882 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:30:48,882 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:30:50,877 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05064969504110316, 1: 0.08565367276584461, 2: 0.4348979050649695, 3: 0.05197560328825245, 4: 0.01909307875894988, 5: 0.03951206576504906, 6: 0.31821797931583135}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.1258205622434616, 'eval_n_examples': 11, 'eval_acc': 0.9655660980371518, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8743006298681479, 'eval_focus_else_acc_minus_one': 0.8743006298681479, 'eval_runtime': 1.9959, 'eval_samples_per_second': 5.511, 'eval_steps_per_second': 1.503, 'epoch': 10.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:30:50,880 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-590\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:30:50,880 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-590\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:30:50,881 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-590/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:30:50,881 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-590/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:30:54,329 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-590/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:30:54,329 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-590/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:31:33,317 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:31:33,317 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:31:33,317 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:31:33,317 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:31:33,317 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:31:33,317 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:31:35,424 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05064969504110316, 1: 0.08565367276584461, 2: 0.43463272341553966, 3: 0.05091487669053302, 4: 0.018297533810660304, 5: 0.0405727923627685, 6: 0.3192787059135508}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.12115998566150665, 'eval_n_examples': 11, 'eval_acc': 0.9628901815125116, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8553155765044784, 'eval_focus_else_acc_minus_one': 0.8553155765044784, 'eval_runtime': 2.1084, 'eval_samples_per_second': 5.217, 'eval_steps_per_second': 1.423, 'epoch': 11.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:31:35,427 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-649\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:31:35,427 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-649\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:31:35,429 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-649/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:31:35,429 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-649/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:31:38,961 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-649/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:31:38,961 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-649/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:31:45,844 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-59] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:31:45,844 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-59] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:32:17,952 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:32:17,952 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:32:17,952 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:32:17,952 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:32:17,952 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:32:17,952 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:32:19,971 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05118005833996288, 1: 0.08565367276584461, 2: 0.4394059931052771, 3: 0.05277114823654203, 4: 0.01909307875894988, 5: 0.03871652081675948, 6: 0.31317952797666404}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.1360645890235901, 'eval_n_examples': 11, 'eval_acc': 0.9554874213621448, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8663287628807406, 'eval_focus_else_acc_minus_one': 0.8663287628807406, 'eval_runtime': 2.0204, 'eval_samples_per_second': 5.445, 'eval_steps_per_second': 1.485, 'epoch': 12.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:32:19,974 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-708\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:32:19,974 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-708\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:32:19,975 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-708/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:32:19,975 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-708/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:32:23,583 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-708/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:32:23,583 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-708/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:32:30,468 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-118] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:32:30,468 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-118] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:33:02,724 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:33:02,724 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:33:02,724 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:33:02,724 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:33:02,724 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:33:02,724 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:33:04,782 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05064969504110316, 1: 0.08565367276584461, 2: 0.4354282683638292, 3: 0.05277114823654203, 4: 0.01909307875894988, 5: 0.03871652081675948, 6: 0.31768761601697165}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.1191936656832695, 'eval_n_examples': 11, 'eval_acc': 0.9666086334833569, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8758259501854145, 'eval_focus_else_acc_minus_one': 0.8758259501854145, 'eval_runtime': 2.0596, 'eval_samples_per_second': 5.341, 'eval_steps_per_second': 1.457, 'epoch': 13.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:33:04,785 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-767\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:33:04,785 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-767\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:33:04,786 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-767/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:33:04,786 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-767/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:33:08,338 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-767/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:33:08,338 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-767/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:33:15,362 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-177] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:33:15,362 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-177] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:33:47,543 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:33:47,543 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:33:47,544 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:33:47,544 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:33:47,544 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:33:47,544 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:33:49,814 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05064969504110316, 1: 0.08565367276584461, 2: 0.4356934500132591, 3: 0.05277114823654203, 4: 0.01882789710952002, 5: 0.03871652081675948, 6: 0.31768761601697165}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.128867506980896, 'eval_n_examples': 11, 'eval_acc': 0.9659040880288114, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8695755161274938, 'eval_focus_else_acc_minus_one': 0.8695755161274938, 'eval_runtime': 2.2718, 'eval_samples_per_second': 4.842, 'eval_steps_per_second': 1.321, 'epoch': 14.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:33:49,817 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-826\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:33:49,817 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-826\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:33:49,818 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-826/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:33:49,818 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-826/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:33:53,323 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-826/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:33:53,323 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-826/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:34:00,111 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-295] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:34:00,111 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-295] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:34:32,609 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:34:32,609 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:34:32,609 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:34:32,609 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:34:32,609 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:34:32,609 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:34:34,690 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05064969504110316, 1: 0.08565367276584461, 2: 0.4341023601166799, 3: 0.05250596658711217, 4: 0.018297533810660304, 5: 0.03898170246618934, 6: 0.3198090692124105}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.1210562065243721, 'eval_n_examples': 11, 'eval_acc': 0.965535501888187, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8597593749059045, 'eval_focus_else_acc_minus_one': 0.8597593749059045, 'eval_runtime': 2.0823, 'eval_samples_per_second': 5.283, 'eval_steps_per_second': 1.441, 'epoch': 15.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:34:34,693 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-885\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:34:34,693 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-885\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:34:34,695 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-885/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:34:34,695 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-885/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:34:38,334 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-885/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:34:38,334 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-885/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:34:45,511 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-354] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:34:45,511 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-354] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:35:18,426 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:35:18,426 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:35:18,426 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:35:18,426 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:35:18,426 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:35:18,426 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:35:20,466 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05064969504110316, 1: 0.08565367276584461, 2: 0.4348979050649695, 3: 0.05277114823654203, 4: 0.018297533810660304, 5: 0.03871652081675948, 6: 0.31901352426412094}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.11810433864593506, 'eval_n_examples': 11, 'eval_acc': 0.9645582382264398, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.857756089012105, 'eval_focus_else_acc_minus_one': 0.857756089012105, 'eval_runtime': 2.0409, 'eval_samples_per_second': 5.39, 'eval_steps_per_second': 1.47, 'epoch': 16.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:35:20,469 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-944\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:35:20,469 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-944\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:35:20,470 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-944/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:35:20,470 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-944/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:35:24,098 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-944/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:35:24,098 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-944/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:35:31,286 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-413] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:35:31,286 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-413] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m{'loss': 0.008, 'learning_rate': 7.627118644067798e-06, 'epoch': 16.95}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:36:03,824 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:36:03,824 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:36:03,824 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:36:03,824 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:36:03,824 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:36:03,824 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:36:05,948 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05064969504110316, 1: 0.08565367276584461, 2: 0.4343675417661098, 3: 0.05277114823654203, 4: 0.018297533810660304, 5: 0.03871652081675948, 6: 0.31954388756298063}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.12017609924077988, 'eval_n_examples': 11, 'eval_acc': 0.9653487520604321, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8592675086269729, 'eval_focus_else_acc_minus_one': 0.8592675086269729, 'eval_runtime': 2.1243, 'eval_samples_per_second': 5.178, 'eval_steps_per_second': 1.412, 'epoch': 17.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:36:05,950 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-1003\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:36:05,950 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-1003\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:36:05,952 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-1003/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:36:05,952 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-1003/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:36:09,648 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-1003/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:36:09,648 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-1003/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:36:16,702 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-472] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:36:16,702 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-472] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:36:49,204 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:36:49,204 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:36:49,205 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:36:49,205 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:36:49,205 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:36:49,205 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:36:51,346 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05064969504110316, 1: 0.08565367276584461, 2: 0.4343675417661098, 3: 0.05277114823654203, 4: 0.01909307875894988, 5: 0.03871652081675948, 6: 0.31874834261469104}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.11556806415319443, 'eval_n_examples': 11, 'eval_acc': 0.9681896611513412, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8787480281074924, 'eval_focus_else_acc_minus_one': 0.8787480281074924, 'eval_runtime': 2.1423, 'eval_samples_per_second': 5.135, 'eval_steps_per_second': 1.4, 'epoch': 18.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:36:51,349 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-1062\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:36:51,349 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-1062\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:36:51,350 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-1062/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:36:51,350 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-1062/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:36:54,846 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-1062/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:36:54,846 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-1062/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:37:01,952 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-531] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:37:01,952 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-531] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:37:34,076 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2964] 2023-05-26 11:37:34,076 >> ***** Running Evaluation *****\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:37:34,076 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:37:34,076 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2966] 2023-05-26 11:37:34,076 >>   Num examples = 11\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2969] 2023-05-26 11:37:34,076 >>   Batch size = 4\u001b[0m\n",
      "\u001b[34m2023-05-26 11:37:36,203 [data.ner] INFO Evaluation class prediction ratios: {0: 0.05064969504110316, 1: 0.08565367276584461, 2: 0.4343675417661098, 3: 0.05277114823654203, 4: 0.01935826040837974, 5: 0.03871652081675948, 6: 0.3184831609652612}\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.11648332327604294, 'eval_n_examples': 11, 'eval_acc': 0.967794404234345, 'eval_n_focus_examples': 11, 'eval_focus_acc': 0.8779790602332614, 'eval_focus_else_acc_minus_one': 0.8779790602332614, 'eval_runtime': 2.1276, 'eval_samples_per_second': 5.17, 'eval_steps_per_second': 1.41, 'epoch': 19.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:37:36,205 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-1121\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:37:36,205 >> Saving model checkpoint to /tmp/transformers/checkpoints/checkpoint-1121\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:37:36,207 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-1121/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:37:36,207 >> Configuration saved in /tmp/transformers/checkpoints/checkpoint-1121/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:37:39,644 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-1121/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:37:39,644 >> Model weights saved in /tmp/transformers/checkpoints/checkpoint-1121/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:37:46,417 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-590] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2787] 2023-05-26 11:37:46,417 >> Deleting older checkpoint [/tmp/transformers/checkpoints/checkpoint-590] due to args.save_total_limit\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1901] 2023-05-26 11:37:46,997 >> \u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:1901] 2023-05-26 11:37:46,997 >> \u001b[0m\n",
      "\u001b[34mTraining completed. Do not forget to share your model on huggingface.co/models =)\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2025] 2023-05-26 11:37:46,998 >> Loading best model from /tmp/transformers/checkpoints/checkpoint-236 (score: 0.9286571972055843).\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2025] 2023-05-26 11:37:46,998 >> Loading best model from /tmp/transformers/checkpoints/checkpoint-236 (score: 0.9286571972055843).\u001b[0m\n",
      "\n",
      "2023-05-26 11:38:16 Uploading - Uploading generated training model\u001b[34m{'train_runtime': 868.3344, 'train_samples_per_second': 2.695, 'train_steps_per_second': 1.359, 'train_loss': 0.09022525738489405, 'epoch': 19.0}\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:38:04,019 >> Saving model checkpoint to /tmp/transformers/checkpoints\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:38:04,019 >> Saving model checkpoint to /tmp/transformers/checkpoints\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:38:04,020 >> Configuration saved in /tmp/transformers/checkpoints/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:38:04,020 >> Configuration saved in /tmp/transformers/checkpoints/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:38:07,464 >> Model weights saved in /tmp/transformers/checkpoints/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:38:07,464 >> Model weights saved in /tmp/transformers/checkpoints/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m***** train metrics *****\u001b[0m\n",
      "\u001b[34mepoch                    =       19.0\n",
      "  train_loss               =     0.0902\n",
      "  train_runtime            = 0:14:28.33\n",
      "  train_samples            =        117\n",
      "  train_samples_per_second =      2.695\n",
      "  train_steps_per_second   =      1.359\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:07,467 [main] INFO Saving model to /opt/ml/model\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:38:07,468 >> Saving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34m[INFO|trainer.py:2709] 2023-05-26 11:38:07,468 >> Saving model checkpoint to /opt/ml/model\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:38:07,469 >> Configuration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|configuration_utils.py:453] 2023-05-26 11:38:07,469 >> Configuration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:38:10,799 >> Model weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|modeling_utils.py:1704] 2023-05-26 11:38:10,799 >> Model weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34m[INFO|image_processing_utils.py:200] 2023-05-26 11:38:10,800 >> Image processor saved in /opt/ml/model/preprocessor_config.json\u001b[0m\n",
      "\u001b[34m[INFO|image_processing_utils.py:200] 2023-05-26 11:38:10,800 >> Image processor saved in /opt/ml/model/preprocessor_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2160] 2023-05-26 11:38:10,801 >> tokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2160] 2023-05-26 11:38:10,801 >> tokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2167] 2023-05-26 11:38:10,801 >> Special tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m[INFO|tokenization_utils_base.py:2167] 2023-05-26 11:38:10,801 >> Special tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,548 [main] INFO Copying code to /opt/ml/model/code for inference\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,548 [main] INFO Copying ./ddp_launcher.py to /opt/ml/model/code/ddp_launcher.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,549 [main] INFO Copying ./requirements.txt to /opt/ml/model/code/requirements.txt\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,550 [main] INFO Copying ./inference.py to /opt/ml/model/code/inference.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,550 [main] INFO Copying ./inference_seq2seq.py to /opt/ml/model/code/inference_seq2seq.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,551 [main] INFO Copying ./train.py to /opt/ml/model/code/train.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,552 [main] INFO Copying ./__init__.py to /opt/ml/model/code/__init__.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,552 [main] INFO Copying ./smtc_launcher.py to /opt/ml/model/code/smtc_launcher.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,553 [main] INFO Copying ./code/__init__.py to /opt/ml/model/code/code/__init__.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,554 [main] INFO Copying ./code/config.py to /opt/ml/model/code/code/config.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,554 [main] INFO Copying ./code/inference.py to /opt/ml/model/code/code/inference.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,555 [main] INFO Copying ./code/inference_seq2seq.py to /opt/ml/model/code/code/inference_seq2seq.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,556 [main] INFO Copying ./code/logging_utils.py to /opt/ml/model/code/code/logging_utils.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,556 [main] INFO Copying ./code/smddpfix.py to /opt/ml/model/code/code/smddpfix.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,557 [main] INFO Copying ./code/train.py to /opt/ml/model/code/code/train.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,558 [main] INFO Copying ./code/data/__init__.py to /opt/ml/model/code/code/data/__init__.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,559 [main] INFO Copying ./code/data/base.py to /opt/ml/model/code/code/data/base.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,560 [main] INFO Copying ./code/data/geometry.py to /opt/ml/model/code/code/data/geometry.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,561 [main] INFO Copying ./code/data/mlm.py to /opt/ml/model/code/code/data/mlm.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,562 [main] INFO Copying ./code/data/ner.py to /opt/ml/model/code/code/data/ner.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,562 [main] INFO Copying ./code/data/smgt.py to /opt/ml/model/code/code/data/smgt.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,563 [main] INFO Copying ./code/data/splitting.py to /opt/ml/model/code/code/data/splitting.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,564 [main] INFO Copying ./code/data/seq2seq/__init__.py to /opt/ml/model/code/code/data/seq2seq/__init__.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,564 [main] INFO Copying ./code/data/seq2seq/date_normalization.py to /opt/ml/model/code/code/data/seq2seq/date_normalization.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,565 [main] INFO Copying ./code/data/seq2seq/metrics.py to /opt/ml/model/code/code/data/seq2seq/metrics.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,566 [main] INFO Copying ./code/data/seq2seq/task_builder.py to /opt/ml/model/code/code/data/seq2seq/task_builder.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,568 [main] INFO Copying ./code/models/__init__.py to /opt/ml/model/code/code/models/__init__.py\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:11,568 [main] INFO Copying ./code/models/layoutlmv2.py to /opt/ml/model/code/code/models/layoutlmv2.py\u001b[0m\n",
      "\u001b[34mRunning smdistributed.dataparallel v1.4.3\u001b[0m\n",
      "\u001b[34mError in atexit._run_exitfuncs:\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/smdistributed/dataparallel/torch/torch_smddp/__init__.py\", line 51, in at_exit_smddp\u001b[0m\n",
      "\u001b[34mhm.shutdown()\u001b[0m\n",
      "\u001b[34mRuntimeError: Was this script started with smddprun? For more info on using smddprun, run smddprun -h\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:12,678 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:12,678 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-05-26 11:38:12,679 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-05-26 11:41:47 Completed - Training job completed\n",
      "Training seconds: 1457\n",
      "Billable seconds: 1457\n"
     ]
    }
   ],
   "source": [
    "inputs = {\n",
    "    \"images\": thumbs_s3uri,  #2023-05-24 not needed for LayoutLM \n",
    "    \"train\": train_manifest_s3uri,\n",
    "    \"textract\": textract_s3uri + \"/\",\n",
    "    \"validation\": test_manifest_s3uri,\n",
    "}\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f211cd-423d-4267-8432-9f044fcc6082",
   "metadata": {
    "tags": []
   },
   "source": [
    "### One-click model deployment\n",
    "\n",
    "Once the training job is complete, the model can be deployed to an endpoint via `estimator.deploy()` - specifying any extra parameters needed such as environment variables and, in this case, configurations for [Asynchronous Inference](https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference.html). Async inference endpoints in SageMaker can accept larger payloads and auto-scale down to 0 instances when not in use (if configured) - making them a useful option for many document processing use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6d5a0173-a3c1-486d-b7bc-c610eeb11020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ws-xlm-cfpb-hf-2023-05-26-11-15-49-226\n",
      "----------!"
     ]
    }
   ],
   "source": [
    "training_job_name = estimator.latest_training_job.describe()[\"TrainingJobName\"]\n",
    "# Or:\n",
    "# training_job_name = tuner.best_training_job()\n",
    "# ws-xlm-cfpb-hf-2023-05-26-01-32-32-238\n",
    "# ws-xlm-cfpb-hf-2023-05-26-01-32-32-238\n",
    "# ws-xlm-cfpb-hf-2023-05-26-11-15-49-226\n",
    "print (training_job_name)\n",
    "\n",
    "\n",
    "predictor = estimator.deploy(\n",
    "    # Avoid us accidentally deploying the same model twice by setting name per training job:\n",
    "    endpoint_name=training_job_name + \"-11\",\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",  # Or try ml.m5.2xlarge\n",
    "    image_uri=inf_image_uri,\n",
    "\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    "\n",
    "    env={\n",
    "        \"PYTHONUNBUFFERED\": \"1\",  # TODO: Disable once debugging is done\n",
    "        \"MMS_MAX_REQUEST_SIZE\": str(100*1024*1024),  # Accept large payloads (docs)\n",
    "        \"MMS_MAX_RESPONSE_SIZE\": str(100*1024*1024),  # Allow large responses\n",
    "    },\n",
    "\n",
    "    # Deploy in Asynchronous mode, to support large req/res payloads:\n",
    "    async_inference_config=sagemaker.async_inference.AsyncInferenceConfig(\n",
    "        output_path=f\"s3://{config.model_results_bucket}\",\n",
    "        max_concurrent_invocations_per_instance=2,\n",
    "        notification_config={\n",
    "            \"SuccessTopic\": config.model_callback_topic_arn,\n",
    "            \"ErrorTopic\": config.model_callback_topic_arn,\n",
    "        },\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4661a-fe4a-4e86-b97f-2b47b25a1cc2",
   "metadata": {},
   "source": [
    "If needed (for example, if your kernel crashes or restarts), you can also attach to previously deployed endpoints. Just look up the endpoint name from the SageMaker Console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb81b22b-ff28-45f2-b391-b6f875045a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint_name=\"xlm-cfpb-hf-2022-05-23-14-10-19-602\"\n",
    "# predictor = sagemaker.predictor_async.AsyncPredictor(\n",
    "#     sagemaker.Predictor(\n",
    "#         endpoint_name,\n",
    "#         serializer=sagemaker.serializers.JSONSerializer(),\n",
    "#         deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    "#     ),\n",
    "#     name=endpoint_name,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c90243-db89-40d9-88ec-30e337b03571",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Extract clean input images on-demand\n",
    "\n",
    "Just as we generated page thumbnail images to originally train our model, online inference should be able to generate these input features on-demand. In this example, the same code we previously used in a batch processing job has already been automatically deployed to a SageMaker inference endpoint for you. We can look up the endpoint name from the deployed stack parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a51024fa-68c4-4b9a-8ed9-952d4212ff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-created thumbnailer endpoint name:\n",
      "  ProcessingPipelineThumbnailStepThumbnailerDeployme-C4yqLIReXeKq\n"
     ]
    }
   ],
   "source": [
    "preproc_endpoint_name = ssm.get_parameter(\n",
    "    Name=config.thumbnail_endpoint_name_param,\n",
    ")[\"Parameter\"][\"Value\"]\n",
    "print(f\"Pre-created thumbnailer endpoint name:\\n  {preproc_endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f788bbf2-8535-4f4e-a27b-fe380e70cd2a",
   "metadata": {},
   "source": [
    "The online thumbnail-generation endpoint accepts raw input documents (i.e. PDFs, images), and returns compressed arrays of page image data. From the name of the endpoint, you can configure I/O formats and connect from the notebook as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "646e61ea-ff3a-44ae-9035-64e37e048b9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The configured thumbnailing endpoint does not exist in SageMaker. See the 'Optional Extras.ipynb' notebook for instructions to manually deploy the thumbnailer before continuing. Missing endpoint: ProcessingPipelineThumbnailStepThumbnailerDeployme-C4yqLIReXeKq",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[233], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e  \u001b[38;5;66;03m# Some other unknown issue\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m desc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe configured thumbnailing endpoint does not exist in SageMaker. See the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOptional \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtras.ipynb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m notebook for instructions to manually deploy the thumbnailer before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuing. Missing endpoint: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m preproc_endpoint_name\n\u001b[1;32m     14\u001b[0m     )\n\u001b[1;32m     16\u001b[0m preproc_predictor \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39mpredictor_async\u001b[38;5;241m.\u001b[39mAsyncPredictor(\n\u001b[1;32m     17\u001b[0m     sagemaker\u001b[38;5;241m.\u001b[39mPredictor(\n\u001b[1;32m     18\u001b[0m         preproc_endpoint_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     name\u001b[38;5;241m=\u001b[39mpreproc_endpoint_name,\n\u001b[1;32m     23\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: The configured thumbnailing endpoint does not exist in SageMaker. See the 'Optional Extras.ipynb' notebook for instructions to manually deploy the thumbnailer before continuing. Missing endpoint: ProcessingPipelineThumbnailStepThumbnailerDeployme-C4yqLIReXeKq"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    desc = smclient.describe_endpoint(EndpointName=preproc_endpoint_name)\n",
    "except smclient.exceptions.ClientError as e:\n",
    "    if e.response.get(\"Error\", {}).get(\"Message\", \"\").startswith(\"Could not find\"):\n",
    "        desc = None  # Endpoint does not exist\n",
    "    else:\n",
    "        raise e  # Some other unknown issue\n",
    "\n",
    "if desc is None:\n",
    "    raise ValueError(\n",
    "        \"The configured thumbnailing endpoint does not exist in SageMaker. See the 'Optional \"\n",
    "        \"Extras.ipynb' notebook for instructions to manually deploy the thumbnailer before \"\n",
    "        \"continuing. Missing endpoint: %s\" % preproc_endpoint_name\n",
    "    )\n",
    "\n",
    "preproc_predictor = sagemaker.predictor_async.AsyncPredictor(\n",
    "    sagemaker.Predictor(\n",
    "        preproc_endpoint_name,\n",
    "        serializer=util.deployment.FileSerializer.from_filename(\"any.pdf\"),\n",
    "        deserializer=util.deployment.CompressedNumpyDeserializer(),\n",
    "    ),\n",
    "    name=preproc_endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b199be3-eaf8-48b3-9607-3431650aec99",
   "metadata": {},
   "source": [
    "So how would it look to test the endpoint from Python? Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284883db-5305-427e-b2ba-a2f463bf8e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Choose an input (document or image):\n",
    "input_file = \"data/raw/121 Financial Credit Union/Visa Credit Card Agreement.pdf\"\n",
    "#input_file = \"data/imgs-clean/121 Financial Credit Union/Visa Credit Card Agreement-0001-1.png\"\n",
    "\n",
    "# Ensure de/serializers are correctly set up (since depends on input file type):\n",
    "preproc_predictor.serializer = util.deployment.FileSerializer.from_filename(input_file)\n",
    "preproc_predictor.deserializer = util.deployment.CompressedNumpyDeserializer()\n",
    "# Duplication because of https://github.com/aws/sagemaker-python-sdk/issues/3100\n",
    "preproc_predictor.predictor.serializer = preproc_predictor.serializer\n",
    "preproc_predictor.predictor.deserializer = preproc_predictor.deserializer\n",
    "\n",
    "# Run prediction:\n",
    "print(\"Calling endpoint...\")\n",
    "resp = preproc_predictor.predict(input_file)\n",
    "print(f\"Got response of type {type(resp)}\")\n",
    "\n",
    "# Render result:\n",
    "util.viz.draw_thumbnails_response(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d1c312-a55d-4c64-877c-3ebf938a778f",
   "metadata": {},
   "source": [
    "---\n",
    "## Using the entity recognition model\n",
    "\n",
    "Once the deployment is complete and a page thumbnail generator is ready, we're ready to test out inference on some documents!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c845df49-d798-4a92-b6f3-ba3f5f834d95",
   "metadata": {},
   "source": [
    "### Making requests and rendering results\n",
    "\n",
    "At a high level, the layout+language model accepts Textract-like JSON (e.g. as returned by [AnalyzeDocument](https://docs.aws.amazon.com/textract/latest/dg/API_AnalyzeDocument.html#API_AnalyzeDocument_ResponseSyntax) or [DetectDocumentText](https://docs.aws.amazon.com/textract/latest/dg/API_DetectDocumentText.html#API_DetectDocumentText_ResponseSyntax) APIs) and classifies each `WORD` [block](https://docs.aws.amazon.com/textract/latest/dg/API_Block.html) according to the entity classes we defined earlier: Returning the same JSON with additional fields added to indicate the predictions.\n",
    "\n",
    "In addition (per the logic in [src/code/inference.py](src/code/inference.py)):\n",
    "\n",
    "- To incorporate image features (for models that support them), requests can also include an `S3Thumbnails: { Bucket, Key }` object pointing to a thumbnailer endpoint response on S3.\n",
    "- Instead of passing the (typically large and already-S3-resident) Amazon Textract JSON inline, an `S3Input: { Bucket, Key }` reference can be passed instead (and this is actually how the standard pipeline integration works).\n",
    "- Output could also be redirected by passing an `S3Output: { Bucket, Key }` field in the request, but this is ignored and not needed on async endpoint deployments.\n",
    "- `TargetPageNum` and `TargetPageOnly` fields can be specified to limit processing to a single page of the input document.\n",
    "\n",
    "We can use utility functions to render these predictions as we did the manual annotations previously:\n",
    "\n",
    "> ⏰ **Inference may take time in some cases:**\n",
    ">\n",
    "> - Although enabling thumbnails can increase demo inference time below by several seconds, the end-to-end pipeline generates these images in parallel with running Amazon Textract - so there's usually no significant impact in practice.\n",
    "> - If you enabled **auto-scale-to-zero** on your your thumbnailer and/or model endpoint, you may see a cold-start of several minutes.\n",
    "\n",
    "> ⚠️ **Check:** Because of the way the SageMaker Python SDK's [AsyncPredictor](https://sagemaker.readthedocs.io/en/stable/api/inference/predictor_async.html) emulates a synchronous `predict()` interface for async endpoints, you may find the notebook waits indefinitely instead of raising an error when something goes wrong. If an inference takes more than ~30s to complete, check the endpoint logs from your [SageMaker Console Endpoints page](https://console.aws.amazon.com/sagemaker/home?#/endpoints) to see if your request resulted in an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "c16db0e3-2c66-4032-8784-ccf7fdb5e255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7227ed2871074d189cb23d3063100c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='Example:', max=9), Output()), _dom_classes=('widget-inte…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(ix)>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import trp\n",
    "\n",
    "# Enabling thumbnails can significantly increase inference time here, but can improve results for\n",
    "# models that consume image features (like LayoutLMv2, XLM):\n",
    "include_thumbnails = False\n",
    "\n",
    "def predict_from_manifest_item(\n",
    "    item,\n",
    "    predictor,\n",
    "    imgs_s3key_prefix=imgs_s3uri[len(\"s3://\"):].partition(\"/\")[2],\n",
    "    raw_s3uri_prefix=raw_s3uri,\n",
    "    textract_s3key_prefix=textract_s3uri[len(\"s3://\"):].partition(\"/\")[2],\n",
    "    imgs_local_prefix=\"data/imgs-clean\",\n",
    "    textract_local_prefix=\"data/textracted\",\n",
    "    draw=True,\n",
    "):\n",
    "    paths = util.viz.local_paths_from_manifest_item(\n",
    "        item,\n",
    "        imgs_s3key_prefix,\n",
    "        textract_s3key_prefix=textract_s3key_prefix,\n",
    "        imgs_local_prefix=imgs_local_prefix,\n",
    "        textract_local_prefix=textract_local_prefix,\n",
    "    )\n",
    "\n",
    "    if include_thumbnails:\n",
    "        doc_textract_s3key = item[\"textract-ref\"][len(\"s3://\"):].partition(\"/\")[2]\n",
    "        doc_raw_s3uri = raw_s3uri_prefix + doc_textract_s3key[len(textract_s3key_prefix):].rpartition(\"/\")[0]\n",
    "        print(f\"Fetching thumbnails for {doc_raw_s3uri}\")\n",
    "        thumbs_async = preproc_predictor.predict_async(input_path=doc_raw_s3uri)\n",
    "        thumbs_bucket, _, thumbs_key = thumbs_async.output_path[len(\"s3://\"):].partition(\"/\")\n",
    "        # Wait for the request to complete:\n",
    "        thumbs_async.get_result(sagemaker.async_inference.WaiterConfig())\n",
    "        req_extras = {\"S3Thumbnails\": {\"Bucket\": thumbs_bucket, \"Key\": thumbs_key}}\n",
    "        print(\"Got thumbnails result\")\n",
    "    else:\n",
    "        req_extras = {}\n",
    "\n",
    "    result_json = predictor.predict({\n",
    "        \"S3Input\": {\"S3Uri\": item[\"textract-ref\"]},\n",
    "        \"TargetPageNum\": item[\"page-num\"],\n",
    "        \"TargetPageOnly\": True,\n",
    "        **req_extras,\n",
    "    })\n",
    "\n",
    "    if \"Warnings\" in result_json:\n",
    "        for warning in result_json[\"Warnings\"]:\n",
    "            logger.warning(warning)\n",
    "    result_trp = trp.Document(result_json)\n",
    "\n",
    "    if draw:\n",
    "        util.viz.draw_smgt_annotated_page(\n",
    "            paths[\"image\"],\n",
    "            entity_classes,\n",
    "            annotations=[],\n",
    "            textract_result=result_trp,\n",
    "            # Note that page_num should be item[\"page-num\"] if we requested the full set of pages\n",
    "            # from the model above:\n",
    "            page_num=1,\n",
    "        )\n",
    "    return result_trp\n",
    "\n",
    "\n",
    "widgets.interact(\n",
    "    lambda ix: predict_from_manifest_item(test_examples[ix], predictor),\n",
    "    ix=widgets.IntSlider(\n",
    "        min=0,\n",
    "        max=len(test_examples) - 1,\n",
    "        step=1,\n",
    "        value=0,\n",
    "        description=\"Example:\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6ddf5a-b833-4750-b953-acb8a0ecb741",
   "metadata": {},
   "source": [
    "### From token classification to entity detection\n",
    "\n",
    "You may have noticed a slight mismatch: We're talking about extracting 'fields' or 'entities' from the document, but our model just classifies individual words. Going from words to entities assumes we're able to understand which words go \"together\" and what order they should be read in.\n",
    "\n",
    "Fortunately, Amazon Textract helps us out with this too as the word blocks are already collected into `LINE`s.\n",
    "\n",
    "For many straightforward applications, we can simply loop through the lines on a page and define an \"entity detection\" as a contiguous group of the same class - as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "040ad61c-9c32-49a5-b07b-acaf9585d7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raw-ref': 's3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/raw/Kean_Miller_Inv._1276537__0008835_-6.jpeg', 'textract-ref': 's3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/textracted/Kean_Miller_Inv._1276537__0008835_-6.jpeg/consolidated.json', 'source-ref': 's3://sagemaker-us-east-1-015943506230/DynamicTableParser/data/imgs-clean/Kean_Miller_Inv._1276537__0008835_-6.jpeg', 'label': {'image_size': [{'width': 2975, 'height': 3911, 'depth': 3}], 'annotations': [{'class_id': 0, 'top': 990, 'left': 440, 'height': 78, 'width': 236}, {'class_id': 0, 'top': 1149, 'left': 440, 'height': 69, 'width': 225}, {'class_id': 0, 'top': 1498, 'left': 443, 'height': 80, 'width': 223}, {'class_id': 0, 'top': 2377, 'left': 429, 'height': 75, 'width': 236}, {'class_id': 0, 'top': 2533, 'left': 434, 'height': 75, 'width': 234}, {'class_id': 0, 'top': 2764, 'left': 429, 'height': 69, 'width': 236}, {'class_id': 0, 'top': 3059, 'left': 432, 'height': 64, 'width': 244}, {'class_id': 0, 'top': 3268, 'left': 429, 'height': 84, 'width': 234}, {'class_id': 1, 'top': 3276, 'left': 711, 'height': 78, 'width': 126}, {'class_id': 1, 'top': 3056, 'left': 700, 'height': 75, 'width': 137}, {'class_id': 1, 'top': 2758, 'left': 695, 'height': 75, 'width': 140}, {'class_id': 1, 'top': 2533, 'left': 714, 'height': 78, 'width': 115}, {'class_id': 1, 'top': 2377, 'left': 708, 'height': 73, 'width': 127}, {'class_id': 1, 'top': 986, 'left': 724, 'height': 81, 'width': 113}, {'class_id': 1, 'top': 1147, 'left': 708, 'height': 78, 'width': 137}, {'class_id': 1, 'top': 1496, 'left': 708, 'height': 78, 'width': 124}, {'class_id': 2, 'top': 887, 'left': 864, 'height': 72, 'width': 588}, {'class_id': 2, 'top': 989, 'left': 875, 'height': 142, 'width': 956}, {'class_id': 2, 'top': 1153, 'left': 869, 'height': 325, 'width': 924}, {'class_id': 2, 'top': 1500, 'left': 869, 'height': 857, 'width': 935}, {'class_id': 2, 'top': 2378, 'left': 867, 'height': 129, 'width': 958}, {'class_id': 2, 'top': 2545, 'left': 864, 'height': 188, 'width': 969}, {'class_id': 2, 'top': 2767, 'left': 869, 'height': 260, 'width': 954}, {'class_id': 2, 'top': 3059, 'left': 867, 'height': 188, 'width': 964}, {'class_id': 2, 'top': 3277, 'left': 867, 'height': 137, 'width': 915}, {'class_id': 2, 'top': 3277, 'left': 1949, 'height': 70, 'width': 145}, {'class_id': 2, 'top': 3059, 'left': 1960, 'height': 62, 'width': 134}, {'class_id': 2, 'top': 2761, 'left': 1951, 'height': 76, 'width': 137}, {'class_id': 2, 'top': 2538, 'left': 1941, 'height': 70, 'width': 153}, {'class_id': 2, 'top': 2379, 'left': 1957, 'height': 72, 'width': 137}, {'class_id': 2, 'top': 1509, 'left': 1954, 'height': 67, 'width': 140}, {'class_id': 2, 'top': 1152, 'left': 1954, 'height': 67, 'width': 132}, {'class_id': 2, 'top': 985, 'left': 1960, 'height': 75, 'width': 126}]}, 'page-num': 1}\n"
     ]
    }
   ],
   "source": [
    "print (test_examples[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "5cea40eb-e46e-49d5-902a-f5b217f2ea31",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "An error occurred (ValidationError) when calling the InvokeEndpointAsync operation: Endpoint ws-xlm-cfpb-hf-2023-05-26-11-15-49-226-11 of account 015943506230 not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[241], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_from_manifest_item\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_examples\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[231], line 39\u001b[0m, in \u001b[0;36mpredict_from_manifest_item\u001b[0;34m(item, predictor, imgs_s3key_prefix, raw_s3uri_prefix, textract_s3key_prefix, imgs_local_prefix, textract_local_prefix, draw)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     req_extras \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 39\u001b[0m result_json \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mS3Input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mS3Uri\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtextract-ref\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTargetPageNum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpage-num\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTargetPageOnly\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mreq_extras\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarnings\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result_json:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m warning \u001b[38;5;129;01min\u001b[39;00m result_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarnings\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/predictor_async.py:100\u001b[0m, in \u001b[0;36mAsyncPredictor.predict\u001b[0;34m(self, data, input_path, initial_args, inference_id, waiter_config)\u001b[0m\n\u001b[1;32m     97\u001b[0m     input_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upload_data_to_s3(data, input_path)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_path \u001b[38;5;241m=\u001b[39m input_path\n\u001b[0;32m--> 100\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_submit_async_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m output_location \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutputLocation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    102\u001b[0m failure_location \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailureLocation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/predictor_async.py:212\u001b[0m, in \u001b[0;36mAsyncPredictor._submit_async_request\u001b[0;34m(self, input_path, initial_args, inference_id)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m\"\"\"Create request and invoke async endpoint with the request\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m request_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_request_args(input_path, initial_args, inference_id)\n\u001b[0;32m--> 212\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_runtime_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_args\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:960\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    959\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mValidationError\u001b[0m: An error occurred (ValidationError) when calling the InvokeEndpointAsync operation: Endpoint ws-xlm-cfpb-hf-2023-05-26-11-15-49-226-11 of account 015943506230 not found."
     ]
    }
   ],
   "source": [
    "res = predict_from_manifest_item(\n",
    "    test_examples[5],\n",
    "    predictor,\n",
    "    draw=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd38ccf7-b594-4621-8c03-86e56df1a379",
   "metadata": {},
   "source": [
    "print (res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "49081201-35e1-4ac9-9fd6-04ab23f69966",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Description:\n",
      "from Bijan Sharafkhani.\n",
      "----------\n",
      "Date:\n",
      "01/26/17\n",
      "----------\n",
      "Person:\n",
      "TJC\n",
      "----------\n",
      "Description:\n",
      "Review correspondence from Mr. Martin\n",
      "----------\n",
      "Hours:\n",
      "0.10\n",
      "----------\n",
      "Description:\n",
      "regarding water disposal options.\n",
      "----------\n",
      "Date:\n",
      "01/26/17\n",
      "----------\n",
      "Person:\n",
      "MDJ\n",
      "----------\n",
      "Description:\n",
      "Held telephone conferences with Bruce\n",
      "----------\n",
      "Hours:\n",
      "0.30\n",
      "----------\n",
      "Description:\n",
      "Martin regarding meeting with Bijan Sharafkhani (LDEQ); drafted email to Bijan Sharafkhani; drafted email to Bruce Martin, et al.\n",
      "----------\n",
      "Date:\n",
      "01/27/17\n",
      "----------\n",
      "Person:\n",
      "TJC\n",
      "----------\n",
      "Description:\n",
      "Telephone conference with Mr.\n",
      "----------\n",
      "Hours:\n",
      "5.00\n",
      "----------\n",
      "Description:\n",
      "Cartwright regarding exploring other options for sinkhole water management; Review DNR information regarding possible wells for re-completion on property which would not require consent of landowners currently suing Texas Brine; Examine requirements for community saltwater disposal well; Review DNR records regarding nearby wells which might be used as part of a community saltwater disposal agreement.\n",
      "----------\n",
      "Date:\n",
      "01/30/17\n",
      "----------\n",
      "Person:\n",
      "TJC\n",
      "----------\n",
      "Description:\n",
      "Review correspondence from Magnitude\n",
      "----------\n",
      "Hours:\n",
      "0.10\n",
      "----------\n",
      "Description:\n",
      "regarding recent seismicity.\n",
      "----------\n",
      "Date:\n",
      "01/30/17\n",
      "----------\n",
      "Person:\n",
      "TJC\n",
      "----------\n",
      "Description:\n",
      "Review correspondence from Mr. Burton\n",
      "----------\n",
      "Hours:\n",
      "0.10\n",
      "----------\n",
      "Description:\n",
      "regarding permission from landowners for berm maintenance.\n",
      "----------\n",
      "Date:\n",
      "01/30/17\n",
      "----------\n",
      "Person:\n",
      "TJC\n",
      "----------\n",
      "Description:\n",
      "Continue analyzing DNR files to obtain\n",
      "----------\n",
      "Hours:\n",
      "6.00\n",
      "----------\n",
      "Description:\n",
      "information requested by Mr. Cartwright regarding sinkhole water management options.\n",
      "----------\n",
      "Date:\n",
      "01/30/17\n",
      "----------\n",
      "Person:\n",
      "TJC\n",
      "----------\n",
      "Description:\n",
      "Review correspondence from Mr. Burton\n",
      "----------\n",
      "Hours:\n",
      "0.10\n",
      "----------\n",
      "Description:\n",
      "regarding access to property for decommissioning RESPEC instruments.\n",
      "----------\n",
      "Date:\n",
      "01/30/17\n",
      "----------\n",
      "Person:\n",
      "TJC\n",
      "----------\n",
      "Description:\n",
      "Telephone conference with Mr. Martin\n",
      "----------\n",
      "Hours:\n",
      "0.30\n",
      "----------\n",
      "Description:\n",
      "regarding sinkhole water management.\n"
     ]
    }
   ],
   "source": [
    "other_cls = len(entity_classes)\n",
    "prev_cls = other_cls\n",
    "current_entity = \"\"\n",
    "\n",
    "for page in res.pages:\n",
    "    for line in page.lines:\n",
    "        for word in line.words:\n",
    "            pred_cls = word._block[\"PredictedClass\"]\n",
    "            if pred_cls != prev_cls:\n",
    "                if prev_cls != other_cls:\n",
    "                    print(f\"----------\\n{entity_classes[prev_cls]}:\\n{current_entity}\")\n",
    "                prev_cls = pred_cls\n",
    "                if pred_cls != other_cls:\n",
    "                    current_entity = word.text\n",
    "                else:\n",
    "                    current_entity = \"\"\n",
    "                continue\n",
    "            current_entity = \" \".join((current_entity, word.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4bd908-4a5c-437c-90e4-895c572745f0",
   "metadata": {},
   "source": [
    "Of course there may be some instances where this heuristic breaks down, but we still have access to all the position (and text) information from each `LINE` and `WORD` to write additional rules for reading order and separation if wanted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93670571-10cf-489b-8b97-cb5a20d8401f",
   "metadata": {},
   "source": [
    "---\n",
    "## Setting up the end-to-end pipeline\n",
    "\n",
    "### Integrating the entity detection model\n",
    "\n",
    "So far we've demonstrated running entity detection requests from here in the notebook, but how can this model be integrated into the end-to-end document processing pipeline stack?\n",
    "\n",
    "First, you'll identify the **endpoint name** of your deployed model and the **AWS Systems Manager Parameter** that configures the SageMaker endpoint parameter for the pipeline stack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a21365-586a-4b83-8a7f-9a0b4cee0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Endpoint name:\\n  {predictor.endpoint_name}\")\n",
    "print(f\"\\nEndpoint SSM param:\\n  {config.sagemaker_endpoint_name_param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46912d03-8748-485b-9d50-841f154a670e",
   "metadata": {},
   "source": [
    "Finally, we'll update this SSM parameter to point to the deployed SageMaker endpoint.\n",
    "\n",
    "The below code should do this for you automatically:\n",
    "\n",
    "> ⚠️ **Note:** The [Lambda function](../pipeline/enrichment/fn-call-sagemaker/main.py) that calls your model from the OCR pipeline caches the endpoint name for a few minutes (`CACHE_TTL_SECONDS`) to reduce unnecessary ssm:GetParameter calls - so it may take a little time for an update here to take effect if you already processed a document recently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a6d62f-47bd-42ea-a74f-fed32fcd8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_endpoint_name = predictor.endpoint_name\n",
    "\n",
    "print(f\"Configuring pipeline with model: {pipeline_endpoint_name}\")\n",
    "\n",
    "ssm.put_parameter(\n",
    "    Name=config.sagemaker_endpoint_name_param,\n",
    "    Overwrite=True,\n",
    "    Value=pipeline_endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32572c6-4fdc-4ade-8801-bfe8f76934c2",
   "metadata": {},
   "source": [
    "Alternatively, you could open the [AWS Systems Manager Parameter Store console](https://console.aws.amazon.com/systems-manager/parameters/?tab=Table) and click on the *name* of the parameter to open its detail page, then the **Edit** button in the top right corner as shown below:\n",
    "\n",
    "![](img/ssm-param-detail-screenshot.png \"Screenshot of SSM parameter detail page showing Edit button\")\n",
    "\n",
    "From this screen you can manually set the **Value** of the parameter and save the changes.\n",
    "\n",
    "Whether you updated the SSM parameters via code or the console, your the pre-processing and enrichment stages of your stack should now be configured to use your endpoints!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81811e20-7b0d-474d-9602-d260db900a86",
   "metadata": {},
   "source": [
    "### Updating the pipeline entity definitions\n",
    "\n",
    "As well as configuring the *enrichment* stage of the pipeline to reference the deployed version of the model, we need to configure the *post-processing* stage to match the model's **definition of entity/field types**.\n",
    "\n",
    "The entity configuration is as we saved in the previous notebook, but the `annotation_guidance` attributes are not needed:\n",
    "\n",
    "> ℹ️ **Note:** As well as the mapping from ID numbers (returned by the model) to human-readable class names, this configuration controls how the pipeline consolidates entity matches into \"fields\" of the document: E.g. choosing the \"most likely\" or \"first\" value between multiple detections, or setting up a multi-value field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688cdf8-e448-45b5-ad5d-c0dbe5a46b04",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_entity_config = json.dumps([f.to_dict(omit=[\"annotation_guidance\"]) for f in fields], indent=2)\n",
    "print(pipeline_entity_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b8289-1bab-414f-aadf-c50fb3d36464",
   "metadata": {},
   "source": [
    "As above, you *could* set this value manually in the SSM console for the parameter named as `EntityConfig`.\n",
    "\n",
    "...But we can make the same update via code through the APIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bca521-6b34-47c9-9062-8d681d9ae817",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Setting pipeline entity configuration\")\n",
    "ssm.put_parameter(\n",
    "    Name=config.entity_config_param,\n",
    "    Overwrite=True,\n",
    "    Value=pipeline_entity_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11386c0a-ad81-4a20-93a8-3f89cdf8388c",
   "metadata": {},
   "source": [
    "### Set up online review with Amazon Augmented AI (A2I)\n",
    "\n",
    "Whereas our original batch annotation used the [built-in](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-task-types.html) image bounding box / object detection task UI, a custom task template is provided for online review.\n",
    "\n",
    "Since the template is built using a web framework (VueJS), we'll need to install some extra dependencies to enable building it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc459c88-e10b-46d5-82c3-24d74cc3dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd review && npm install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a638c64f-79a9-413f-8887-220b50da9526",
   "metadata": {},
   "source": [
    "Then, build the UI HTML template from source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5b333b-a887-4f05-a87c-c605ca4fd8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd review && npm run build\n",
    "ui_template_file = \"review/dist/index.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece1831-28dd-43f1-8077-91b064b6e531",
   "metadata": {},
   "source": [
    "Next, upload the built file as an A2I human review task UI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d403d4-08cb-4f4f-aefc-47fbfba80412",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ui_template_file, \"r\") as f:\n",
    "    create_template_resp = smclient.create_human_task_ui(\n",
    "        HumanTaskUiName=\"fields-validation-1\",  # (Can change this name as you like)\n",
    "        UiTemplate={\"Content\": f.read()},\n",
    "    )\n",
    "\n",
    "task_template_arn = create_template_resp[\"HumanTaskUiArn\"]\n",
    "print(f\"Created A2I task template:\\n{task_template_arn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e1637-e04a-4078-9079-beb56f8e5f17",
   "metadata": {},
   "source": [
    "We already defined a \"team\" for tasks to be routed to above, for SageMaker Ground Truth, and can re-use that team for the online review flow.\n",
    "\n",
    "To finish setting up the workflow itself, we need 2 more pieces of information:\n",
    "\n",
    "- The **location in S3** where review outputs should be stored\n",
    "- An appropriate **execution role** which will give the A2I workflow to read input documents and write review results.\n",
    "\n",
    "These are determined by the **OCR pipeline solution stack**, because the reviews bucket is created by the pipeline with event triggers to resume the next stage when reviews are uploaded.\n",
    "\n",
    "The code below should be able to look up these parameters for you automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f7c1f-d6d5-4d84-ba68-8bf9b86b812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_bucket_name = config.pipeline_reviews_bucket_name\n",
    "print(reviews_bucket_name)\n",
    "reviews_role_arn = config.a2i_execution_role_arn\n",
    "print(reviews_role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb724957-a783-48fb-85d3-39b16937e877",
   "metadata": {},
   "source": [
    "Alternatively, you may **find** your pipeline solution stack from the [AWS CloudFormation Console](https://console.aws.amazon.com/cloudformation/home?#/stacks) and click through to the stack detail page. From the **Outputs** tab, you should see the `A2IHumanReviewBucketName` and `A2IHumanReviewExecutionRoleArn` values as shown below.\n",
    "\n",
    "(You may also note the `A2IHumanReviewFlowParamName`, which we'll use in the next section)\n",
    "\n",
    "![](img/cfn-stack-outputs-a2i.png \"CloudFormation stack outputs for OCR pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e05cd6d-314b-435b-9994-8ec9bef79d4a",
   "metadata": {},
   "source": [
    "Once these values are populated, you're ready to create your review workflow by running the code below.\n",
    "\n",
    "Note that you can also manage flows via the [A2I Human Review Workflows Console](https://console.aws.amazon.com/a2i/home?#/human-review-workflows/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1f6192-99cb-4c4e-95da-656c64c3bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_flow_resp = smclient.create_flow_definition(\n",
    "    FlowDefinitionName=\"ocr-fields-validation-1\",  # (Can change this name as you like)\n",
    "    HumanLoopConfig={\n",
    "        \"WorkteamArn\": workteam_arn,\n",
    "        \"HumanTaskUiArn\": task_template_arn,\n",
    "        \"TaskTitle\": \"Review OCR Field Extractions\",\n",
    "        \"TaskDescription\": \"Review and correct credit card agreement field extractions\",\n",
    "        \"TaskCount\": 1,  # One reviewer per item\n",
    "        \"TaskAvailabilityLifetimeInSeconds\": 60 * 60,  # Availability timeout\n",
    "        \"TaskTimeLimitInSeconds\": 60 * 60,  # Working timeout\n",
    "    },\n",
    "    OutputConfig={\n",
    "        \"S3OutputPath\": f\"s3://{reviews_bucket_name}/reviews\",\n",
    "    },\n",
    "    RoleArn=reviews_role_arn,\n",
    ")\n",
    "\n",
    "print(f\"Created review workflow:\\n{create_flow_resp['FlowDefinitionArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed48057-1311-4609-839a-7cb5abf0b294",
   "metadata": {},
   "source": [
    "Finally, when the human review flow is created and registered, we can configure the document pipeline to use it - similarly to our SageMaker endpoint and entity configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb62b35-7fe9-4b9a-b6fe-8dd1e2bf6c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Configuring pipeline with review workflow: {create_flow_resp['FlowDefinitionArn']}\")\n",
    "\n",
    "ssm = boto3.client(\"ssm\")\n",
    "ssm.put_parameter(\n",
    "    Name=config.a2i_review_flow_arn_param,\n",
    "    Overwrite=True,\n",
    "    Value=create_flow_resp[\"FlowDefinitionArn\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ba0fc-1470-4d51-ba47-ac3ced075e91",
   "metadata": {},
   "source": [
    "Alternatively through the console, you would follow these steps:\n",
    "\n",
    "▶️ **Check** the `A2IHumanReviewFlowParamName` output of your OCR pipeline stack in [CloudFormation](https://console.aws.amazon.com/cloudformation/home?#/stacks) (as we did above)\n",
    "\n",
    "▶️ **Open** the [AWS Systems Manager Parameter Store console](https://console.aws.amazon.com/systems-manager/parameters/?tab=Table) and **find the review flow parameter in the list**.\n",
    "\n",
    "▶️ **Click** on the name of the parameter to open its detail page, and then on the **Edit** button in the top right corner. Set the value to the **workflow ARN** (see previous code cell in this notebook) and save the changes.\n",
    "\n",
    "![](img/ssm-a2i-param-detail.png \"Screenshot of SSM parameter detail page for human workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0768a157-9115-4261-aeae-6827bf7189f2",
   "metadata": {},
   "source": [
    "---\n",
    "## Final testing\n",
    "\n",
    "Your OCR pipeline should now be fully functional! Let's try it out:\n",
    "\n",
    "▶️ **Log in** to the labelling portal (URL available from the [SageMaker Ground Truth Workforces Console](https://console.aws.amazon.com/sagemaker/groundtruth?#/labeling-workforces) for your correct AWS Region)\n",
    "\n",
    "![](img/smgt-find-workforce-url.png \"Screenshot of SMGT console with workforce login URL\")\n",
    "\n",
    "▶️ **Upload** one of the sample documents to your pipeline's input bucket in Amazon S3, either using the code snippets below or drag and drop in the [Amazon S3 Console](https://console.aws.amazon.com/s3/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f202de-d041-4e94-af90-d80df1fe84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfpaths = []\n",
    "for currpath, dirs, files in os.walk(\"data/raw\"):\n",
    "    if \"/.\" in currpath or \"__\" in currpath:\n",
    "        continue\n",
    "    pdfpaths += [\n",
    "        os.path.join(currpath, f) for f in files\n",
    "        if f.lower().endswith(\".pdf\")\n",
    "    ]\n",
    "pdfpaths = sorted(pdfpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23811e21-bd19-45b1-ae92-a385f1981bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filepath = pdfpaths[14]\n",
    "test_s3uri = f\"s3://{config.pipeline_input_bucket_name}/{test_filepath}\"\n",
    "\n",
    "!aws s3 cp '{test_filepath}' '{test_s3uri}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68794a23-e2ec-49df-8d8b-7b5a8c375c2a",
   "metadata": {},
   "source": [
    "▶️ **Open up** your \"Processing Pipeline\" state machine in the [AWS Step Functions Console](https://console.aws.amazon.com/states/home?#/statemachines)\n",
    "\n",
    "After a few seconds you should find that a Step Function execution is automatically triggered and (since we enabled so many fields that at least one is always missing) the example is eventually forwarded for human review in A2I.\n",
    "\n",
    "As you'll see from the `ModelResult` field in your final *Step Output*, this pipeline produces a rich but usefully-structured output - with good opportunities for onward integration into further Step Functions steps or external systems. You can find more information and sample solutions for integrating AWS Step Functions in the [Step Functions Developer Guide](https://docs.aws.amazon.com/step-functions/latest/dg/welcome.html).\n",
    "\n",
    "![](img/sfn-statemachine-success.png \"Screenshot of successful Step Function execution with output JSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede76bf-3660-4418-82e3-ec303cb2a5a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this worked example we showed how advanced, open-source language processing models specifically tailored for document understanding can be integrated with [Amazon Textract](https://aws.amazon.com/textract/): providing a trainable, ML-driven framework for tackling more niche or complex requirements where Textract's [built-in structure extraction tools](https://aws.amazon.com/textract/features/) may not fully solve the challenges out-of-the-box.\n",
    "\n",
    "The underlying principle of the model - augmenting multi-task neural text processing architectures with positional data - is highly extensible, with potential to tackle a wide range of use cases where joint understanding of the content and presentation of text can deliver better results than considering text alone.\n",
    "\n",
    "We demonstrated how an end-to-end process automation pipeline applying this technology might look: Developing and deploying the model with [Amazon SageMaker](https://aws.amazon.com/sagemaker/), building a serverless workflow with [AWS Step Functions](https://aws.amazon.com/step-functions/) and [AWS Lambda](https://aws.amazon.com/lambda/), and driving quality with human review of low-confidence documents through [Amazon Augmented AI](https://aws.amazon.com/augmented-ai/).\n",
    "\n",
    "Thanks for following along, and for more information, don't forget to check out:\n",
    "\n",
    "- The other published [Amazon Textract Examples](https://docs.aws.amazon.com/textract/latest/dg/other-examples.html) listed in the [Textract Developer Guide](https://docs.aws.amazon.com/textract/latest/dg/what-is.html)\n",
    "- The extensive repository of [Amazon SageMaker Examples](https://github.com/aws/amazon-sagemaker-examples) and usage documentation in the [SageMaker Python SDK User Guide](https://sagemaker.readthedocs.io/en/stable/) - as well as the [SageMaker Developer Guide](https://docs.aws.amazon.com/sagemaker/index.html)\n",
    "- The wide range of other open algorithms and models published by [HuggingFace Transformers](https://huggingface.co/transformers/), and their specific documentation on [using the library with SageMaker](https://huggingface.co/transformers/sagemaker.html)\n",
    "- The conversational AI and NLP area (and others) of Amazon's own [Amazon.Science](https://www.amazon.science/conversational-ai-natural-language-processing) blog\n",
    "\n",
    "Happy building!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "7671b24f-b77e-4ae4-9a7d-b8cc9259d748",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shut down end point after use so we don't incur needless charges. \n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3224dead-aae3-41fa-9d2c-91d66a2255c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
